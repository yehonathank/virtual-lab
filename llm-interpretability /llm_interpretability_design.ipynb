{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2653f11",
   "metadata": {},
   "source": [
    "# virtual-lab Implementation -----\n",
    "## Objective: \n",
    "Create a method and implementation for a software used for clincian LLM interpretability in the context of automatic electronic phenotyping using an LLM\n",
    "\n",
    "## Steps (edit later)\n",
    "1. Team selection: An individual meeting with the PI to define a set of scientist agents to work on the project.\n",
    "2. Project specification: A team meeting to specify the project direction by deciding on key high-level details.\n",
    "3. Tools selection: A team meeting to brainstorm machine learning and/or computational tools for llm interpretability design.\n",
    "4. Tools implementation: A series of individual meetings with different scientist agents to implement their components individually. \n",
    "5. Workflow design: An individual meeting with the PI to determine the workflow for applying the tool implementations.\n",
    "\n",
    "<img src=\"images/steps.png\" style=\"display: block; margin: auto;\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4049f2c8",
   "metadata": {},
   "source": [
    "## Imports -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d55698c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from virtual_lab.constants import CONSISTENT_TEMPERATURE, CREATIVE_TEMPERATURE\n",
    "from virtual_lab.prompts import (\n",
    "    CODING_RULES,\n",
    "    REWRITE_PROMPT,\n",
    "    create_merge_prompt,\n",
    ")\n",
    "from virtual_lab.run_meeting import run_meeting\n",
    "from virtual_lab.utils import load_summaries\n",
    "\n",
    "from interpretability_constants import (\n",
    "    background_prompt,\n",
    "    project_specific_prompt,\n",
    "    num_iterations,\n",
    "    num_rounds,\n",
    "    discussions_phase_to_dir,\n",
    "    principal_investigator,\n",
    "    team_members,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd6b27a",
   "metadata": {},
   "source": [
    "## Team Selection -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386bec7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🟡 Starting meeting discussion_1\n",
      "DEBUGGING: Individual meeting members = [Principal Investigator, Scientific Critic]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team:   0%|          | 0/2 [00:14<?, ?it/s]1 [00:00<?, ?it/s]\n",
      "Rounds (+ Final Round): 100%|██████████| 1/1 [00:14<00:00, 14.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 245\n",
      "Output token count: 271\n",
      "Tool token count: 0\n",
      "Max token length: 516\n",
      "Cost: $0.00\n",
      "Time: 0:15\n",
      "✅ Finished meeting discussion_1\n",
      "🟡 Starting meeting discussion_2\n",
      "DEBUGGING: Individual meeting members = [Principal Investigator, Scientific Critic]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team:   0%|          | 0/2 [00:08<?, ?it/s]1 [00:00<?, ?it/s]\n",
      "Rounds (+ Final Round): 100%|██████████| 1/1 [00:08<00:00,  8.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 245\n",
      "Output token count: 268\n",
      "Tool token count: 0\n",
      "Max token length: 513\n",
      "Cost: $0.00\n",
      "Time: 0:11\n",
      "✅ Finished meeting discussion_2\n",
      "🟡 Starting meeting discussion_3\n",
      "DEBUGGING: Individual meeting members = [Principal Investigator, Scientific Critic]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team:   0%|          | 0/2 [00:13<?, ?it/s]1 [00:00<?, ?it/s]\n",
      "Rounds (+ Final Round): 100%|██████████| 1/1 [00:13<00:00, 13.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 245\n",
      "Output token count: 234\n",
      "Tool token count: 0\n",
      "Max token length: 479\n",
      "Cost: $0.00\n",
      "Time: 0:14\n",
      "✅ Finished meeting discussion_3\n",
      "🟡 Starting meeting discussion_4\n",
      "DEBUGGING: Individual meeting members = [Principal Investigator, Scientific Critic]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team:   0%|          | 0/2 [00:08<?, ?it/s]1 [00:00<?, ?it/s]\n",
      "Rounds (+ Final Round): 100%|██████████| 1/1 [00:08<00:00,  8.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 245\n",
      "Output token count: 289\n",
      "Tool token count: 0\n",
      "Max token length: 534\n",
      "Cost: $0.00\n",
      "Time: 0:10\n",
      "✅ Finished meeting discussion_4\n",
      "🟡 Starting meeting discussion_5\n",
      "DEBUGGING: Individual meeting members = [Principal Investigator, Scientific Critic]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team:   0%|          | 0/2 [00:11<?, ?it/s]1 [00:00<?, ?it/s]\n",
      "Rounds (+ Final Round): 100%|██████████| 1/1 [00:11<00:00, 11.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 245\n",
      "Output token count: 288\n",
      "Tool token count: 0\n",
      "Max token length: 533\n",
      "Cost: $0.00\n",
      "Time: 0:12\n",
      "✅ Finished meeting discussion_5\n",
      "Number of summaries: 5\n",
      "DEBUGGING: Individual meeting members = [Principal Investigator, Scientific Critic]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team:   0%|          | 0/2 [00:09<?, ?it/s]1 [00:00<?, ?it/s]\n",
      "Rounds (+ Final Round): 100%|██████████| 1/1 [00:09<00:00,  9.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 1,745\n",
      "Output token count: 525\n",
      "Tool token count: 0\n",
      "Max token length: 2,270\n",
      "Cost: $0.01\n",
      "Time: 0:11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## User\n",
       "\n",
       "This is the beginning of an individual meeting with Principal Investigator to discuss your research project.\n",
       "\n",
       "Here are summaries of the previous meetings:\n",
       "\n",
       "[begin summary 1]\n",
       "\n",
       "To address the challenge of developing a tool for LLM interpretability in the context of creating electronic phenotype definitions, it is crucial to assemble a team with diverse expertise in AI, biomedical informatics, and visualization. Here are the proposed team members:\n",
       "\n",
       "1. **Agent(\n",
       "    title=\"Computational Linguist\",\n",
       "    expertise=\"natural language processing and large language models\",\n",
       "    goal=\"develop methodologies for interpreting LLM outputs and ensuring their relevance in biomedical contexts\",\n",
       "    role=\"design and refine algorithms for LLM interpretability specific to electronic phenotype definitions\"\n",
       ")**\n",
       "   \n",
       "2. **Agent(\n",
       "    title=\"Biomedical Informatics Specialist\",\n",
       "    expertise=\"electronic health records and phenotype extraction\",\n",
       "    goal=\"align LLM outputs with clinical needs and validate their applicability and usefulness\",\n",
       "    role=\"bridge the gap between LLM interpretations and real-world clinical applications by defining relevant phenotype criteria\"\n",
       ")**\n",
       "   \n",
       "3. **Agent(\n",
       "    title=\"Data Visualization Expert\",\n",
       "    expertise=\"visual analytics and human-computer interaction\",\n",
       "    goal=\"create visual tools that foster trust and understanding between clinicians and AI outputs\",\n",
       "    role=\"develop interactive visualizations to represent LLM decisions and rationale clearly to clinical users\"\n",
       ")**\n",
       "\n",
       "This team composition ensures comprehensive coverage of the key areas necessary for the success of this project. Each member will bring a unique perspective and skill set to address the multifaceted challenges of LLM interpretability and its application in a clinical setting.\n",
       "\n",
       "[end summary 1]\n",
       "\n",
       "[begin summary 2]\n",
       "\n",
       "To effectively develop a tool for LLM interpretability in the context of creating electronic phenotype definitions, it is crucial to assemble a team with diverse expertise that covers both technical and domain-specific knowledge. Here's the proposed team:\n",
       "\n",
       "```python\n",
       "Agent(\n",
       "    title=\"Machine Learning Engineer\",\n",
       "    expertise=\"developing and optimizing large language models and interpretability techniques\",\n",
       "    goal=\"contribute expertise in building and refining the LLM interpretability framework\",\n",
       "    role=\"design algorithms and methods to enhance interpretability and ensure the models are transparent and reliable for clinical use\",\n",
       ")\n",
       "\n",
       "Agent(\n",
       "    title=\"Clinical Informatics Specialist\",\n",
       "    expertise=\"understanding electronic health records (EHRs) and phenotype definitions\",\n",
       "    goal=\"ensure that the interpretability tool aligns with clinical needs and accurately represents phenotype information\",\n",
       "    role=\"provide insights into clinical data structures and facilitate the integration of LLM outputs with EHR systems\",\n",
       ")\n",
       "\n",
       "Agent(\n",
       "    title=\"Data Visualization Expert\",\n",
       "    expertise=\"creating visual representations of complex data to enhance understanding\",\n",
       "    goal=\"design visual interfaces that enhance the interpretability tool's usability and foster trust between clinicians and the model\",\n",
       "    role=\"develop visualizations that clearly communicate the LLM's decision-making process and output\",\n",
       ")\n",
       "```\n",
       "\n",
       "These team members will collaborate to create a robust and reliable LLM interpretability tool that bridges the gap between AI models and clinical practice, ultimately fostering trust and aiding in the accurate definition of phenotypes.\n",
       "\n",
       "[end summary 2]\n",
       "\n",
       "[begin summary 3]\n",
       "\n",
       "To effectively tackle the challenge of LLM interpretability in the context of electronic phenotype definitions, it is crucial to assemble a diverse team with expertise in relevant areas. Here is my proposed team:\n",
       "\n",
       "Agent(\n",
       "    title=\"Data Scientist\",\n",
       "    expertise=\"natural language processing and large language model development\",\n",
       "    goal=\"enhance model interpretability through advanced NLP techniques\",\n",
       "    role=\"develop algorithms and methods to interpret and visualize LLM decisions in clinical phenotyping\"\n",
       ")\n",
       "\n",
       "Agent(\n",
       "    title=\"Clinical Informatics Specialist\",\n",
       "    expertise=\"clinical data management and electronic health records\",\n",
       "    goal=\"ensure clinical relevance and accuracy in phenotype definitions\",\n",
       "    role=\"provide insights into clinical data and collaborate on aligning model outputs with clinical needs\"\n",
       ")\n",
       "\n",
       "Agent(\n",
       "    title=\"Visualization Expert\",\n",
       "    expertise=\"data visualization and user interface design\",\n",
       "    goal=\"foster trust with clinicians through intuitive visual representations\",\n",
       "    role=\"design and implement visual tools to help clinicians understand model decisions and phenotypes\"\n",
       ")\n",
       "\n",
       "I believe that this team, with expertise spanning AI, clinical informatics, and visualization, is well-suited to develop a comprehensive tool that enhances LLM interpretability and trust in clinical applications.\n",
       "\n",
       "[end summary 3]\n",
       "\n",
       "[begin summary 4]\n",
       "\n",
       "To effectively develop a tool for large language model (LLM) interpretability in the context of creating electronic phenotype definitions, incorporating a visual perspective, I propose assembling a diverse team with expertise in relevant areas. Here are the recommended team members:\n",
       "\n",
       "```python\n",
       "Agent(\n",
       "    title=\"Computational Linguist\",\n",
       "    expertise=\"natural language processing, language model interpretability\",\n",
       "    goal=\"develop methods to enhance the interpretability of language models in biomedical applications\",\n",
       "    role=\"design and implement interpretability techniques for LLMs, focusing on understanding and explaining model outputs\"\n",
       ")\n",
       "\n",
       "Agent(\n",
       "    title=\"Bioinformatician\",\n",
       "    expertise=\"electronic health records, phenotype extraction\",\n",
       "    goal=\"ensure accurate extraction and definition of phenotypes from biomedical data\",\n",
       "    role=\"guide the integration of electronic health record data with LLMs, and validate phenotype definitions\"\n",
       ")\n",
       "\n",
       "Agent(\n",
       "    title=\"Data Visualization Specialist\",\n",
       "    expertise=\"data visualization, human-computer interaction\",\n",
       "    goal=\"create intuitive visualizations to foster trust and understanding between clinicians and AI models\",\n",
       "    role=\"develop visual tools to represent LLM decision-making processes and outputs in a clinician-friendly manner\"\n",
       ")\n",
       "```\n",
       "\n",
       "These team members will bring a balance of skills necessary to address the technical, biomedical, and usability aspects of the project, ensuring a comprehensive approach to developing the desired tool.\n",
       "\n",
       "[end summary 4]\n",
       "\n",
       "[begin summary 5]\n",
       "\n",
       "To develop a tool for large language model (LLM) interpretability in the context of creating electronic phenotype definitions, we will need a team with diverse expertise in artificial intelligence, natural language processing, biomedical informatics, and visualization techniques. Here are the team members I would like to invite to the discussion:\n",
       "\n",
       "```python\n",
       "Agent(\n",
       "    title=\"Data Scientist\",\n",
       "    expertise=\"natural language processing and machine learning\",\n",
       "    goal=\"develop and implement NLP algorithms to improve LLM interpretability in biomedical contexts\",\n",
       "    role=\"design LLM models and enhance their interpretability through innovative techniques\",\n",
       ")\n",
       "\n",
       "Agent(\n",
       "    title=\"Clinical Informatics Specialist\",\n",
       "    expertise=\"clinical data interpretation and electronic health records\",\n",
       "    goal=\"ensure the interpretability tool aligns with clinical needs and accurately represents phenotype definitions\",\n",
       "    role=\"provide insights into clinical requirements and validate the interpretability approach from a healthcare perspective\",\n",
       ")\n",
       "\n",
       "Agent(\n",
       "    title=\"Visualization Expert\",\n",
       "    expertise=\"data visualization and user interface design\",\n",
       "    goal=\"create visual tools that improve the interpretability and trust of LLM outputs for clinicians\",\n",
       "    role=\"design and implement visualization strategies that effectively communicate model decisions to end-users\",\n",
       ")\n",
       "```\n",
       "\n",
       "These experts will collaborate to create a comprehensive approach to LLM interpretability, incorporating both technical and clinical insights, and ensuring the tool is both functional and user-friendly for clinicians.\n",
       "\n",
       "[end summary 5]\n",
       "\n",
       "Here is the agenda for the meeting:\n",
       "\n",
       "Please read the summaries of multiple separate meetings about the same agenda. Based on the summaries, provide a single answer that merges the best components of each individual answer. Please use the same format as the individual answers. Additionally, please explain what components of your answer came from each individual answer and why you chose to include them in your answer.\n",
       "\n",
       "As a reference, here is the agenda from those meetings, which must be addressed here as well:\n",
       "\n",
       "You are working on a research project to use software techniques to develop a tool for large language model (LLM) interpretability in the context of creating electronic phenotype definitions, ideally, also incorporating a visual perspective to foster trust between the clinician and the model. You need to select a team of three scientists to help you with this project. Please select the team members that you would like to invite to a discussion to create the LLM interpretability approach. Please list the team members in the following format, using the team member below as an example. You should not include yourself (Principal Investigator) in the list.\n",
       "\n",
       "Agent(\n",
       "    title=\"Principal Investigator\",\n",
       "    expertise=\"applying artificial intelligence to biomedical research\",\n",
       "    goal=\"perform research in your area of expertise that maximizes the scientific impact of the work\",\n",
       "    role=\"lead a team of experts to solve an important problem in artificial intelligence for biomedicine, make key decisions about the project direction based on team member input, and manage the project timeline and resources\",\n",
       ")\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "Principal Investigator, please provide your response to the agenda.\n",
       "\n",
       "## Principal Investigator\n",
       "\n",
       "Based on the summaries provided, I have synthesized the best components from each meeting to form a cohesive team for developing a tool for LLM interpretability in the context of electronic phenotype definitions. Here is the proposed team:\n",
       "\n",
       "```python\n",
       "Agent(\n",
       "    title=\"Computational Linguist\",\n",
       "    expertise=\"natural language processing and large language models\",\n",
       "    goal=\"develop methodologies for interpreting LLM outputs and ensuring their relevance in biomedical contexts\",\n",
       "    role=\"design and refine algorithms for LLM interpretability specific to electronic phenotype definitions\",\n",
       ")\n",
       "\n",
       "Agent(\n",
       "    title=\"Clinical Informatics Specialist\",\n",
       "    expertise=\"electronic health records and phenotype extraction\",\n",
       "    goal=\"align LLM outputs with clinical needs and validate their applicability and usefulness\",\n",
       "    role=\"bridge the gap between LLM interpretations and real-world clinical applications by defining relevant phenotype criteria\",\n",
       ")\n",
       "\n",
       "Agent(\n",
       "    title=\"Data Visualization Expert\",\n",
       "    expertise=\"visual analytics and human-computer interaction\",\n",
       "    goal=\"create visual tools that foster trust and understanding between clinicians and AI outputs\",\n",
       "    role=\"develop interactive visualizations to represent LLM decisions and rationale clearly to clinical users\",\n",
       ")\n",
       "```\n",
       "\n",
       "### Explanation of Components:\n",
       "\n",
       "1. **Computational Linguist**: \n",
       "   - **Source**: Summaries 1 and 4\n",
       "   - **Reason**: The role of a Computational Linguist is crucial for developing methodologies to interpret LLM outputs, which is a core aspect of the project. This role was consistently highlighted in summaries 1 and 4, emphasizing the need for expertise in NLP and LLM interpretability.\n",
       "\n",
       "2. **Clinical Informatics Specialist**:\n",
       "   - **Source**: Summaries 2, 3, and 5\n",
       "   - **Reason**: This role ensures that the interpretability tool aligns with clinical needs and accurately represents phenotype definitions. The consistent mention across summaries 2, 3, and 5 underscores the importance of integrating clinical insights to validate the tool's applicability in real-world settings.\n",
       "\n",
       "3. **Data Visualization Expert**:\n",
       "   - **Source**: All summaries\n",
       "   - **Reason**: The inclusion of a Data Visualization Expert is essential for creating visual tools that enhance understanding and trust. This role was universally acknowledged across all summaries, highlighting the need for intuitive visual representations to communicate model decisions effectively to clinicians.\n",
       "\n",
       "By combining these roles, the team will have a balanced mix of expertise in NLP, clinical informatics, and visualization, ensuring a comprehensive approach to developing the LLM interpretability tool. This team composition addresses the technical, biomedical, and usability aspects of the project, aligning with the goal of fostering trust between clinicians and AI models.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Team selection - prompts\n",
    "team_selection_agenda = f\"\"\"{background_prompt} You need to select a team of three scientists to help you with this project. Please select the team members that you would like to invite to a discussion to create the LLM interpretability approach. Please list the team members in the following format, using the team member below as an example. You should not include yourself (Principal Investigator) in the list.\n",
    "\n",
    "Agent(\n",
    "    title=\"Principal Investigator\",\n",
    "    expertise=\"applying artificial intelligence to biomedical research\",\n",
    "    goal=\"perform research in your area of expertise that maximizes the scientific impact of the work\",\n",
    "    role=\"lead a team of experts to solve an important problem in artificial intelligence for biomedicine, make key decisions about the project direction based on team member input, and manage the project timeline and resources\",\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# Team selection - discussion\n",
    "for iteration_num in range(num_iterations):\n",
    "    save_name = f\"discussion_{iteration_num + 1}\"\n",
    "    try:\n",
    "        print(f\"🟡 Starting meeting {save_name}\")\n",
    "        run_meeting(\n",
    "            meeting_type=\"individual\",\n",
    "            team_member=principal_investigator,\n",
    "            agenda=team_selection_agenda,\n",
    "            save_dir=discussions_phase_to_dir[\"team_selection\"],\n",
    "            save_name=f\"discussion_{iteration_num + 1}\",\n",
    "            temperature=CREATIVE_TEMPERATURE,\n",
    "        )\n",
    "        print(f\"✅ Finished meeting {save_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Meeting {save_name} failed with error: {e}\")\n",
    "\n",
    "# Team selection - merge\n",
    "team_selection_summaries = load_summaries(\n",
    "    discussion_paths=list(discussions_phase_to_dir[\"team_selection\"].glob(\"discussion_*.json\")))\n",
    "print(f\"Number of summaries: {len(team_selection_summaries)}\")\n",
    "\n",
    "team_selection_merge_prompt = create_merge_prompt(agenda=team_selection_agenda)\n",
    "\n",
    "run_meeting(\n",
    "    meeting_type=\"individual\",\n",
    "    team_member=principal_investigator,\n",
    "    summaries=team_selection_summaries,\n",
    "    agenda=team_selection_merge_prompt,\n",
    "    save_dir=discussions_phase_to_dir[\"team_selection\"],\n",
    "    save_name=\"merged\",\n",
    "    temperature=CONSISTENT_TEMPERATURE,\n",
    ")\n",
    "\n",
    "# Show merged meeting output for team_selection\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "with open(\"discussions/team_selection/merged.md\", \"r\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "display(Markdown(content))\n",
    "### Note: Manually imported the merged chosen team members into interpretability_constants.py\n",
    "### Note: Once that is done, you must run the import again to sync chosen team members..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9235e716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloaded team_members: (Computational Linguist, Clinical Informatics Specialist, Data Visualization Expert, Scientific Critic)\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import interpretability_constants\n",
    "\n",
    "# RELOAD the whole module\n",
    "importlib.reload(interpretability_constants)\n",
    "\n",
    "# THEN re-import what you need from it\n",
    "from interpretability_constants import team_members\n",
    "\n",
    "print(\"Reloaded team_members:\", team_members)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5586ada2",
   "metadata": {},
   "source": [
    "## Project Specification -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea37105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleared 10 discussion files from discussions/project_specification\n",
      "🟡 Starting meeting discussion_1\n",
      "DEBUGGING: Entering a team meeting...\n",
      "the team lead is:\n",
      "Principal Investigator\n",
      "and the team members are:\n",
      "(Computational Linguist, Clinical Informatics Specialist, Data Visualization Expert, Scientific Critic)\n",
      "\n",
      "DEBUGGING: Team meeting members = [Principal Investigator, Computational Linguist, Clinical Informatics Specialist, Data Visualization Expert, Scientific Critic]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team: 100%|██████████| 5/5 [00:57<00:00, 11.55s/it]<?, ?it/s]\n",
      "Team: 100%|██████████| 5/5 [00:53<00:00, 10.67s/it]<02:53, 57.76s/it]\n",
      "Team: 100%|██████████| 5/5 [00:52<00:00, 10.42s/it]<01:50, 55.17s/it]\n",
      "Team:   0%|          | 0/5 [00:14<?, ?it/s]4 [02:43<00:53, 53.78s/it]\n",
      "Rounds (+ Final Round): 100%|██████████| 4/4 [02:57<00:00, 44.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 58,604\n",
      "Output token count: 6,087\n",
      "Tool token count: 0\n",
      "Max token length: 8,039\n",
      "Cost: $0.21\n",
      "Time: 3:00\n",
      "✅ Finished meeting discussion_1\n",
      "🟡 Starting meeting discussion_2\n",
      "DEBUGGING: Entering a team meeting...\n",
      "the team lead is:\n",
      "Principal Investigator\n",
      "and the team members are:\n",
      "(Computational Linguist, Clinical Informatics Specialist, Data Visualization Expert, Scientific Critic)\n",
      "\n",
      "DEBUGGING: Team meeting members = [Principal Investigator, Computational Linguist, Clinical Informatics Specialist, Data Visualization Expert, Scientific Critic]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team: 100%|██████████| 5/5 [01:05<00:00, 13.10s/it]<?, ?it/s]\n",
      "Team: 100%|██████████| 5/5 [00:56<00:00, 11.24s/it]<03:16, 65.52s/it]\n",
      "Team: 100%|██████████| 5/5 [00:49<00:00,  9.84s/it]<02:00, 60.05s/it]\n",
      "Team:   0%|          | 0/5 [00:14<?, ?it/s]4 [02:50<00:55, 55.10s/it]\n",
      "Rounds (+ Final Round): 100%|██████████| 4/4 [03:05<00:00, 46.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 64,175\n",
      "Output token count: 7,093\n",
      "Tool token count: 0\n",
      "Max token length: 9,045\n",
      "Cost: $0.23\n",
      "Time: 3:09\n",
      "✅ Finished meeting discussion_2\n",
      "🟡 Starting meeting discussion_3\n",
      "DEBUGGING: Entering a team meeting...\n",
      "the team lead is:\n",
      "Principal Investigator\n",
      "and the team members are:\n",
      "(Computational Linguist, Clinical Informatics Specialist, Data Visualization Expert, Scientific Critic)\n",
      "\n",
      "DEBUGGING: Team meeting members = [Principal Investigator, Computational Linguist, Clinical Informatics Specialist, Data Visualization Expert, Scientific Critic]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team: 100%|██████████| 5/5 [01:03<00:00, 12.77s/it]<?, ?it/s]\n",
      "Team: 100%|██████████| 5/5 [01:05<00:00, 13.10s/it]<03:11, 63.83s/it]\n",
      "Team: 100%|██████████| 5/5 [01:00<00:00, 12.07s/it]<02:09, 64.80s/it]\n",
      "Team:   0%|          | 0/5 [00:19<?, ?it/s]4 [03:09<01:02, 62.78s/it]\n",
      "Rounds (+ Final Round): 100%|██████████| 4/4 [03:29<00:00, 52.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 65,143\n",
      "Output token count: 7,019\n",
      "Tool token count: 0\n",
      "Max token length: 8,971\n",
      "Cost: $0.23\n",
      "Time: 3:33\n",
      "✅ Finished meeting discussion_3\n",
      "🟡 Starting meeting discussion_4\n",
      "DEBUGGING: Entering a team meeting...\n",
      "the team lead is:\n",
      "Principal Investigator\n",
      "and the team members are:\n",
      "(Computational Linguist, Clinical Informatics Specialist, Data Visualization Expert, Scientific Critic)\n",
      "\n",
      "DEBUGGING: Team meeting members = [Principal Investigator, Computational Linguist, Clinical Informatics Specialist, Data Visualization Expert, Scientific Critic]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rounds (+ Final Round):   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "def clear_discussion_files(save_dir: Path):\n",
    "    json_files = glob.glob(str(save_dir / \"discussion_*.json\"))\n",
    "    md_files = glob.glob(str(save_dir / \"discussion_*.md\"))\n",
    "    for f in json_files + md_files:\n",
    "        os.remove(f)\n",
    "    print(f\"Cleared {len(json_files) + len(md_files)} discussion files from {save_dir}\")\n",
    "\n",
    "clear_discussion_files(discussions_phase_to_dir[\"project_specification\"])\n",
    "\n",
    "# Project specification - prompts\n",
    "project_specification_agenda = f\"{background_prompt} Please create a software design approach to solve this problem. Decide whether you will take a machine learning approach or not. For your choice, decide whether you will use open source interpretability libraries from GitHub or create your own completely from scratch. If modifying existing libraries, please specify which interpretability libraries to build upon to create an interpretability tool that conveys interpretability information visually so the clinician can trust it with ease. If designing algorithms from scratch, please describe how you propose new algorithms. Consider methods for eliminating LLM hallucinations using RAG or similar, increasing faithfulness and reasoning, and promote valid chain of thought logic using the SNOMED Database, which we have access to.\" \n",
    "\n",
    "project_specification_questions = (\n",
    "    \"Will you take a machine learning approach or not?\",\n",
    "    \"Will you use open source interpretability libraries from GitHub or create your own completely from scratch? (choose only one)?\",\n",
    "    \"If modifying existing libraries, which interpretability libraries to build upon (please list 3-4)?\",\n",
    "    \"If designing algorithms from scratch, how exactly will you propose new algorithms?\",\n",
    "    \"How will the interpretability tool use methods for eliminating LLM hallucinations, increasing faithfulness and reasoning, and promote valid chain of thought logic using the SNOMED Database, which we have access to?\",\n",
    ") \n",
    "\n",
    "# Project specification - discussion\n",
    "for iteration_num in range(num_iterations):\n",
    "    save_name = f\"discussion_{iteration_num + 1}\"\n",
    "    try:\n",
    "        print(f\"🟡 Starting meeting {save_name}\")\n",
    "        run_meeting(\n",
    "            meeting_type=\"team\",\n",
    "            team_lead=principal_investigator,\n",
    "            team_members=team_members,\n",
    "            agenda=project_specification_agenda,\n",
    "            agenda_questions=project_specification_questions,\n",
    "            save_dir=discussions_phase_to_dir[\"project_specification\"],\n",
    "            save_name=save_name,\n",
    "            temperature=CREATIVE_TEMPERATURE,\n",
    "            num_rounds=num_rounds,\n",
    "        )\n",
    "        print(f\"✅ Finished meeting {save_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Meeting {save_name} failed with error: {e}\")\n",
    "\n",
    "\n",
    "# Project specification - merge\n",
    "project_specification_summaries = load_summaries(\n",
    "    discussion_paths=list(discussions_phase_to_dir[\"project_specification\"].glob(\"discussion_*.json\")))\n",
    "print(f\"Number of summaries: {len(project_specification_summaries)}\")\n",
    "\n",
    "project_specification_merge_prompt = create_merge_prompt(\n",
    "    agenda=project_specification_agenda,\n",
    "    agenda_questions=project_specification_questions,\n",
    ")\n",
    "\n",
    "run_meeting(\n",
    "    meeting_type=\"individual\",\n",
    "    team_member=principal_investigator,\n",
    "    summaries=project_specification_summaries,\n",
    "    agenda=project_specification_merge_prompt,\n",
    "    save_dir=discussions_phase_to_dir[\"project_specification\"],\n",
    "    save_name=\"merged\",\n",
    "    temperature=CONSISTENT_TEMPERATURE,\n",
    "    num_rounds=num_rounds,\n",
    ")\n",
    "\n",
    "# Show merged meeting output for project_specification\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "with open(\"discussions/project_specification/merged.md\", \"r\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "display(Markdown(content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b28b86",
   "metadata": {},
   "source": [
    "## Tool Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5d1491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of prior summaries: 1\n",
      "🟡 Starting meeting discussion_1\n",
      "DEBUGGING: Entering a team meeting...\n",
      "the team lead is:\n",
      "Principal Investigator\n",
      "and the team members are:\n",
      "(Computational Linguist, Biomedical Informatics Specialist, Data Visualization Expert, Scientific Critic)\n",
      "\n",
      "DEBUGGING: Team meeting members = [Principal Investigator, Computational Linguist, Biomedical Informatics Specialist, Data Visualization Expert, Scientific Critic]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team: 100%|██████████| 5/5 [01:02<00:00, 12.48s/it]<?, ?it/s]\n",
      "Team: 100%|██████████| 5/5 [01:03<00:00, 12.66s/it]<03:07, 62.39s/it]\n",
      "Team: 100%|██████████| 5/5 [01:02<00:00, 12.43s/it]<02:05, 62.91s/it]\n",
      "Team:   0%|          | 0/5 [00:16<?, ?it/s]4 [03:07<01:02, 62.57s/it]\n",
      "Rounds (+ Final Round): 100%|██████████| 4/4 [03:23<00:00, 50.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 86,524\n",
      "Output token count: 8,070\n",
      "Tool token count: 0\n",
      "Max token length: 10,819\n",
      "Cost: $0.30\n",
      "Time: 3:26\n",
      "✅ Finished meeting discussion_1\n",
      "🟡 Starting meeting discussion_2\n",
      "DEBUGGING: Entering a team meeting...\n",
      "the team lead is:\n",
      "Principal Investigator\n",
      "and the team members are:\n",
      "(Computational Linguist, Biomedical Informatics Specialist, Data Visualization Expert, Scientific Critic)\n",
      "\n",
      "DEBUGGING: Team meeting members = [Principal Investigator, Computational Linguist, Biomedical Informatics Specialist, Data Visualization Expert, Scientific Critic]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team: 100%|██████████| 5/5 [00:53<00:00, 10.79s/it]<?, ?it/s]\n",
      "Team: 100%|██████████| 5/5 [00:51<00:00, 10.37s/it]<02:41, 53.93s/it]\n",
      "Team: 100%|██████████| 5/5 [00:49<00:00,  9.84s/it]<01:45, 52.69s/it]\n",
      "Team:   0%|          | 0/5 [00:17<?, ?it/s]4 [02:34<00:51, 51.09s/it]\n",
      "Rounds (+ Final Round): 100%|██████████| 4/4 [02:52<00:00, 43.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 76,107\n",
      "Output token count: 6,643\n",
      "Tool token count: 0\n",
      "Max token length: 9,392\n",
      "Cost: $0.26\n",
      "Time: 2:57\n",
      "✅ Finished meeting discussion_2\n",
      "🟡 Starting meeting discussion_3\n",
      "DEBUGGING: Entering a team meeting...\n",
      "the team lead is:\n",
      "Principal Investigator\n",
      "and the team members are:\n",
      "(Computational Linguist, Biomedical Informatics Specialist, Data Visualization Expert, Scientific Critic)\n",
      "\n",
      "DEBUGGING: Team meeting members = [Principal Investigator, Computational Linguist, Biomedical Informatics Specialist, Data Visualization Expert, Scientific Critic]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team: 100%|██████████| 5/5 [00:51<00:00, 10.38s/it]<?, ?it/s]\n",
      "Team: 100%|██████████| 5/5 [00:53<00:00, 10.80s/it]<02:35, 51.91s/it]\n",
      "Team: 100%|██████████| 5/5 [00:50<00:00, 10.03s/it]<01:46, 53.13s/it]\n",
      "Team:   0%|          | 0/5 [00:13<?, ?it/s]4 [02:36<00:51, 51.77s/it]\n",
      "Rounds (+ Final Round): 100%|██████████| 4/4 [02:49<00:00, 42.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 77,802\n",
      "Output token count: 6,778\n",
      "Tool token count: 0\n",
      "Max token length: 9,527\n",
      "Cost: $0.26\n",
      "Time: 2:52\n",
      "✅ Finished meeting discussion_3\n",
      "🟡 Starting meeting discussion_4\n",
      "DEBUGGING: Entering a team meeting...\n",
      "the team lead is:\n",
      "Principal Investigator\n",
      "and the team members are:\n",
      "(Computational Linguist, Biomedical Informatics Specialist, Data Visualization Expert, Scientific Critic)\n",
      "\n",
      "DEBUGGING: Team meeting members = [Principal Investigator, Computational Linguist, Biomedical Informatics Specialist, Data Visualization Expert, Scientific Critic]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team: 100%|██████████| 5/5 [01:04<00:00, 12.90s/it]<?, ?it/s]\n",
      "Team: 100%|██████████| 5/5 [00:57<00:00, 11.57s/it]<03:13, 64.51s/it]\n",
      "Team: 100%|██████████| 5/5 [00:56<00:00, 11.26s/it]<02:01, 60.59s/it]\n",
      "Team:   0%|          | 0/5 [00:15<?, ?it/s]4 [02:58<00:58, 58.64s/it]\n",
      "Rounds (+ Final Round): 100%|██████████| 4/4 [03:14<00:00, 48.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 82,391\n",
      "Output token count: 7,396\n",
      "Tool token count: 0\n",
      "Max token length: 10,145\n",
      "Cost: $0.28\n",
      "Time: 3:17\n",
      "✅ Finished meeting discussion_4\n",
      "🟡 Starting meeting discussion_5\n",
      "DEBUGGING: Entering a team meeting...\n",
      "the team lead is:\n",
      "Principal Investigator\n",
      "and the team members are:\n",
      "(Computational Linguist, Biomedical Informatics Specialist, Data Visualization Expert, Scientific Critic)\n",
      "\n",
      "DEBUGGING: Team meeting members = [Principal Investigator, Computational Linguist, Biomedical Informatics Specialist, Data Visualization Expert, Scientific Critic]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team: 100%|██████████| 5/5 [00:56<00:00, 11.23s/it]<?, ?it/s]\n",
      "Team: 100%|██████████| 5/5 [00:56<00:00, 11.25s/it]<02:48, 56.15s/it]\n",
      "Team: 100%|██████████| 5/5 [00:51<00:00, 10.20s/it]<01:52, 56.20s/it]\n",
      "Team:   0%|          | 0/5 [00:19<?, ?it/s]4 [02:43<00:53, 53.83s/it]\n",
      "Rounds (+ Final Round): 100%|██████████| 4/4 [03:02<00:00, 45.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 79,822\n",
      "Output token count: 6,870\n",
      "Tool token count: 0\n",
      "Max token length: 9,619\n",
      "Cost: $0.27\n",
      "Time: 3:05\n",
      "✅ Finished meeting discussion_5\n",
      "Number of summaries: 5\n",
      "DEBUGGING: Individual meeting members = [Principal Investigator, Scientific Critic]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team: 100%|██████████| 2/2 [00:30<00:00, 15.28s/it]<?, ?it/s]\n",
      "Team: 100%|██████████| 2/2 [00:39<00:00, 19.59s/it]<01:31, 30.55s/it]\n",
      "Team: 100%|██████████| 2/2 [00:29<00:00, 14.60s/it]<01:11, 35.62s/it]\n",
      "Team:   0%|          | 0/2 [00:13<?, ?it/s]4 [01:38<00:32, 32.69s/it]\n",
      "Rounds (+ Final Round): 100%|██████████| 4/4 [01:52<00:00, 28.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 52,913\n",
      "Output token count: 5,332\n",
      "Tool token count: 0\n",
      "Max token length: 10,836\n",
      "Cost: $0.19\n",
      "Time: 1:53\n"
     ]
    }
   ],
   "source": [
    "# Tools selection - prompts\n",
    "tools_selection_agenda = f\"{background_prompt} {project_specific_prompt} Now you need to select machine learning and/or computational and/or visualization and/or interpretability tools to implement this LLM interpretability tool approach. Please list several tools (5-10) that would be relevant to this LLM interpretability approach and how they could be used in the context of this project. If selecting machine learning tools, please prioritize pre-trained models (e.g., pre-trained interpretability libraries or models) for simplicity.\"\n",
    "\n",
    "tools_selection_questions = (\n",
    "    \"What machine learning and/or computational and/or visualization and/or interpretability tools could be used for this LLM interpretability design approach (list 5-10)?\",\n",
    "    \"For each tool, how could it be used for designing an LLM interetability tool?\",\n",
    ")\n",
    "\n",
    "tools_selection_prior_summaries = load_summaries(\n",
    "    discussion_paths=[discussions_phase_to_dir[\"project_specification\"] / \"merged.json\"])\n",
    "print(f\"Number of prior summaries: {len(tools_selection_prior_summaries)}\")\n",
    "\n",
    "# Tools selection - discussion\n",
    "for iteration_num in range(num_iterations):\n",
    "    save_name = f\"discussion_{iteration_num + 1}\"\n",
    "    try:\n",
    "        print(f\"🟡 Starting meeting {save_name}\")\n",
    "        run_meeting(\n",
    "            meeting_type=\"team\",\n",
    "            team_lead=principal_investigator,\n",
    "            team_members=team_members,\n",
    "            summaries=tools_selection_prior_summaries,\n",
    "            agenda=tools_selection_agenda,\n",
    "            agenda_questions=tools_selection_questions,\n",
    "            save_dir=discussions_phase_to_dir[\"tools_selection\"],\n",
    "            save_name=f\"discussion_{iteration_num + 1}\",\n",
    "            temperature=CREATIVE_TEMPERATURE,\n",
    "            num_rounds=num_rounds,\n",
    "        )\n",
    "        print(f\"✅ Finished meeting {save_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Meeting {save_name} failed with error: {e}\")\n",
    "\n",
    "# Tools selection - merge\n",
    "tools_selection_summaries = load_summaries(\n",
    "    discussion_paths=list(discussions_phase_to_dir[\"tools_selection\"].glob(\"discussion_*.json\")))\n",
    "print(f\"Number of summaries: {len(tools_selection_summaries)}\")\n",
    "\n",
    "tools_selection_merge_prompt = create_merge_prompt(\n",
    "    agenda=tools_selection_agenda,\n",
    "    agenda_questions=tools_selection_questions,\n",
    ")\n",
    "\n",
    "run_meeting(\n",
    "    meeting_type=\"individual\",\n",
    "    team_member=principal_investigator,\n",
    "    summaries=tools_selection_summaries,\n",
    "    agenda=tools_selection_merge_prompt,\n",
    "    save_dir=discussions_phase_to_dir[\"tools_selection\"],\n",
    "    save_name=\"merged\",\n",
    "    temperature=CONSISTENT_TEMPERATURE,\n",
    "    num_rounds=num_rounds,\n",
    ")\n",
    "\n",
    "# Show merged meeting output for tool_selection\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "with open(\"discussions/tool_selection/merged.md\", \"r\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "display(Markdown(content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33b1813",
   "metadata": {},
   "source": [
    "## Implementation -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e5e1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of prior summaries: 3\n",
      "🟡 Starting meeting discussion_1\n",
      "DEBUGGING: Individual meeting members = [Principal Investigator, Scientific Critic]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team:   0%|          | 0/2 [00:12<?, ?it/s]1 [00:00<?, ?it/s]\n",
      "Rounds (+ Final Round): 100%|██████████| 1/1 [00:12<00:00, 13.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 2,634\n",
      "Output token count: 376\n",
      "Tool token count: 0\n",
      "Max token length: 3,010\n",
      "Cost: $0.01\n",
      "Time: 0:15\n",
      "✅ Finished meeting discussion_1\n",
      "🟡 Starting meeting discussion_2\n",
      "DEBUGGING: Individual meeting members = [Principal Investigator, Scientific Critic]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team:   0%|          | 0/2 [00:13<?, ?it/s]1 [00:00<?, ?it/s]\n",
      "Rounds (+ Final Round): 100%|██████████| 1/1 [00:13<00:00, 13.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 2,634\n",
      "Output token count: 534\n",
      "Tool token count: 0\n",
      "Max token length: 3,168\n",
      "Cost: $0.01\n",
      "Time: 0:14\n",
      "✅ Finished meeting discussion_2\n",
      "🟡 Starting meeting discussion_3\n",
      "DEBUGGING: Individual meeting members = [Principal Investigator, Scientific Critic]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team:   0%|          | 0/2 [00:14<?, ?it/s]1 [00:00<?, ?it/s]\n",
      "Rounds (+ Final Round): 100%|██████████| 1/1 [00:14<00:00, 14.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 2,634\n",
      "Output token count: 415\n",
      "Tool token count: 0\n",
      "Max token length: 3,049\n",
      "Cost: $0.01\n",
      "Time: 0:15\n",
      "✅ Finished meeting discussion_3\n",
      "🟡 Starting meeting discussion_4\n",
      "DEBUGGING: Individual meeting members = [Principal Investigator, Scientific Critic]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team:   0%|          | 0/2 [00:16<?, ?it/s]1 [00:00<?, ?it/s]\n",
      "Rounds (+ Final Round): 100%|██████████| 1/1 [00:16<00:00, 16.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 2,634\n",
      "Output token count: 424\n",
      "Tool token count: 0\n",
      "Max token length: 3,058\n",
      "Cost: $0.01\n",
      "Time: 0:17\n",
      "✅ Finished meeting discussion_4\n",
      "🟡 Starting meeting discussion_5\n",
      "DEBUGGING: Individual meeting members = [Principal Investigator, Scientific Critic]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team:   0%|          | 0/2 [00:09<?, ?it/s]1 [00:00<?, ?it/s]\n",
      "Rounds (+ Final Round): 100%|██████████| 1/1 [00:09<00:00,  9.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 2,634\n",
      "Output token count: 465\n",
      "Tool token count: 0\n",
      "Max token length: 3,099\n",
      "Cost: $0.01\n",
      "Time: 0:11\n",
      "✅ Finished meeting discussion_5\n",
      "Number of summaries: 5\n",
      "DEBUGGING: Individual meeting members = [Principal Investigator, Scientific Critic]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team:   0%|          | 0/2 [00:29<?, ?it/s]1 [00:00<?, ?it/s]\n",
      "Rounds (+ Final Round): 100%|██████████| 1/1 [00:29<00:00, 29.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 2,659\n",
      "Output token count: 630\n",
      "Tool token count: 0\n",
      "Max token length: 3,289\n",
      "Cost: $0.01\n",
      "Time: 0:31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Implementation - prompts\n",
    "implementation_agent_selection_agenda = f\"{background_prompt} {project_specific_prompt} Your team needs to build three components of a nanobody design pipeline: BioBERT/ClinicalBERT, SNOMED CT APIs, Plotly/Dash (or D3.js), and SHAP or LIME. For each component, please select the team member who will implement the component. A team member may implement more than one component.\"\n",
    "\n",
    "implementation_agent_selection_questions = (\n",
    "    \"Which team member will implement BioBERT/ClinicalBERT?\",\n",
    "    \"Which team member will implement SNOMED CT APIs?\",\n",
    "    \"Which team member will implement Plotly/Dash (or D3.js)?\",\n",
    "    \"Which team member will implement SHAP or LIME?\",\n",
    ")\n",
    "\n",
    "implementation_agent_selection_prior_summaries = load_summaries(\n",
    "    discussion_paths=[discussions_phase_to_dir[\"team_selection\"] / \"merged.json\",\n",
    "                      discussions_phase_to_dir[\"project_specification\"] / \"merged.json\",\n",
    "                      discussions_phase_to_dir[\"tools_selection\"] / \"merged.json\"])\n",
    "print(f\"Number of prior summaries: {len(implementation_agent_selection_prior_summaries)}\")\n",
    "\n",
    "# Implementation - discussion\n",
    "for iteration_num in range(num_iterations):\n",
    "    save_name = f\"discussion_{iteration_num + 1}\"\n",
    "    try:\n",
    "        print(f\"🟡 Starting meeting {save_name}\")\n",
    "        run_meeting(\n",
    "            meeting_type=\"individual\",\n",
    "            team_member=principal_investigator,\n",
    "            summaries=implementation_agent_selection_prior_summaries,\n",
    "            agenda=implementation_agent_selection_agenda,\n",
    "            agenda_questions=implementation_agent_selection_questions,\n",
    "            save_dir=discussions_phase_to_dir[\"implementation_agent_selection\"],\n",
    "            save_name=f\"discussion_{iteration_num + 1}\",\n",
    "            temperature=CREATIVE_TEMPERATURE,\n",
    "        )\n",
    "        print(f\"✅ Finished meeting {save_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Meeting {save_name} failed with error: {e}\")\n",
    "\n",
    "# Implementation - merge\n",
    "implementation_agent_selection_summaries = load_summaries(\n",
    "    discussion_paths=list(discussions_phase_to_dir[\"implementation_agent_selection\"].glob(\"discussion_*.json\")))\n",
    "print(f\"Number of summaries: {len(implementation_agent_selection_summaries)}\")\n",
    "\n",
    "implementation_agent_selection_merge_prompt = create_merge_prompt(\n",
    "    agenda=implementation_agent_selection_agenda,\n",
    "    agenda_questions=implementation_agent_selection_questions\n",
    ")\n",
    "\n",
    "run_meeting(\n",
    "    meeting_type=\"individual\",\n",
    "    team_member=principal_investigator,\n",
    "    summaries=implementation_agent_selection_summaries,\n",
    "    agenda=implementation_agent_selection_merge_prompt,\n",
    "    save_dir=discussions_phase_to_dir[\"implementation_agent_selection\"],\n",
    "    save_name=\"merged\",\n",
    "    temperature=CONSISTENT_TEMPERATURE,\n",
    ")\n",
    "\n",
    "# Show merged meeting output for implementation_agent_selection\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "with open(\"discussions/implementation_agent_selection/merged.md\", \"r\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "display(Markdown(content))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
