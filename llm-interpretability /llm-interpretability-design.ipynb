{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2653f11",
   "metadata": {},
   "source": [
    "# virtual-lab Implementation\n",
    "## Objective: \n",
    "Create a method and implementation for a software used for clincian LLM interpretability in the context of automatic electronic phenotyping using an LLM\n",
    "\n",
    "## Steps (from VL paper w/ slight edits)\n",
    "1. Team selection: An individual meeting with the PI to define a set of scientist agents to work on the project.\n",
    "2. Project specification: A team meeting to specify the project direction by deciding on key high-level details.\n",
    "3. Team Fine-tuning: Send each team member to read new pubmed articles relavent to their role and personal objective.\n",
    "4. Project Fine-tuning: Once the team members know their place and understand the field better, the project specifications is re-aligned before creating tools.\n",
    "5. Tools selection: A team meeting to brainstorm machine learning and/or computational tools for llm interpretability design.\n",
    "6. Tools implementation: A series of individual meetings with different scientist agents to implement their components individually. \n",
    "7. Workflow design: An individual meeting with the PI to determine the workflow for applying the tool implementations.\n",
    "\n",
    "<img src=\"images/steps.png\" style=\"display: block; margin: auto;\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4049f2c8",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d55698c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from virtual_lab.constants import CONSISTENT_TEMPERATURE, CREATIVE_TEMPERATURE\n",
    "from virtual_lab.prompts import (\n",
    "    CODING_RULES,\n",
    "    REWRITE_PROMPT,\n",
    "    create_merge_prompt,\n",
    ")\n",
    "from virtual_lab.run_meeting import run_meeting\n",
    "from virtual_lab.utils import load_summaries\n",
    "\n",
    "from interpretability_constants import (\n",
    "    background_prompt,\n",
    "    nanobody_prompt,\n",
    "    num_iterations,\n",
    "    num_rounds,\n",
    "    discussions_phase_to_dir,\n",
    "    principal_investigator,\n",
    "    team_members,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd6b27a",
   "metadata": {},
   "source": [
    "## Team Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "386bec7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUGGING: Individual meeting members = [Principal Investigator, Scientific Critic]\n",
      "DEBUGGING: Individual meeting members = [Principal Investigator, Scientific Critic]\n",
      "DEBUGGING: Individual meeting members = [Principal Investigator, Scientific Critic]\n",
      "DEBUGGING: Individual meeting members = [Principal Investigator, Scientific Critic]\n",
      "DEBUGGING: Individual meeting members = [Principal Investigator, Scientific Critic]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rounds (+ Final Round):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Team:   0%|          | 0/2 [00:08<?, ?it/s]\n",
      "Rounds (+ Final Round): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 245\n",
      "Output token count: 275\n",
      "Tool token count: 0\n",
      "Max token length: 520\n",
      "Cost: $0.00\n",
      "Time: 0:09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team:   0%|          | 0/2 [00:09<?, ?it/s]\n",
      "\n",
      "Rounds (+ Final Round): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 245\n",
      "Output token count: 297\n",
      "Tool token count: 0\n",
      "Max token length: 542\n",
      "Cost: $0.00\n",
      "Time: 0:11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team:   0%|          | 0/2 [00:11<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Rounds (+ Final Round): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 245\n",
      "Output token count: 294\n",
      "Tool token count: 0\n",
      "Max token length: 539\n",
      "Cost: $0.00\n",
      "Time: 0:12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team:   0%|          | 0/2 [00:11<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Rounds (+ Final Round): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 245\n",
      "Output token count: 308\n",
      "Tool token count: 0\n",
      "Max token length: 553\n",
      "Cost: $0.00\n",
      "Time: 0:13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team:   0%|          | 0/2 [00:13<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "Rounds (+ Final Round): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 245\n",
      "Output token count: 287\n",
      "Tool token count: 0\n",
      "Max token length: 532\n",
      "Cost: $0.00\n",
      "Time: 0:15\n",
      "Number of summaries: 5\n",
      "DEBUGGING: Individual meeting members = [Principal Investigator, Scientific Critic]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team:   0%|          | 0/2 [00:11<?, ?it/s]1 [00:00<?, ?it/s]\n",
      "Rounds (+ Final Round): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 1,856\n",
      "Output token count: 529\n",
      "Tool token count: 0\n",
      "Max token length: 2,385\n",
      "Cost: $0.01\n",
      "Time: 0:12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Team selection - prompts\n",
    "team_selection_agenda = f\"\"\"{background_prompt} You need to select a team of three scientists to help you with this project. Please select the team members that you would like to invite to a discussion to create the LLM interpretability approach. Please list the team members in the following format, using the team member below as an example. You should not include yourself (Principal Investigator) in the list.\n",
    "\n",
    "Agent(\n",
    "    title=\"Principal Investigator\",\n",
    "    expertise=\"applying artificial intelligence to biomedical research\",\n",
    "    goal=\"perform research in your area of expertise that maximizes the scientific impact of the work\",\n",
    "    role=\"lead a team of experts to solve an important problem in artificial intelligence for biomedicine, make key decisions about the project direction based on team member input, and manage the project timeline and resources\",\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# Team selection - discussion\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    concurrent.futures.wait([\n",
    "        executor.submit(\n",
    "            run_meeting,\n",
    "            meeting_type=\"individual\",\n",
    "            team_member=principal_investigator,\n",
    "            agenda=team_selection_agenda,\n",
    "            save_dir=discussions_phase_to_dir[\"team_selection\"],\n",
    "            save_name=f\"discussion_{iteration_num + 1}\",\n",
    "            temperature=CREATIVE_TEMPERATURE,\n",
    "        ) for iteration_num in range(num_iterations)\n",
    "    ])\n",
    "\n",
    "# Team selection - merge\n",
    "team_selection_summaries = load_summaries(\n",
    "    discussion_paths=list(discussions_phase_to_dir[\"team_selection\"].glob(\"discussion_*.json\")))\n",
    "print(f\"Number of summaries: {len(team_selection_summaries)}\")\n",
    "\n",
    "team_selection_merge_prompt = create_merge_prompt(agenda=team_selection_agenda)\n",
    "\n",
    "run_meeting(\n",
    "    meeting_type=\"individual\",\n",
    "    team_member=principal_investigator,\n",
    "    summaries=team_selection_summaries,\n",
    "    agenda=team_selection_merge_prompt,\n",
    "    save_dir=discussions_phase_to_dir[\"team_selection\"],\n",
    "    save_name=\"merged\",\n",
    "    temperature=CONSISTENT_TEMPERATURE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f28a14a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## User\n",
       "\n",
       "This is the beginning of an individual meeting with Principal Investigator to discuss your research project.\n",
       "\n",
       "Here are summaries of the previous meetings:\n",
       "\n",
       "[begin summary 1]\n",
       "\n",
       "To address the challenge of developing a tool for large language model interpretability in the context of electronic phenotype definitions, I propose forming a team with diverse expertise spanning natural language processing, biomedical informatics, and visualization. Here are the team members I recommend:\n",
       "\n",
       "1. Agent(\n",
       "    title=\"NLP Specialist\",\n",
       "    expertise=\"natural language processing and computational linguistics\",\n",
       "    goal=\"enhance the interpretability of large language models by developing algorithms and techniques that elucidate model decision-making\",\n",
       "    role=\"design and implement interpretability methods for LLMs, focusing on understanding and explaining model outputs relevant to phenotype definitions\",\n",
       ")\n",
       "\n",
       "2. Agent(\n",
       "    title=\"Biomedical Informatics Expert\",\n",
       "    expertise=\"biomedical informatics and electronic health records\",\n",
       "    goal=\"ensure the accurate translation of clinical concepts into computational phenotype definitions and validate model outputs against biomedical data\",\n",
       "    role=\"provide insight into clinical data interpretation, guide the integration of phenotype definitions, and collaborate on validating model findings with clinical experts\",\n",
       ")\n",
       "\n",
       "3. Agent(\n",
       "    title=\"Visualization Scientist\",\n",
       "    expertise=\"data visualization and user interface design\",\n",
       "    goal=\"create visual tools that foster trust and understanding between clinicians and models through intuitive data representation\",\n",
       "    role=\"develop interactive visualization components that convey model reasoning and outputs clearly to clinicians, enhancing interpretability and usability\",\n",
       ")\n",
       "\n",
       "I believe this team composition will maximize our ability to develop a robust and trusted interpretability tool, leveraging each memberâ€™s unique expertise to address the complex challenges inherent in this project.\n",
       "\n",
       "[end summary 1]\n",
       "\n",
       "[begin summary 2]\n",
       "\n",
       "To effectively tackle the challenge of developing a tool for large language model (LLM) interpretability, particularly in the context of creating electronic phenotype definitions with a visual component, it is essential to assemble a diverse team with expertise in various relevant areas. Here are the proposed team members who have the knowledge and skills that will be instrumental in this project:\n",
       "\n",
       "1. Agent(\n",
       "    title=\"Senior Data Scientist\",\n",
       "    expertise=\"machine learning and natural language processing (NLP)\",\n",
       "    goal=\"design and implement algorithms for interpreting and explaining LLM outputs\",\n",
       "    role=\"develop NLP methods to enhance LLM interpretability and collaborate on integrating visual tools for clinician interaction\",\n",
       ")\n",
       "\n",
       "2. Agent(\n",
       "    title=\"Clinical Informatics Specialist\",\n",
       "    expertise=\"biomedical data and electronic health records (EHR)\",\n",
       "    goal=\"ensure the tool's clinical relevance and utility by incorporating real-world clinical data and practices\",\n",
       "    role=\"provide insight into the clinical application of phenotype definitions and validate the model's outputs against EHR data\",\n",
       ")\n",
       "\n",
       "3. Agent(\n",
       "    title=\"Visual Analytics Expert\",\n",
       "    expertise=\"data visualization and user interface design\",\n",
       "    goal=\"create visual tools that improve model transparency and trust for clinicians\",\n",
       "    role=\"develop interactive visual interfaces that allow clinicians to explore and understand the model's decision-making process\",\n",
       ")\n",
       "\n",
       "These team members collectively bring the necessary expertise to address both the technical and practical aspects of the project, ensuring that the final tool is both scientifically robust and clinically applicable.\n",
       "\n",
       "[end summary 2]\n",
       "\n",
       "[begin summary 3]\n",
       "\n",
       "To effectively tackle the research project on developing a tool for large language model (LLM) interpretability in electronic phenotype definitions, we'll need a diverse team with expertise in machine learning, biomedical informatics, and data visualization. Here is the selection of team members I propose for the initial discussion:\n",
       "\n",
       "Agent(\n",
       "    title=\"Machine Learning Scientist\",\n",
       "    expertise=\"large language models and natural language processing\",\n",
       "    goal=\"develop algorithms for interpreting LLM outputs and enhancing their transparency\",\n",
       "    role=\"design and implement machine learning models that can interpret LLMs in the biomedical context\",\n",
       ")\n",
       "\n",
       "Agent(\n",
       "    title=\"Biomedical Informatics Specialist\",\n",
       "    expertise=\"electronic health records and phenotype definitions\",\n",
       "    goal=\"bridge the gap between clinical needs and computational tools by providing domain knowledge\",\n",
       "    role=\"ensure that the LLM interpretability approach aligns with clinical realities and can be effectively integrated into healthcare workflows\",\n",
       ")\n",
       "\n",
       "Agent(\n",
       "    title=\"Data Visualization Expert\",\n",
       "    expertise=\"creating visual tools to interpret complex data\",\n",
       "    goal=\"develop intuitive visualizations that enhance the understanding and trust of LLM outputs among clinicians\",\n",
       "    role=\"design and implement visual perspectives to present LLM interpretations clearly and effectively to end-users\",\n",
       ")\n",
       "\n",
       "These team members bring a blend of technical acumen and domain-specific knowledge that will be crucial in creating a clinically meaningful and trustworthy interpretability tool for LLMs. I look forward to discussing the project direction and strategies with them.\n",
       "\n",
       "[end summary 3]\n",
       "\n",
       "[begin summary 4]\n",
       "\n",
       "To successfully develop a tool for LLM interpretability in the context of creating electronic phenotype definitions, while also incorporating a visual perspective, we need a diverse team of experts who bring complementary skills to the project. Here is my proposed list of team members:\n",
       "\n",
       "1. **Agent(\n",
       "    title=\"Machine Learning Scientist\",\n",
       "    expertise=\"large language models and natural language processing\",\n",
       "    goal=\"develop and refine algorithms to enhance LLM interpretability and performance\",\n",
       "    role=\"design and implement algorithms to improve model transparency, and collaborate with other team members to integrate these solutions into the interpretability tool\",\n",
       ")**\n",
       "\n",
       "2. **Agent(\n",
       "    title=\"Clinical Informatics Specialist\",\n",
       "    expertise=\"electronic health records and phenotype definitions\",\n",
       "    goal=\"ensure clinical relevance and accuracy of phenotype definitions created by the LLM\",\n",
       "    role=\"bridge the gap between clinical knowledge and machine learning models, validate phenotype definitions, and provide clinical context for interpretability solutions\",\n",
       ")**\n",
       "\n",
       "3. **Agent(\n",
       "    title=\"Data Visualization Expert\",\n",
       "    expertise=\"visual analytics and user interface design\",\n",
       "    goal=\"create intuitive visualizations that foster clinician trust and enhance model interpretability\",\n",
       "    role=\"develop visualization techniques to represent LLM outputs and their decision-making processes, ensuring these are easily understandable by clinicians\",\n",
       ")**\n",
       "\n",
       "This team covers the necessary expertise in machine learning, clinical relevance, and data visualization, allowing us to address both the technical and user-centric aspects of the project comprehensively. Let me know if you have any questions or need further elaboration on the team selection.\n",
       "\n",
       "[end summary 4]\n",
       "\n",
       "[begin summary 5]\n",
       "\n",
       "For this project focused on large language model (LLM) interpretability for electronic phenotype definitions, incorporating both software techniques and a visual perspective, it is crucial to assemble a team with diverse expertise in AI, biomedical informatics, and user interface design. Here's the proposed team of three scientists:\n",
       "\n",
       "1. Agent(\n",
       "    title=\"Machine Learning Scientist\",\n",
       "    expertise=\"natural language processing and deep learning\",\n",
       "    goal=\"develop novel algorithms for interpretability of large language models\",\n",
       "    role=\"design and implement LLM interpretability techniques and validate their performance in the context of electronic phenotype definitions\",\n",
       ")\n",
       "\n",
       "2. Agent(\n",
       "    title=\"Biomedical Informatician\",\n",
       "    expertise=\"clinical data analysis and electronic health records\",\n",
       "    goal=\"ensure that the LLM interpretability approaches are clinically relevant and effective\",\n",
       "    role=\"provide domain knowledge for electronic phenotype definitions and assist in evaluating the interpretability of LLMs with respect to clinical applications\",\n",
       ")\n",
       "\n",
       "3. Agent(\n",
       "    title=\"User Interface Designer\",\n",
       "    expertise=\"human-computer interaction and visualization\",\n",
       "    goal=\"create intuitive and trustworthy visualizations of LLM outputs for clinicians\",\n",
       "    role=\"design and test user interfaces that enhance clinician trust and understanding of LLM-generated electronic phenotype definitions through visual aids\",\n",
       ")\n",
       "\n",
       "These team members will bring a well-rounded set of skills to address both the technical and user-focused aspects of the project.\n",
       "\n",
       "[end summary 5]\n",
       "\n",
       "Here is the agenda for the meeting:\n",
       "\n",
       "Please read the summaries of multiple separate meetings about the same agenda. Based on the summaries, provide a single answer that merges the best components of each individual answer. Please use the same format as the individual answers. Additionally, please explain what components of your answer came from each individual answer and why you chose to include them in your answer.\n",
       "\n",
       "As a reference, here is the agenda from those meetings, which must be addressed here as well:\n",
       "\n",
       "You are working on a research project to use software techniques to develop a tool for large language model (LLM) interpretability in the context of creating electronic phenotype definitions, ideally, also incorporating a visual perspective to foster trust between the clinician and the model. You need to select a team of three scientists to help you with this project. Please select the team members that you would like to invite to a discussion to create the LLM interpretability approach. Please list the team members in the following format, using the team member below as an example. You should not include yourself (Principal Investigator) in the list.\n",
       "\n",
       "Agent(\n",
       "    title=\"Principal Investigator\",\n",
       "    expertise=\"applying artificial intelligence to biomedical research\",\n",
       "    goal=\"perform research in your area of expertise that maximizes the scientific impact of the work\",\n",
       "    role=\"lead a team of experts to solve an important problem in artificial intelligence for biomedicine, make key decisions about the project direction based on team member input, and manage the project timeline and resources\",\n",
       ")\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "Principal Investigator, please provide your response to the agenda.\n",
       "\n",
       "## Principal Investigator\n",
       "\n",
       "Based on the summaries provided, I have synthesized the best components from each meeting to form a cohesive team that will effectively address the project goals of developing a tool for LLM interpretability in electronic phenotype definitions with a visual component. Here is the proposed team:\n",
       "\n",
       "1. **Agent(\n",
       "    title=\"Machine Learning Scientist\",\n",
       "    expertise=\"large language models, natural language processing, and deep learning\",\n",
       "    goal=\"develop and refine algorithms to enhance LLM interpretability and performance\",\n",
       "    role=\"design and implement novel interpretability techniques for LLMs, focusing on transparency and validation in the context of electronic phenotype definitions\",\n",
       ")**\n",
       "\n",
       "   - **Reason for inclusion**: This role is consistently highlighted across all summaries as crucial for developing the core algorithms that will drive the interpretability of LLMs. The emphasis on both NLP and deep learning expertise ensures a comprehensive approach to model development (Summary 1, 3, 4, 5).\n",
       "\n",
       "2. **Agent(\n",
       "    title=\"Biomedical Informatics Specialist\",\n",
       "    expertise=\"electronic health records, clinical data analysis, and phenotype definitions\",\n",
       "    goal=\"ensure clinical relevance and accuracy of phenotype definitions created by the LLM\",\n",
       "    role=\"bridge the gap between clinical needs and computational tools, validate phenotype definitions, and provide clinical context for interpretability solutions\",\n",
       ")**\n",
       "\n",
       "   - **Reason for inclusion**: This role is essential for ensuring that the interpretability tool is grounded in clinical reality and effectively integrates with healthcare workflows. The focus on bridging clinical knowledge with computational tools is a recurring theme in all summaries (Summary 1, 2, 3, 4, 5).\n",
       "\n",
       "3. **Agent(\n",
       "    title=\"Visualization Scientist\",\n",
       "    expertise=\"data visualization, user interface design, and human-computer interaction\",\n",
       "    goal=\"create intuitive visualizations that foster clinician trust and enhance model interpretability\",\n",
       "    role=\"develop interactive visual interfaces and visualization techniques to represent LLM outputs clearly and effectively to clinicians\",\n",
       ")**\n",
       "\n",
       "   - **Reason for inclusion**: The need for a visualization expert is emphasized in all summaries to ensure that the interpretability tool is not only technically robust but also user-friendly and trustworthy. The focus on creating intuitive visualizations aligns with the project's goal of fostering trust between clinicians and the model (Summary 1, 2, 3, 4, 5).\n",
       "\n",
       "This team composition leverages the strengths identified in each summary, ensuring a balanced approach that addresses both the technical and practical aspects of the project. The inclusion of experts in machine learning, biomedical informatics, and visualization ensures that the tool will be scientifically robust, clinically relevant, and user-friendly.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show merged meeting output for team selection\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "with open(\"discussions/team_selection/merged.md\", \"r\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "display(Markdown(content))\n",
    "\n",
    "# Manually imported the chosen team members into interpretability_constants.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5586ada2",
   "metadata": {},
   "source": [
    "## Project Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ea37105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleared 2 discussion files from discussions/project_specification\n",
      "ðŸŸ¡ Starting meeting discussion_1\n",
      "DEBUGGING: Entering a team meeting...\n",
      "the team lead is:\n",
      "Principal Investigator\n",
      "and the team members are:\n",
      "(Computational Linguist, Biomedical Informatics Specialist, Data Visualization Expert, Scientific Critic)\n",
      "\n",
      "DEBUGGING: Team meeting members = [Principal Investigator, Computational Linguist, Biomedical Informatics Specialist, Data Visualization Expert, Scientific Critic]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:52<00:00, 10.45s/it]<?, ?it/s]\n",
      "Team: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:56<00:00, 11.20s/it]<02:36, 52.24s/it]\n",
      "Team: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:51<00:00, 10.32s/it]<01:48, 54.46s/it]\n",
      "Team:   0%|          | 0/5 [00:19<?, ?it/s]4 [02:39<00:53, 53.15s/it]\n",
      "Rounds (+ Final Round): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [02:59<00:00, 44.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 54,517\n",
      "Output token count: 5,624\n",
      "Tool token count: 0\n",
      "Max token length: 7,580\n",
      "Cost: $0.19\n",
      "Time: 3:02\n",
      "âœ… Finished meeting discussion_1\n",
      "ðŸŸ¡ Starting meeting discussion_2\n",
      "DEBUGGING: Entering a team meeting...\n",
      "the team lead is:\n",
      "Principal Investigator\n",
      "and the team members are:\n",
      "(Computational Linguist, Biomedical Informatics Specialist, Data Visualization Expert, Scientific Critic)\n",
      "\n",
      "DEBUGGING: Team meeting members = [Principal Investigator, Computational Linguist, Biomedical Informatics Specialist, Data Visualization Expert, Scientific Critic]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:50<00:00, 10.18s/it]<?, ?it/s]\n",
      "Team: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:54<00:00, 10.90s/it]<02:32, 50.92s/it]\n",
      "Team: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:00<00:00, 12.01s/it]<01:46, 53.04s/it]\n",
      "Team:   0%|          | 0/5 [00:15<?, ?it/s]4 [02:45<00:56, 56.24s/it]\n",
      "Rounds (+ Final Round): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [03:00<00:00, 45.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 60,950\n",
      "Output token count: 6,471\n",
      "Tool token count: 0\n",
      "Max token length: 8,427\n",
      "Cost: $0.22\n",
      "Time: 3:03\n",
      "âœ… Finished meeting discussion_2\n",
      "ðŸŸ¡ Starting meeting discussion_3\n",
      "DEBUGGING: Entering a team meeting...\n",
      "the team lead is:\n",
      "Principal Investigator\n",
      "and the team members are:\n",
      "(Computational Linguist, Biomedical Informatics Specialist, Data Visualization Expert, Scientific Critic)\n",
      "\n",
      "DEBUGGING: Team meeting members = [Principal Investigator, Computational Linguist, Biomedical Informatics Specialist, Data Visualization Expert, Scientific Critic]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:52<00:00, 10.57s/it]<?, ?it/s]\n",
      "Team: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:03<00:00, 12.64s/it]<02:38, 52.86s/it]\n",
      "Team: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:02<00:00, 12.43s/it]<01:57, 58.93s/it]\n",
      "Team:   0%|          | 0/5 [00:17<?, ?it/s]4 [02:58<01:00, 60.40s/it]\n",
      "Rounds (+ Final Round): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [03:15<00:00, 48.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 62,656\n",
      "Output token count: 6,592\n",
      "Tool token count: 0\n",
      "Max token length: 8,548\n",
      "Cost: $0.22\n",
      "Time: 3:18\n",
      "âœ… Finished meeting discussion_3\n",
      "ðŸŸ¡ Starting meeting discussion_4\n",
      "DEBUGGING: Entering a team meeting...\n",
      "the team lead is:\n",
      "Principal Investigator\n",
      "and the team members are:\n",
      "(Computational Linguist, Biomedical Informatics Specialist, Data Visualization Expert, Scientific Critic)\n",
      "\n",
      "DEBUGGING: Team meeting members = [Principal Investigator, Computational Linguist, Biomedical Informatics Specialist, Data Visualization Expert, Scientific Critic]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:53<00:00, 10.62s/it]<?, ?it/s]\n",
      "Team: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:49<00:00,  9.80s/it]<02:39, 53.08s/it]\n",
      "Team: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:53<00:00, 10.61s/it]<01:41, 50.68s/it]\n",
      "Team:   0%|          | 0/5 [00:23<?, ?it/s]4 [02:35<00:51, 51.76s/it]\n",
      "Rounds (+ Final Round): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [02:58<00:00, 44.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 62,626\n",
      "Output token count: 6,695\n",
      "Tool token count: 0\n",
      "Max token length: 8,651\n",
      "Cost: $0.22\n",
      "Time: 3:01\n",
      "âœ… Finished meeting discussion_4\n",
      "ðŸŸ¡ Starting meeting discussion_5\n",
      "DEBUGGING: Entering a team meeting...\n",
      "the team lead is:\n",
      "Principal Investigator\n",
      "and the team members are:\n",
      "(Computational Linguist, Biomedical Informatics Specialist, Data Visualization Expert, Scientific Critic)\n",
      "\n",
      "DEBUGGING: Team meeting members = [Principal Investigator, Computational Linguist, Biomedical Informatics Specialist, Data Visualization Expert, Scientific Critic]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:53<00:00, 10.62s/it]<?, ?it/s]\n",
      "Team: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:56<00:00, 11.31s/it]<02:39, 53.13s/it]\n",
      "Team: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:55<00:00, 11.12s/it]<01:50, 55.13s/it]\n",
      "Team:   0%|          | 0/5 [00:25<?, ?it/s]4 [02:45<00:55, 55.34s/it]\n",
      "Rounds (+ Final Round): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [03:10<00:00, 47.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 62,361\n",
      "Output token count: 6,874\n",
      "Tool token count: 0\n",
      "Max token length: 8,830\n",
      "Cost: $0.22\n",
      "Time: 3:13\n",
      "âœ… Finished meeting discussion_5\n",
      "Number of summaries: 5\n",
      "DEBUGGING: Individual meeting members = [Principal Investigator, Scientific Critic]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:28<00:00, 14.49s/it]<?, ?it/s]\n",
      "Team: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:24<00:00, 12.34s/it]<01:26, 28.98s/it]\n",
      "Team: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:24<00:00, 12.26s/it]<00:52, 26.45s/it]\n",
      "Team:   0%|          | 0/2 [00:12<?, ?it/s]4 [01:18<00:25, 25.57s/it]\n",
      "Rounds (+ Final Round): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [01:30<00:00, 22.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 50,941\n",
      "Output token count: 4,877\n",
      "Tool token count: 0\n",
      "Max token length: 10,379\n",
      "Cost: $0.18\n",
      "Time: 1:32\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "def clear_discussion_files(save_dir: Path):\n",
    "    json_files = glob.glob(str(save_dir / \"discussion_*.json\"))\n",
    "    md_files = glob.glob(str(save_dir / \"discussion_*.md\"))\n",
    "    for f in json_files + md_files:\n",
    "        os.remove(f)\n",
    "    print(f\"Cleared {len(json_files) + len(md_files)} discussion files from {save_dir}\")\n",
    "\n",
    "clear_discussion_files(discussions_phase_to_dir[\"project_specification\"])\n",
    "\n",
    "# Project specification - prompts\n",
    "project_specification_agenda = f\"{background_prompt} Please create a software design approach to solve this problem. Decide whether you will take a machine learning approach or not. For your choice, decide whether you will use open source interpretability libraries from GitHub or create your own completely from scratch. If modifying existing libraries, please specify which interpretability libraries to build upon to create an interpretability tool that conveys interpretability information visually so the clinician can trust it with ease. If designing algorithms from scratch, please describe how you propose new algorithms. Consider methods for eliminating LLM hallucinations using RAG or similar, increasing faithfulness and reasoning, and promote valid chain of thought logic using the SNOMED Database, which we have access to.\" \n",
    "\n",
    "project_specification_questions = (\n",
    "    \"Will you take a machine learning approach or not?\",\n",
    "    \"Will you use open source interpretability libraries from GitHub or create your own completely from scratch? (choose only one)?\",\n",
    "    \"If modifying existing libraries, which interpretability libraries to build upon (please list 3-4)?\",\n",
    "    \"If designing algorithms from scratch, how exactly will you propose new algorithms?\",\n",
    "    \"How will the interpretability tool use methods for eliminating LLM hallucinations, increasing faithfulness and reasoning, and promote valid chain of thought logic using the SNOMED Database, which we have access to?\",\n",
    ") \n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Project specification - discussion\n",
    "for i in range(num_iterations):\n",
    "    save_name = f\"discussion_{i + 1}\"\n",
    "    try:\n",
    "        print(f\"ðŸŸ¡ Starting meeting {save_name}\")\n",
    "        run_meeting(\n",
    "            meeting_type=\"team\",\n",
    "            team_lead=principal_investigator,\n",
    "            team_members=team_members,\n",
    "            agenda=project_specification_agenda,\n",
    "            agenda_questions=project_specification_questions,\n",
    "            save_dir=discussions_phase_to_dir[\"project_specification\"],\n",
    "            save_name=save_name,\n",
    "            temperature=CREATIVE_TEMPERATURE,\n",
    "            num_rounds=num_rounds,\n",
    "        )\n",
    "        print(f\"âœ… Finished meeting {save_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Meeting {save_name} failed with error: {e}\")\n",
    "\n",
    "\n",
    "# Project specification - merge\n",
    "project_specification_summaries = load_summaries(\n",
    "    discussion_paths=list(discussions_phase_to_dir[\"project_specification\"].glob(\"discussion_*.json\")))\n",
    "print(f\"Number of summaries: {len(project_specification_summaries)}\")\n",
    "\n",
    "project_specification_merge_prompt = create_merge_prompt(\n",
    "    agenda=project_specification_agenda,\n",
    "    agenda_questions=project_specification_questions,\n",
    ")\n",
    "\n",
    "run_meeting(\n",
    "    meeting_type=\"individual\",\n",
    "    team_member=principal_investigator,\n",
    "    summaries=project_specification_summaries,\n",
    "    agenda=project_specification_merge_prompt,\n",
    "    save_dir=discussions_phase_to_dir[\"project_specification\"],\n",
    "    save_name=\"merged\",\n",
    "    temperature=CONSISTENT_TEMPERATURE,\n",
    "    num_rounds=num_rounds,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca76bd6",
   "metadata": {},
   "source": [
    "## Reload\n",
    "Note: since the team selection output faulty code I had to debug this for a while trying to figure out why team meetings were not running, then I realized the code did not include the argument ```model=model``` so I had to add that for every agent.\n",
    "\n",
    "Use this code to reload the kernel:\n",
    "```python\n",
    "import importlib\n",
    "import interpretability_constants\n",
    "\n",
    "importlib.reload(interpretability_constants)\n",
    "\n",
    "from interpretability_constants import team_members\n",
    "print(\"Reloaded team_members:\", team_members)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51eee92d",
   "metadata": {},
   "source": [
    "## Reload\n",
    "Note: since the team selection output faulty code I had to debug this for a while trying to figure out why team meetings were not running, then I realized the code did not include the argument ```model=model``` so I had to add that for every agent.\n",
    "\n",
    "Use this code to reload the kernel:\n",
    "```python\n",
    "import importlib\n",
    "import interpretability_constants\n",
    "\n",
    "importlib.reload(interpretability_constants)\n",
    "\n",
    "from interpretability_constants import team_members\n",
    "print(\"Reloaded team_members:\", team_members)\n",
    "```\n",
    "\n",
    "## Project Specification Debugging\n",
    "The issue was that only one out of five team meetings was being saved as `.json` and `.md` files during the project specification phase. This was caused by attempting to run all meetings in parallel using `ThreadPoolExecutor`, which led to errors such as \"cannot schedule new futures after shutdown\" and failed runs due to rate limits or resource contention. The fix was to switch from parallel to sequential execution by replacing the thread pool with a simple `for` loop, calling `run_meeting()` one meeting at a time. This ensured each meeting had dedicated resources and time to complete successfully, resulting in all outputs being properly saved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
