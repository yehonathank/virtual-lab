{
    "content": [
        "The significance of liver metastasis (LM) in increasing the risk of death for postoperative colorectal cancer (CRC) patients necessitates innovative approaches to predict LM.",
        "Our study presents a novel and significant contribution by developing an interpretable fusion model that effectively integrates both free\u2010text medical record data and structured laboratory data to predict LM in postoperative CRC patients.",
        "We used a robust dataset of 1463 patients and leveraged state\u2010of\u2010the\u2010art natural language processing (NLP) and machine learning techniques to construct a two\u2010layer fusion framework that demonstrates superior predictive performance compared to single modal models. Our innovative two\u2010tier algorithm fuses the results from different data modalities, achieving balanced prediction results on test data and significantly enhancing the predictive ability of the model. To increase interpretability, we employed Shapley additive explanations to elucidate the contributions of free\u2010text clinical data and structured clinical data to the final model. Furthermore, we translated our findings into practical clinical applications by creating a novel NLP score\u2010based nomogram using the top 13 valid predictors identified in our study.",
        "The proposed fusion models demonstrated superior predictive performance with an accuracy of 80.8%, precision of 80.3%, recall of 80.5%, and an F1 score of 80.8% in predicting LMs.",
        "This fusion model represents a notable advancement in predicting LMs for postoperative CRC patients, offering the potential to enhance patient outcomes and support clinical decision\u2010making.",
        "Colorectal cancer (CRC) is the third most common malignancy worldwide (10.0%) and the second most common cause of cancer\u2010related deaths (9.4%). With the ongoing research on molecular mechanisms of cancer and the joint development of various omics studies, an increasing number of treatment options are now available for local lesions and advanced diseases, thereby improving individualized diagnosis, treatment, and precision medicine. Current treatments for CRC include endoscopic and surgical local excision, downstaging preoperative radiotherapy and systemic therapy, extensive surgery for local and metastatic disease, local ablation of metastases, palliative chemotherapy, targeted therapy, and immunotherapy. These treatments, alone or in combination, significantly improve the survival of CRC patients. The liver is the most common site of postsurgery metastasis, involved in 25%\u201350% of CRC patients during the follow\u2010up period. Liver metastatic lesions detected in the early stage can be removed by surgery, resulting in a better overall prognosis. However, only 25% of the patients are suitable for first\u2010line therapy at the time of CRC liver metastasis (LM) diagnosis, owing to the rapid metastases. As a result, most patients receive second\u2010line chemotherapy as an alternative, associated with greater toxicity and a worse prognosis. Therefore, it has always been a challenge to predict LM in patients with CRC.",
        "Radiological techniques are the most promising for the surveillance of LMs in CRC patients. Experts have developed standards for evaluating liver lesions, such as the Liver Reporting & Data System (LI\u2010RADS\u00ae). However, the frequency at which imaging tests should be performed to prevent postoperative recurrence has been controversial. Although recent studies have shown that 16%\u201326% of liver lesions are too small to be identified or excluded as benign lesions, invasive physical examinations, such as needle biopsies, are not recommended because their benefits may not outweigh the risk and cost to the patients. Moreover, repeated CT scanning may increase the risk of tumor mutation and progression, especially considering the aggressive nature of CRC metastasis. Thus, a valid analytical strategy for assessing and predicting LM in postoperative CRC patients, through which physicians can gain more confidence in determining whether a radiology examination should be scheduled for personalized surveillance of LM, can be attractive in clinical scenarios. In addition, such strategy would promote more efficient use of imaging techniques and improve the overall well\u2010being of CRC patients.",
        "With the rapid development of artificial intelligence (AI) and big data, medical multimodal big\u2010data\u2010driven algorithms have achieved remarkable breakthroughs. Radiomics and pathomics have successfully predicted the prognosis and assessed the risk of metastasis in CRC patients. In a retrospective study by Li et al. on data from 766 patients undergoing LM resection, a neural network model was developed to predict the overall survival (OS) more accurately than the Cox regression model. More recently, Wang et al. reported a multiomics model by combining pathomics, radiomic features, immune scores, and clinical factors into a novel nomogram with outstanding performance in predicting OS (area under the curve [AUC] 0.860) and disease\u2010free survival (AUC 0.875). These breakthroughs inspire future research to develop more advanced AI techniques to improve the overall efficacy of CRC treatment.",
        "Despite significant success in predicting LMs using the multiomic approach, unneglectable barriers hinder the clinical application of those models. For example, the data quality must meet the unified standard set by the model\u2010builder to ensure the consistency of model input, which is difficult to satisfy in real\u2010world clinical scenarios owing to the variation in data acquisition techniques and a lack of comprehensive quality assessment method. Moreover, many patients may not choose to visit the same hospital during follow\u2010up, which indicates that multiomic data may not be available to the physicians in terms of original electronic profiles during subsequent visits, mainly owing to legal obstacles associated with transferring between electronic health record (EHR) systems across different hospitals. In this regard, the clinical history can offer important evidence such as the duration of the disease, treatment records, changes in symptoms, and comprehensive summarization made by the previous physician, which provides a full review of the patients in unstructured texts. It is highly attractive to develop novel approaches to use these informatic data in AI models to prompt computer\u2010aided diagnosis.",
        "Natural language processing (NLP) is an essential branch of AI technology that aims to convert natural language into a computable digital form to achieve text\u2010level understanding and calculation. In the medical domain, the mainstream of NLP focuses on extracting clinically meaningful entities or classifying subgroups using EHRs, radiology reports, or drug instructions. Moreover, studies utilizing deep learning from free text to predict patient outcomes deserve further attention. More recently, Causa Andrieu et al. developed an NLP\u2010based radiology report analysis model to identify clinically meaningful CRC metastatic phenotypes and demonstrated a correlation between the phenotypes and overall clinical survival. Our previous study established a domain\u2010specific transfer learning pipeline to identify patients with clinically meaningful pathogenesis related to tinnitus. However, the integration of multimodal data, such as free text, genomics, and radiomics, and structured data has always been a critical challenge in modeling.",
        "This study aimed to effectively quantify the risk of LM in CRC patients using EHRs and laboratory data by constructing a novel fusion framework. The highlights of this study are listed as follows:",
        "A two\u2010tier fusion\u2010based framework is proposed to predict LMs in CRC patients. A total of 18 structured clinical factors including age, gender, the most recent laboratory tests associated with liver function, and cancer metastasis, in addition to clinical history, intraoperative findings, and pathology phenotypes from original medical record, have been manually extracted and numerized. Moreover, deep learning\u2010based textual features based on the most recent medical record have been modeled as free\u2010text representative features and included in the modeling.",
        "We have established a novel NLP and clinical factors\u2010based nomogram for the practical application of our fusion model. As clinical texts are the most common and essential data collected during the follow\u2010up of CRC patients, this nomogram may have broader applications.",
        "We evaluated the contribution of each data module to the prediction accuracy during the fusion process, thus improving the interpretability of this complex model.",
        "This study consisted of four parts. In Part 1, we built the machine learning (ML) and NLP models using structured clinical factors and free\u2010text medical history to evaluate their accuracy in predicting LMs. In Part 2, we used two advanced fusions, namely stacking and ensembling methods. Thus, a fusion learning framework was established to realize the joint prediction of LM by ML and NLP models. In the third part, the model performance was evaluated in terms of accuracy, precision, recall, F1, receiver operating characteristic (ROC) curve, AUC, and Shapley additive explanations (SHAP) values to improve the interpretability of the model. In the fourth part, we constructed a novel nomogram based on clinical factors and NLP scores to provide a valuable tool for clinical applications. Figure\u00a01 presents the workflow of this study.",
        "The study was conducted according to the Declaration of Helsinki. It was approved by the Beijing Friendship Hospital Ethics Committee, Capital Medical University (Research Application System number 2021\u2010P2\u2010144\u201001), and \u201cEthical Review of Biomedical Research Involving People,\u201d the Ministry of Public Health of China.",
        "We retrospectively collected EHR data from a tertiary hospital in Beijing, China, including the data of 1463 CRC patients admitted for surgery and followed\u2010up between 2019 and 2022. All authors discussed the inclusion and exclusion criteria. All definitions and details are listed in Table\u00a0S1 in Data\u00a0S1.",
        "All structured clinical data were derived from the Hospital Information System (HIS), including general information, laboratory test results, surgical record findings, and pathology results. Clinical free\u2010text medical history was defined as admission history at the most recent follow\u2010up visit, and follow\u2010up time was defined as the time between the initial surgery and the most recent follow\u2010up visit. We used two independent sample t\u2010tests to analyze the differences between the groups.",
        "The clinical notes used in this study were not annotated and acquired from the patients' most recent visits. These notes offer a comprehensive record of the patients' entire medical journey since the onset of the disease, encapsulating primary symptoms, duration, treatment process, and other pertinent information. An example is shown in Figure\u00a02. Note that this contextual information was processed by the NLP model without additional labeling. A sample of clinical notes used in our study is provided in Data S2.",
        "All patients underwent standard procedures for LM screening on admission: a CT scan of the upper abdomen with contrast or an MRI with contrast. The diagnostic criteria for LMs were determined using the LI\u2010RADS@ criteria defined by the American College of Radiology. Based on the imaging features, liver lesions are scored as LR\u20101 (100% benign), LR\u20102 (probably benign), LR\u20103 (intermediate probability for HCC), LR\u20104 (probably HCC), and LR\u20105 (100% definite HCC). As per the diagnostic criteria of recent international large\u2010scale clinical trials, This study defined \u201cNo metastasis\u201d as the following three conditions: no nodules detected, presence of LR\u20101 lesions, or the presence of LR\u20102 lesions. \u201cMetastasis\u201d was defined as detection of at least one LR\u20103 to LR\u20105 lesion. Table\u00a01 compares the basic statistics between the two groups.",
        "General information and laboratory test results were obtained directly from the HIS. Clinical history, intraoperative findings, and pathological information were manually extracted from semi\u2010structured electronic reports.",
        "Several ML\u2010based models for cancer prognosis have been developed. Chen et al. recently developed an eXtreme gradient boosting (XGBoost)\u2010based framework to identify patients with early\u2010stage pancreatic cancer using clinical data from EHRs. Wu et al. established a support vector machine (SVM) model to classify metastatic and non\u2010metastatic osteosarcoma patients. A risk\u2010scoring model was developed to quantify the risk by extracting and classifying independent prognostic genes. In this study, five mainstream ML models, including SVM, K\u2010nearest neighbors (KNN), decision tree (DT), random forest (RF), and extra trees were fine\u2010tuned and comprehensively evaluated for their performance in predicting the risk of LMs.",
        "NLP models are pretrained models that have achieved great success, and the bidirectional encoder representations from transformer (BERT) architecture proposed by Google researchers is the most representative. By applying an attention\u2010based two\u2010layer transformer architecture, BERT makes the model parameters fit the text context through unsupervised learning. Central to its design is the [CLS] token, which, influenced by all tokens in the input sequence owing to the self\u2010attention mechanism of BERT, captures a comprehensive representation of the entire input sequence. This feature is critical for tasks that require the entire context to be understood in our study. In this study, a Chinese BERT model based on Chinese super\u2010large prediction was adopted and fine\u2010tuned to evaluate the model's performance in predicting LMs in patients using Chinese\u2010text medical records. Figure\u00a03 illustrates the framework for fine\u2010tuning the BERT model used in this study.",
        "The feature data from a single modality are not sufficient to assess the patient's condition. For example, laboratory tests provide information about the quantitative changes in tumor markers, but only for a certain period, while free\u2010text medical records document the long\u2010term medical experience of patients. Therefore, this study strived to integrate and utilize heterogeneous data by establishing effective fusion frameworks. We used two of the most commonly used fusion schemes to evaluate the effect of different data fusion methods comprehensively.",
        "In Stage I of our model, we separately trained ML models on structured clinical data and the BERT model on free\u2010text clinical notes to maximize the utilization of both clinical and text features, aiming to obtain the best models to fit the predicted LM status. For early fusion (EF), we integrated the vector from the last layer of the BERT model and the features from the best model into a single feature vector. This combined feature vector was then used to train a final XGBoost model for further prediction tasks (Figure\u00a01; Stage II EF). The XGBoost classifier is a powerful ensemble model based on a tree structure and an optimized version of the gradient boosting tree method which incorporates an improved second\u2010order derivative loss function, regularization term to prevent overfitting, and parallel computing for block storage optimization. The formula for the XGBoost model is shown in Equation\u00a01.where L is the loss function, y is the actual value, \u0177 is the predicted value, l is the logistic loss function, and \u03a9(f) is the regularization term.",
        "In the late fusion (LF) model, we use the predictions generated by the models trained in Stage I to reach the final decision (Figure\u00a01; Stage II LF). These predictions, which are derived from the output of the models in Stage I, are then fused using an aggregation function to yield a final result. The aggregation can be achieved using methods such as averaging, majority voting, or weighted voting. The formula for weighted voting is shown in Equation\u00a02.where \u0177 is the final prediction, w\u1d62 is the weight of each model, and p\u1d62 is the prediction of each model.",
        "In our LF model, the weights assigned to each model for the weighted voting method were determined based on the performance of the respective models during the training phase. Specifically, the weights were computed as the reciprocal of the error rate observed in the cross\u2010validation of each model. Hence, models demonstrating lower error rates (indicating higher performance) were assigned greater weights. This method of weight assignment ensures that models with higher performance have a more substantial impact on the final prediction. The detailed equations and explanations are provided in Data S3.",
        "The advantage of the LF approach lies in its ability to integrate independent predictions from multiple models and establish a threshold based on the number of accurately predicted models. Considering the number of models in our study and recent research focusing on LF models, we chose the weighted voting method as the algorithm for LF, offering a more informed and robust final prediction.",
        "SHAP analysis is a method to address model interpretability. It is based on Shapley values, a game\u2010theoretic concept developed by economist Lloyd Shapley to determine the importance of individuals by calculating their contributions to cooperation. This method has received much attention in AI interpretability research and has contributed significantly to advancing the clinical applications of models. The Shapley value interpretation is an additive feature attribution method that interprets a model's predicted value as a linear function of a binary variable.  where g is the explanatory model (3a), z is the coalition vector, M is the maximum coalition size (3b), and \u03d5 j \u2208 R is the feature attribution of feature j.",
        "In this study, we employed SHAP analysis to visualize and evaluate the importance of each feature in the EF model and the final decision step to screen the most predictive features. The identified features were used to improve the model's interpretability.",
        "A quantifiable and practical clinical assistance tool is needed to help clinicians identify patients at high risk of developing LMs and implement individualized screening and diagnosis strategies. Therefore, we constructed a nomogram based on the 13 compelling predictive features identified by the SHAP analysis. The nomogram was constructed using the Python system's \u201crpy\u201d and \u201crms\u201d packages (Python Software Foundation, version 3.1.1).",
        "The performance of each method was evaluated using the ROC curve, along with the accuracy, precision, recall, and F1 scores. Furthermore, true positive (TP) and false positive (FP) are the numbers of correctly and incorrectly predicted positive cases, respectively, while true negative (TN) and false negative (FN) are the numbers of correctly and incorrectly predicted negative cases, respectively. Equations\u00a0(4a), (4b), (4c), (4d) describe the performance metrics.    ",
        "To explore the potential of predicting the risk of LM using only clinical indicators, five different ML models were first built using structured or semi\u2010structured clinical data, and the parameters were optimized. Features with significant correlations were excluded using Pearson correlation analysis. None of the 18 clinical features showed linear correlations using Pearson's coefficient (Data S1; Figure\u00a0S1); hence, they were incorporated into the ML model.",
        "The ROC curves and AUC values of the five ML algorithm\u2010building models on the test set are shown in Figure\u00a04, and the accuracy, precision, recall, and F1 values are listed in Table\u00a02. Overall, the performance of each ML algorithm in the validation group was similar and moderate; SVM showed the highest average AUC (0.640) and accuracy (0.640), while the KNN and DT had high recall (0.950) and precision (1.00). However, the F1 values of these two models were lower than their optimal metric (0.230 and 0.685), suggesting a potential deficiency in robustness. Therefore, SVM is considered the preferred optimal ML algorithm and is included in the EF of the second stage.",
        "As the NLP model, we used the BERT model with a bidirectional transformer structure, which has received sufficient attention and recognition in medical natural language research. After training, the BERT model obtained a precision of 0.617, recall of 0.613, accuracy of 0.636 (Table\u00a03), and AUC of 0.676 (Figure\u00a05). The BERT model had a more balanced prediction ability for positive and negative samples than the ML model. However, the effect was insignificant compared to the ML model, suggesting that the text features may be valuable for predicting LM but need to be supplemented by other features.",
        "In Stage II, we explored two fusion approaches to integrate the ML and NLP models from Stage I. Early fusion concatenated the feature vectors from the ML and NLP models into a single vector to train an XGBoost classifier. Late fusion aggregated the predictions from each model using weighted voting, with weights based on cross\u2010validation performance. The aim was to fuse the complementary structured clinical and free\u2010text information to improve predictive ability over individual models.",
        "Based on the above results, we performed SHAP analysis to evaluate and interpret the impact of different features in the BERT\u2010clinical\u2010EF model for predicting CRC liver metastases. As shown in the SHAP summary plot (Figure\u00a06A), four laboratory markers were the strongest predictors of LMs. These included two oncological biomarkers (CA199 and CEA) and two liver enzymatic parameters (ALT and AST), consistent with most clinical studies predicting LMs. It is worth noting that the importance of the \u201cNLP score\u201d is second only to laboratory data, indicating that complex clinical text features provide essential decision\u2010making information, although this information is not yet fully utilized. In the SHAP summary plot (Figure\u00a06B), all eigenvalues are represented in blue (low) or red (high), and the distance of each point from 0 (SHAP value) represents its contribution (different degrees) to the outcomes, with increasing values favoring the negative (no LM) or positive (LM) classes, respectively.",
        "Based on the top 13 valid predictors identified by the SHAP analysis, a nomogram was developed to predict the risk of LMs. As shown in the nomogram presented in Figure\u00a07, the effect of each feature on the outcome was consistent with its importance ranking determined by the SHAP analysis.",
        "To validate the predictive performance of the nomogram, an external dataset of 102 cases was collected from the Aerospace Center Hospital. Two physicians, Liu Wenjuan and Lv Han, who have at least 10\u2010year experience in CRC diagnosis, were blinded to the dataset and participated simultaneously in the validation process.",
        "In this external validation, the nomogram demonstrated superior performance compared to the two physicians across key predictive performance metrics, reinforcing its potential utility in predicting the risk of LMs in clinical practice. The ROC curve of the nomogram, presented in Figure\u00a08, yielded an AUC of 0.782, indicating a strong discriminative ability of the model. Compared with the performance of the physicians, represented by two points on the ROC curve, the nomogram achieved a higher TP rate for a given FP rate across a range of threshold probabilities.",
        "Table\u00a04 presents a summary of the key performance metrics for the nomogram and the two physicians. The nomogram consistently demonstrated higher performance across all metrics, underscoring its potential utility in a clinical setting. These results provide evidence supporting the application of the nomogram in clinical decision\u2010making while also highlighting areas for potential improvement in future iterations of the model.",
        "Considering the escalating global incidence of CRC, there is an urgent need for tools capable of quantifying the risk of disease progression, ultimately enhancing overall patient outcomes. A significant clinical challenge lies in accurately determining the risk of CRC\u2010related LMs and conducting timely imaging screening. Numerous studies employing ML and AI technology have contributed to the improved prognosis of CRC patients with remarkable results. However, the majority of these studies rely on costly high\u2010throughput sequencing genetic data or high\u2010quality imaging or pathology data. By contrast, medical free texts, representing the most prevalent and effective data indicative of patient disease progression, have been largely overlooked. With advances in NLP technologies such as BERT, computers are increasingly adept at understanding human language, and medical free text is poised to become another major branch of omics research.",
        "In this pioneering study, we introduced a fusion modeling approach that combines textual and clinical data to predict the risk of LMs in patients. Notably, to the best of our knowledge, this is the first study to merge NLP and classical ML prediction methods in the oncology domain. In the first stage, we employed five classic ML models to predict LMs but observed suboptimal results, suggesting that laboratory tests alone were insufficient for the prediction. In the second stage, we experimented with two levels of data fusion between the trained NLP and ML models. We found that the EF of models proved more effective than LF. This could be attributed to the ability of EF to preserve and incorporate the information from textual data into the decision model at an earlier stage, allowing for a more integrated and comprehensive representation of the data. By contrast, LF, which combines the predictions from individual models at a later stage, may not fully leverage the interactions between the different types of data.",
        "A critical barrier to the clinical application of deep learning is the \u201cblack box\u201d nature of AI models. To address this issue, we assessed feature importance in model decision\u2010making using the state\u2010of\u2010the\u2010art SHAP algorithm. In the top\u2010performing EF models, tumor biomarkers and liver enzymes emerged as the most crucial factors for decision\u2010making compared with other indicators, aligning with previous CRC clinical study conclusions. Furthermore, these findings are consistent with existing clinical evidence and perspectives on CRC, underscoring the value of these indicators. Notably, both the SHAP interpretation map and the nomogram map revealed that the clinical text features (NLP score) processed by NLP technology played a relatively significant role in decision\u2010making. By contrast, medical free texts, the most common and effective data reflecting patient disease progression, have been underappreciated. With breakthroughs in NLP technologies such as BERT, computers will further improve their ability to comprehend human language, leading to medical free text becoming another vital branch of omics research. ",
        "This study has several limitations that warrant further investigation. Most importantly, due to technical constraints and hardware resources, we used a fine\u2010tuned version of the BERT model rather than more advanced methods, such as domain pretraining. Consequently, the model may have limitations in understanding free\u2010text medical records. Additionally, the data scale in this study was relatively small compared to similar studies, which may introduce biases that could affect the robustness of the model. We also acknowledge that while the SHAP algorithm provides some level of interpretability, it does not fully explain the \u201cblack box\u201d nature of our model, highlighting the need for caution in interpreting the conclusions drawn from the SHAP analysis in our study. Finally, we believe the model architecture still has room for improvement, such as adopting the BioBERT architecture proposed by Lee et al. or the Siamese network architecture suggested by Bajaj et al. Exploring data fusion methods will enable the development of efficient prognostic models for multimodal data to improve human health in the oncology field.",
        "We developed a fusion framework based on NLP and clinical data to predict the risk of postoperative metastasis in CRC patients. Our EF model outperformed standalone ML\u2010 and NLP\u2010based models. In addition, we utilized the SHAP method to verify the interpretability of clinical and textual data and demonstrated their critical role in the final decision\u2010making. We also built a quantitative nomogram map for clinical practice based on our model. We believe our findings will promote the application of NLP and data fusion techniques in oncology to improve clinical decision\u2010making and overall patient outcomes."
    ],
    "title": "An interpretable deep learning framework for predicting liver metastases in postoperative colorectal cancer patients using natural language processing and clinical data integration"
}