{
    "content": [
        "In the global effort to prevent death by suicide, many academic medical institutions are implementing natural language processing (NLP) approaches to detect suicidality from unstructured clinical text in electronic health records (EHRs), with the hope of targeting timely, preventative interventions to individuals most at risk of suicide. Despite the international need, the development of these NLP approaches in EHRs has been largely local and not shared across healthcare systems.",
        "In this study, we developed a process to share NLP approaches that were individually developed at King\u2019s College London (KCL), UK and Weill Cornell Medicine (WCM), US - two academic medical centers based in different countries with vastly different healthcare systems. We tested and compared the algorithms\u2019 performance on manually annotated clinical notes (KCL: n = 4,911 and WCM = 837).",
        "After a successful technical porting of the NLP approaches, our quantitative evaluation determined that independently developed NLP approaches can detect suicidality at another healthcare organization with a different EHR system, clinical documentation processes, and culture, yet do not achieve the same level of success as at the institution where the NLP algorithm was developed (KCL approach: F1-score 0.85 vs. 0.68, WCM approach: F1-score 0.87 vs. 0.72).",
        "Independent NLP algorithm development and patient cohort selection at the two institutions comprised direct comparability.",
        "Shared use of these NLP approaches is a critical step forward towards improving data-driven algorithms for early suicide risk identification and timely prevention.",
        "Suicide is a major public health concern across the world. The World Health Organization (WHO) reports that nearly 700,000 people die per year by suicide, accounting for nearly 1.3% of all deaths worldwide. To prevent suicide, many healthcare institutions have attempted to predict deaths by suicide, but this has not been particularly successful. This can be attributed to the fact that within most populations, suicidal phenomena, especially those resulting in death, are relatively rare events, making it difficult to identify at-risk individuals. To improve suicide risk detection, researchers need to collaborate with other institutions to aggregate data or, when governance limits the pooling of protected health information (PHI), perform meta-analytic evaluations, improving statistical power.",
        "Electronic health records (EHRs) are distributed documentation systems that offer a substantial advantage compared to paper records or charts by aggregating and collecting a wide variety of patient health information. Making use of EHR data, particularly unstructured clinical notes, offers a novel avenue for suicide risk modeling. EHRs can bring together very large samples for researchers to scrutinize and provide real-world insights into a patient\u2019s mental state. This is particularly true for suicidality, a common precursor to death by suicide, as it has been established that many providers document suicidality in notes rather than as structured data elements in EHR systems. Based on this evidence, several investigators and health systems are now working to develop natural language processing (NLP) approaches to detect suicidality from unstructured clinical notes in the EHRs. Currently, such NLP algorithms are considered useful for retrospective suicide-related research and can aid domain experts on patterns of suicide precursors and identification of suicide prevention interventions.",
        "As health systems begin to achieve siloed success in detecting clinical conditions from EHR data and clinical notes, a critical next step forward in suicide risk detection is sharing and implementing these approaches broadly across other organizations, as most do not have the infrastructure and resources to develop and build these approaches de novo. Wide adoption of existing approaches may minimize duplicative effort in the development of NLP algorithms. While the literature details multiple efforts to enhance the portability of phenotype algorithms, such as through the eMERGE network or the OHDSI consortium, and apply them to detecting physical conditions, such as rheumatoid arthritis and heart disease, to our knowledge, there has been little work in the sharing of NLP algorithms to detect more complex clinical phenomena specific to psychiatry, such as suicidality and traumatic life events such as violence or abuse. The process is further complicated when sharing across institutions located internationally where the practice of clinical psychiatry, coding and documentation varies greatly.",
        "In this study, we evaluate cross-institutional NLP portability of such complex clinical phenomena, with suicidality detection across the US and UK as our use case. As described by, the lack of an internationally agreed-upon set of terms, definitions, and classifications that indicate suicidality make it difficult to conduct and compare suicide-related research and further, make generalizable conclusions on findings. Psychiatrists in the US and UK document suicide-related issues according to the phenomenology they were taught in medical school and during clinical training, they and are inevitably \u201clikely to emulate their supervisors\u2019 EHR use\u201d. Each clinician seeks to follow best practice national guidelines, such as the American Psychiatric Association (APA) guidelines in USA and the Department of Health Best Practice in Managing Risk guidance in the UK. Currently, there is no prior work that can aid international collaborations for sharing and evaluating NLP algorithms to detect suicidality from clinical notes in EHR systems, nor are there empirical findings on performance when NLP algorithms developed in one institution are implemented in another organization. Use of another institution\u2019s algorithm may give unique insights on suicide precursors not previously studied and recognized, aiding the development of suicide prevention measures implemented at the institution.",
        "To address this, we set out to evaluate how independently developed NLP approaches that detect suicidality translate across differing EHR platforms and classification objectives. In this study, we conducted a portability experiment using NLP approaches and datasets developed independently at two separate academic medical centers in two different countries (UK and the USA) known to have very different rates of national suicide rates (UK:US odds ratios for suicide 1:1.79) reflecting societal cultural differences (gun-related suicide deaths in the US) and healthcare systems. Results from our experiment can inform other institutions on how to share NLP algorithms that detect clinically complex psychiatric phenomena, such as suicidality, a phenotype with important implications in improving international collaboration for suicide prevention efforts.",
        "We used NLP algorithms and EHR data from two large, academic healthcare institutions: South London and Maudsley Foundation National Health Service (NHS) Trust, based in South London, UK and Weill Cornell Medicine based in New York City, USA.",
        "The KCL team used data extracted from electronic clinical records from the South London and Maudsley (SLaM) Foundation. NHS Trust is one of the UK\u2019s largest and oldest mental health trusts, providing a wide range of inpatient, outpatient and community-based mental health services. The main catchment area is four boroughs in south London (Croydon, Lambeth, Lewisham and Southwark), serving a local population of around 1.3 million people with more than 4500 employees. Jointly with the Institute of Psychiatry, Psychology & Neuroscience, KCL, SLaM hosts the National Institute for Healthcare Research (NIHR) Maudsley Biomedical Research center (BRC). The Clinical Record Interactive Search (CRIS) database is a resource developed at the Maudsley BRC, making de-identified EHR records available for secondary research use under an extensive governance model. The de-identified CRIS database has received ethical approval for secondary analysis: Oxford REC C, reference 18/SC/0372. The data is used in an anonymized and data-secure format under strict governance procedures. All experiments were performed in accordance with guidelines and regulations. The data were used in an entirely anonymized and data-secure format, and patients have the choice to opt-out of their anonymized data being used, and therefore, under UK law, does not require informed consent from patients whose data are represented here.",
        "Weill Cornell Medicine (WCM) is an academic medical center in New York City with 1600 physicians, over 50 locations throughout the New York City metropolitan region, and 3 million annual patient encounters. WCM has an affiliation with NewYork-Presbyterian Hospital (NYPH), which serves as the primary emergency and inpatient setting for WCM patients. While clinical care is documented in different EHR systems at WCM and NYPH, the Architecture for Research Computing in Health (ARCH) database facilitates the secondary use of EHR data for research by capturing novel research measures and integrating data from multiple EHR systems. This study was approved by the WCM Institutional Review Board (IRB). All experiments were performed in accordance with guidelines and regulations. This study was approved for a full waiver of informed consent, as it involves no more than minimal risk to the subjects.",
        "The KCL test data consists of 4911 documents (progress notes, assessments and correspondence notes) from a random sub-cohort of 500 adolescents (13\u201318 years old) diagnosed with autism spectrum disorders (International Classification of Diseases (ICD-10): F84.0, F84.1, F84.5, F84.9) derived from a previously studied clinical sample. Cohort demographic characteristics are provided in the supplementary section. The clinical documents were annotated for mentions of suicide-related information by trainee clinical psychologists, under senior clinician supervision. As described in, suicidality was defined as \u201cas either the reporting of the intention to engage in a potentially lethal act towards oneself, or undertaking such acts themselves.\u201d Each note contained at least one instance of a suicide-related term (e.g. \u2018suicid*\u2019, \u2018kill him/her/themself\u2019, \u2018want to die\u2019), that were then labeled as positive, negated, or uncertain. From the individual annotations, each document has then been further labeled as either affirmed/relevant for suicidality (True) or negated (False). There are in total 3069 documents labeled as True (62.5%) and 1842 as False (37.5%).",
        "The WCM test data set consists of 837 suicide-related notes for 30 patients selected from a pre-established depression cohort, defined as any patient diagnosed with depression or prescribed an antidepressant. Of the 30 patients, 10 patients had an encounter diagnosis of suicidal ideation (V62.84 (ICD9), R45.85 (ICD10)) in their medical history. The remaining 20 patients were considered to be potentially suicidal, as they had at least ten notes with a key suicidal phrase (\u201csuicidal\u201d, \u201csuicide\u201d, \u201csuicidal ideation (SI)\u201d, or \u201csuicidality\u201d). Cohort demographic statistics are provided in the supplementary section. A large majority of these notes (83%) were documented in the outpatient office setting at psychiatry and internal medicine departments between January of 2006 and December of 2019, further described in. The dataset was annotated for current suicidality, defined as patients discussing, thinking about or planning for suicide during the documented encounter, by two investigators at WCM with established annotation guidelines. Each note contained at least one instance of a suicidal mention (\u201csuicidal\u201d, \u201csuicide\u201d, \u201cSI\u201d, or \u201csuicidality\u201d), that were then labeled as positive or negative for current suicidality. Based on these annotations, 134 (16.0%) of the documents were classified as either affirmed/relevant for suicidality (True) and 703 (84.0%) documents were classified as negated (False).",
        "Two symbolic rule-based NLP approaches were applied from each of the institutions. We henceforth refer to the KCL approach as KCL-neg and the WCM approach as WCM-si. They were both developed on the basis of the NegEx algorithm, an approach to identify negated findings in unstructured clinical text. This algorithm relies on two lexicons: one defining target concepts (e.g. suicidal) and the other defining modifiers (e.g. not).",
        "The KCL-neg approach was designed to detect any mention of suicidality, regardless of temporality (i.e. current or historical). The thirteen target lexicons of the KCL-neg approach included both direct and indirect mentions of suicidality. Direct mentions are any word with the regular expression basis of \u201csuicid\u201d, which includes \u201csuicidal,\u201d \u201csuicidality,\u201d and \u201csuicide.\u201d Indirect mentions include expressions such as \u201ctake (his|her|their) life\u201d, \u201cwish to die\u201d, and \u201clife not worth living.\u201d The WCM-si approach was designed for detecting current suicidality, a predictor for lethal suicide attempts. The target lexicons for the WCM-si approach were the four key suicidal ideation terms\u2014\u201dsuicidal\u201d, \u201csuicide\u201d, \u201csuicidality\u201d, \u201csi\u201d\u2014used to select the EHR note cohort. The two approaches had overlap in target lexicons that were direct mentions of suicidality.",
        "The KCL team implemented different sets of modifiers to study the impact on algorithm performance when using previously published lists of modifier terms compared to adapted lists for new use cases. We used two of the KCL modifier sets, anySI-1 (44 modifiers) and anySI-2 (248 modifiers). The WCM modifier lexicon set, henceforth called currentSI, included 108 modifiers to negate current suicidality. The WCM modifier set shared 10 and 25 modifiers with anySI-1 and anySI-2, respectively. We categorized both the KCL and WCM modifiers into four different categories: negated, historical, conditional, and unrelated. Examples of each of these modifiers are provided in Table 1. The entire set of modifiers are available on our respective GitHub2,3 websites, with additional details on the NLP approaches in the supplementary section.",
        "To initiate the portability experiment, investigators from WCM and KCL held several meetings to present and discuss each of the NLP algorithms from both a clinical and technical standpoint. First, it was critical to share the algorithm\u2019s main clinical objectives, key details about the study population and site, and guidelines behind the manual annotation of the test set. Next, we shared the technical details of the algorithms and developed a plan of action to transfer compatible code and execution guidelines. Upon realizing that versioning issues might arise, we created a virtual environment with a consistent Python installation and package versions. Finally, we confirmed the format of each institution\u2019s data set, including the text format. To maintain security and privacy of each institution\u2019s dataset, we ran both algorithms within our respective firewalls, with no data sharing. Code for the algorithms is available on our respective GitHub1,2 websites.",
        "After executing the two NLP algorithms on the manually annotated datasets, we evaluated the results using both quantitative and qualitative methods. First, to assess portability quantitatively, we compared the algorithms\u2019 results using traditional intrinsic evaluation metrics, such as accuracy, precision, recall, and F1-scores. Second, to assess portability with an eye towards the underlying details of each NLP approach, we conducted a thorough qualitative manual error analysis to characterize the most common misclassification scenarios. Based on the specification of each of the approaches, we can identify some classification errors to be expected and re-analyze relevant quantitative metrics after removing notes with such errors. No changes were made to either of the algorithms during the portability experiment, leaving improvements for generalizability as future work.",
        "During a five-month span, the two teams met at least ten times (twice a month) to outline the technical requirements necessary to port our algorithms to unseen datasets at the other institution. Once all necessary information and details were made available on GitHub1, each team successfully executed the ported algorithm on their own test data set with little difficulty. In the event of questions, we communicated via email, striving to respond within two days to all critical communications. Fig. 1 illustrates the complete portability experiment workflow. Pre-experiment, the WCM and KCL teams independently developed and validated their respective algorithms. Within the portability experiment, the teams engaged in preliminary discussions and planning, executed code sharing through GitHub, and conducted quantitative evaluation followed by qualitative error analysis. Finally, future work will involve algorithm improvements on generalizability and further cross-institutional collaborations.",
        "As demonstrated in Table 2, the ported algorithms did detect suicidality, yet they did not replicate the same level of success in detecting suicidality as at the institution where the algorithm was originally developed. Using the two modifier sets, the KCL-neg approach achieved a maximum macro-average f1-score of 0.85 on its own KCL test dataset, but only resulted in a maximum score of 0.68 on the WCM dataset. Similarly, the WCM-si approach resulted in a macro-average f1-score of 0.87 on their own test dataset, but only achieved a maximum score of 0.72 on the KCL dataset.",
        "We observed the same phenomenon on each of the performance metrics (e.g. precision on affirmed instances), as neither of the approaches outperformed the success of the \u201chome algorithms\u201d. While the WCM-si approach was able to achieve higher precision (0.87) than the KCL-neg approach using AnySI-1 modifiers (0.74) for positive instances of suicidality on the KCL data, the KCL-neg approach using AnySI-2 modifiers yielded a similar precision (0.87).",
        "Although the KCL-neg approach using the AnySI-2 modifier set had a better overall performance (macro-average f1-score: 0.85 vs. 0.68) in comparison to the AnySI-1 modifier set on their own KCL data set, the opposite was observed on the WCM data set (macro-average f1-score: 0.53 with AnySI-1 vs. 0.68 with AnySI-2).",
        "Of the two KCL-neg modifier sets, the AnySI-I modifier lexicon set proved the most successful (macro-average f1-score of 0.68 vs. 0.53). Thus, using this set, we conducted our qualitative error analysis to determine the reasons for misclassification.",
        "Out of the 206 total errors, there were 177 and 29 false positive and false negative errors, respectively. Of the 29 false negative errors, the majority (69%) can be attributed to the KCL-neg algorithm\u2019s target lexicons not including the term \u201csi.\u201d For this reason, the KCL algorithm was not programmed to detect this type of mention from the clinical notes and automatically classified the note as negative. After removing these expected instances from the note set, recall for positive mentions of suicidal ideation increased from 0.80 to 0.93.",
        "The 177 false positive errors (Table 3) can be grouped into the following scenarios: missing a negation modifier, non-patient person reference, structured references, conditional mentions, and historical mentions. The table below displays the number of cases in each scenario and several examples. Because the KCL algorithm was not configured to negate historical suicidality, the 45 false positive errors classified to this scenario were to be expected. By removing these expected errors from the note set, precision for positive mentions increased from 0.39 to 0.46.",
        "A similar error analysis was performed on the KCL data with the WCM-si approach. Out of the 1398 total errors, there were 279 and 1119 false positive and false negative errors, respectively. Of the 1119 false negative errors, 529 (47%) were attributed to the WCM-si algorithm not including target terms such as \u201ckill him/herself\u201d or \u201cend his/her life\u201d. An analysis of 250 of the remaining 590 errors revealed that 58 (23%) related to references to the past, which the WCM-si approach was designed to exclude given that its primary focus is on \u201ccurrent\u201d suicidality; 69 (28%) related to complex, long documents where there were several references to suicidal behavior but the algorithm only picked up those related to \u201csuicid*\u201d; 40 (16%) related to missing triggers or erroneous trigger scopes; and 83 (33%) related to other issues, including errors in the gold standard annotations. As the WCM-si approach was not configured to detect indirect mentions and purposefully negated historical mentions, we considered 779 of the false negative errors to be expected, changing the recall for positive mentions of suicidal ideation from 0.64 to 0.83.",
        "For the 279 false positive errors, similar scenarios as for the KCL-neg approach on the WCM dataset were observed (Table 4), with some notable differences: historical mentions were not considered false positives in this case; but missing negation modifiers were observed (e.g. \u201cnil\u201d), as well as structured mentions in forms. Additionally, some false positives were related to documents where there were both negative and positive mentions. These were classified as negated in the KCL gold standard, but the WCM-si approach classified them as positive. Other examples include mentions of routine checks by the clinician, hypotheticals, and mentions related to someone other than the patient. We did not consider any of these errors to be expected.",
        "Our study showed that NLP approaches developed to detect complex clinical constructs, such as suicidality, can be successfully ported and shared across institutions, with proper emphasis on clear and effective communication. In this experiment, we saw success in technical seamlessness, the algorithms\u2019 ability to gain signal on an unseen new dataset, and the valuable insight for more nuanced NLP evaluation techniques and opportunities for future work. First, our informative discussions on the technical compatibility of our NLP algorithms (now hosted on GitHub1) made porting the algorithms a seamless experience. Second, while the traditional quantitative measures of portability, such as accuracy and F1-scores, indicated that ported NLP approaches were not able to achieve the same level of success as at their home institution, much of this was attributed to the approaches\u2019 slight differences in clinical objectives. Our qualitative error analysis, which took this into account, indicated that many of the errors were to be expected based on the institution\u2019s guidelines for defining and annotating suicidality. In fact, if expected errors were taken out of consideration, we found the ported algorithm\u2019s results to improve significantly. For the KCL-neg on the WCM data, 65 (32%) of the 206 errors were to be expected, changing the overall F1 score of the algorithm from 0.75 to 0.83. Similarly, of the 1398 errors that the WCM-si approach made on the KCL data, 587 (42%) of the errors were to be expected based on the algorithm\u2019s configuration and objective, changing the overall F1 score from 0.72 to 0.83. Adjustment for expected errors led to reductions in the instances of false negative errors, one of the most important metrics for NLP algorithms in being useful for detecting suicidality and common precursors to suicide. Finally, through the collaborative process, we were able to gain a better understanding of the other institution\u2019s clinical objectives and patient cohorts of interest, develop a framework for a more informative qualitative evaluation, and identify potential areas of improvement for future work.",
        "In addition to a more meaningful evaluation, understanding the underlying details of the NLP approaches may inform how to develop a more generalizable approach. Similar to prior work, we confirmed in this study that suicidality is interpreted and defined differently across institutions and healthcare systems. Among our two institutions, the biggest differences in the definition of suicidality include decisions on temporality, specifically WCM-si\u2019s focus on current suicidality, and inclusion of indirect suicidality-related terms, specifically KCL-neg\u2019s use of phrases such as \u201cwish to die\u201d, and \u201clife not worth living.\u201d While these differences exist, our approaches did also have a number of similarities, including terms in the target lexicons and modifier terms within negation, conditional, and non-experiencer (unrelated categories). This commonality suggests that with further experimentation and collaborations, we can continue to improve on the detection of this complex clinical condition, by developing a portable and generalizable approach.",
        "The NLP methods used in this study used relatively simple rule-based approaches to tackle the clinically complex phenomena of suicidality. Both of our institutions have also implemented more novel, state-of-the-art methods for the detection of suicidality, such as a text classification convolutional neural network (CNN), and support vector machines (SVM). However, we decided to experiment with the more basic rule-based NLP algorithms for two reasons: ease of portability and human interpretability. With the eventual goal of building generalizable and portable NLP approaches to detect suicidality, we determined that rule-based approaches could be more widely implemented across institutions as they require significantly less technical expertise, computational power, and other resources. In addition, many studies have concluded that simple rule-based approaches achieve similar levels of success to these novel implementations. A second advantage of rule-based NLP algorithms is their human interpretability. While effective, state of the art machine learning methods are challenging to interpret and even more difficult to adjust. In the case of rule-based NLP algorithms, an external institution would have the ability to determine the most common sources of error and make changes to the approach, as it sees fit to the organization\u2019s use case.",
        "There are several limitations to this study. First, because the suicidality NLP approaches and test data sets were developed completely independently of each other, we recognize that they may not be directly comparable. However, these differences show the robustness of our approaches \u2013 as they were able to detect suicidality in disparate populations. We view this to be a real-world experiment and thus replicable by other institutions. Second, our test data sets were relatively small, and similar results may not hold in larger patient populations. Third, our methods of data extraction, specifically data filtering, create patient cohorts with known suicidal issues, which may be problematic when applying NLP at scale. While the WCM team only extracted notes with explicit mentions of suicidality, such as \u201csuicidal\u201d, the KCL team extracted notes with wider search criterion, which included both explicit and \u201cimplicit\u201d terms, such as \u201cwish to die.\u201d Fourth, because we were not able to interact with the clinicians who wrote the clinical notes, we were unable to comment and interpret how specific institutional differences in front-end EHR systems, clinical documentation process, and culture impacted the results of our portability experiment. Fifth, incorporation of diagnostic codes, such as ICD-9/10 may improve our algorithms\u2019 results. However, the aim of this study was to evaluate and assess portability of our suicidality NLP approaches, rather than prediction results. Results from this study will make NLP algorithms more widely accessible and bolster results of existing suicide prediction algorithms currently reliant on structured EHR data such as diagnosis codes. Finally, because we did not port and evaluate our more advanced machine-learning based algorithms, we cannot say for certain whether these models would have achieved higher success than our lexicon-based NLP approaches. However, based on our goal of developing NLP approaches that can be widely used, we believe this is out of scope for this study and a future area of research.",
        "In an effort to understand patients who are at risk for death by suicide, routinely collected data from healthcare institutions, such as EHRs, can be a valuable resource at scale. Information about suicidal risk behavior is predominantly documented in free text notes in EHRs, leading to an increase in the development of NLP approaches to detect suicidality in unstructured clinical text. However, due to the clinical complexity of suicidality, the lack of consensus on how to define this condition, differences in how clinical assessments are documented in EHRs, and the various ways the task can be modeled for information extraction, the development of relevant NLP approaches have largely been local to each institution\u2019s definitions and interpretations. Thus, these NLP approaches are much less generalizable and portable in comparison to phenotype algorithms for well-defined clinical conditions, such as rheumatoid arthritis. However, with a well-defined process to understand the underlying details of an approach, institutions can be well-equipped to make use of an external approach, allowing a larger number of institutions to participate in suicide-related research. This is a critical step forward in learning how to develop more robust, portable, and generalizable NLP methods that can be applied to any clinical text, regardless of the origin EHR system."
    ],
    "title": "Portability of natural language processing methods to detect suicidality from clinical text in US and UK electronic health records"
}