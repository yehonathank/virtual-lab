{
    "content": [
        "Rationale: Chronic kidney disease (CKD) is a major public health problem worldwide associated with cardiovascular disease, renal failure, and mortality. To effectively address this growing burden, innovative solutions to management are urgently required. We conducted a scoping review to identify key use cases in which artificial intelligence (AI) could be leveraged for improving management of CKD. Additionally, we examined the challenges faced by AI in CKD management, proposed potential solutions to overcome these barriers.",
        "Methods: We reviewed 41 articles published between 2014-2024 which examined various AI techniques including machine learning (ML) and deep learning (DL), unsupervised clustering, digital twin, natural language processing (NLP) and large language models (LLMs) in CKD management. We focused on four areas: early detection, risk stratification and prediction, treatment recommendations and patient care and communication.",
        "Results: We identified 41 articles published between 2014-2024 that assessed image-based DL models for early detection (n = 6), ML models for risk stratification and prediction (n = 14) and treatment recommendations (n = 4), and NLP and LLMs for patient care and communication (n = 17). Key challenges in integrating AI models into healthcare include technical issues such as data quality and access, model accuracy, and interpretability, alongside adoption barriers like workflow integration, user training, and regulatory approval.",
        "Conclusions: There is tremendous potential of integrating AI into clinical care of CKD patients to enable early detection, prediction, and improved patient outcomes. Collaboration among healthcare providers, researchers, regulators, and industries is crucial to developing robust protocols that ensure compliance with legal standards, while minimizing risks and maintaining patient safety.",
        "Chronic kidney disease (CKD) is a global health challenge associated with serious adverse consequences including cardiovascular disease (CVD), kidney failure, premature death, and poor quality of life. A recent meta-analysis reported the global prevalence of CKD to be 11%-13% affecting an estimated 844 million people worldwide, twice the estimated number of people with diabetes. With aging populations and increasing prevalence of diabetes and hypertension, the burden of CKD is projected to increase substantially. CKD was ranked as the 12th leading cause of death accounting for 1.2 million deaths in 2017 with this number expected to reach 4 million and the 5th leading cause of death by 2040. Developed nations allocate over 2-3% of their annual healthcare budget to treat end-stage kidney disease (ESKD), despite it affecting only 0.02-0.03% of the total population. To effectively address this growing burden of CKD, innovative solutions are urgently required.",
        "In the past decade, a series of new artificial intelligence (AI) technologies, including machine learning (ML) and deep learning (DL), natural language processing (NLP) and large language models (LLMs), have been developed, offering highly promising approaches to optimize CKD management. Previous reviews on AI in kidney disease have either addressed AI in nephrology as a broad topic, covering areas such as acute kidney injury (AKI), CKD, renal cancer, dialysis, and transplantation management, or focused on specific techniques, such as traditional ML models or NLP. There has been no comprehensive review of emerging AI technologies, such as DL, unsupervised learning, and LLMs in CKD management. In this review, we address these gaps by exploring a full range of AI techniques beyond traditional ML, including DL, unsupervised clustering, NLP, and LLMs (ChatGPT) in CKD management. Additionally, we examine technical and non-technical challenges to integrating AI into CKD management and propose potential solutions.",
        "Figure 1 illustrates the expansive field of AI and its pivotal subfields that significantly contribute to advancing healthcare practices. AI is a computer science field focused on creating intelligent machines capable of mimicking human cognitive functions like learning, decision making and problem-solving but offers faster processing, potentially more objective decision-making, and the ability to analyze vast amounts of data that would be unmanageable for humans. ML, a subset of AI, focuses on enabling computers to learn from data without explicit programming, allowing them to improve performance through experience. DL, a subfield of ML, utilizes artificial neural networks (ANN) inspired by the structure of the human brain. These networks have multiple layers and are proficient in processing complex forms of data, such as images, text, or speech. NLP, is a subfield of AI that deals with the interaction between computers and human language allowing computers to understand, interpret, and generate human language. LLMs, a subfield of DL, excels in understanding, reasoning and generating human-like text.",
        "ML, one of the cornerstones of AI, can be broadly classified into several types, each serving different purposes (Table 1). Supervised learning relies on labeled data to train models that can predict outcomes or classify information, while unsupervised learning identifies patterns in unlabeled data. Reinforcement learning uses trial-and-error methods to optimize decisions, particularly useful in dynamic healthcare environments like personalized treatment planning. Other types include semi-supervised learning, which combines labeled and unlabeled data, and self-supervised learning, often used for feature extraction and predictive modeling in healthcare applications. The specific tasks and applications of these types of ML, such as classification, clustering, disease diagnosis, and risk prediction as listed in Table 1 demonstrate the wide-ranging impact of ML in healthcare, from prediction to patient segmentation.",
        "LLMs are trained on massive text data using a phased approach that leverages the Transformer architecture. The Transformer's self-attention mechanism allows LLMs to efficiently process sequential data, enabling a strong grasp of context and meaning in text. Training LLMs begins with pretraining on large, unlabeled corpora (e.g., internet text, Wikipedia, social media) using a self-supervised approach followed by fine-tuning on specific datasets with human feedback, tailoring the model to particular tasks. In the final phase, experts apply specialized prompting techniques to adapt the model for targeted applications, enabling it to handle nuanced, domain-specific tasks effectively. A prominent example of an LLM based on this Transformer architecture is OpenAI's ChatGPT, which, after extensive training on diverse text sources, can generate coherent and contextually relevant responses across a wide range of topics.",
        "We explored how AI contributes to CKD management across four areas (Figure 2): 1) early detection and screening, 2) risk stratification and prediction, 3) treatment recommendations and personalized care, and 4) patient care and communication. As previous reviews on AI in CKD have focused largely on traditional ML models for detecting or predicting CKD progression, we excluded data-derived ML models for prognosis prediction but included them for risk stratification and treatment recommendations. Use cases include image-based DL techniques for detection, data-driven ML models that combine both supervised and unsupervised clustering for risk stratification, and prediction, and treatment planning through clinical decision support systems (CDSS) and NLP/LLM applications in enhancing patient communication and care. Additionally, we addressed AI challenges, such as ethical concerns, and proposed solutions, while exploring future directions like foundation models to create AI platforms supporting personalized care and patient self-management for CKD.",
        "We conducted a scoping review by identifying literature in PubMed from January 1, 2014, to September 30, 2024. The search was restricted to English language and adult studies, focusing on the past 10 years, which marked the period of DL and when AI techniques began to significantly impact on medicine and nephrology. We excluded editorials, review articles, and articles related to specific kidney diseases other than CKD for e.g. acute renal failure, IgA nephropathy, polycystic kidney disease, diabetic nephropathy etc. We used search terms associated with CKD and AI models and their alternative terms. For e.g., for CKD, we used, end-stage kidney disease, renal failure, kidney failure, impaired kidney function, etc. We combined the search terms using Boolean Operators (\u201cOR\u201d, \u201cAND\u201d). We also reviewed the reference lists of the articles identified through our search strategy and selected additional articles that we deemed relevant. For our aim on image-based deep learning in CKD detection and screening, the search terms included \u201cartificial intelligence\u201d OR \u201cdeep learning algorithm\u201d OR \u201cneural networks\u201d combined with \u201cimage\u201d and CKD search terms. This search produced 28 articles, of which four were selected for inclusion and through back referencing, two more articles were included, resulting in a final reference list of six articles relevant to image-based deep learning. For risk stratification and prediction, we identified 14 articles, and for treatment recommendations, we found 4 articles. For our aim on patient care and communication using NLP and LLM, we identified 17 articles through direct searching, coauthor recommendations and back references. In total, we identified 41 use cases relevant to CKD management across various AI techniques which are discussed in the following sections.",
        "CKD often remains asymptomatic until advanced stages, but early detection through risk factor management can slow progression. Regular screening for CKD is recommended in the general population, and particularly for high-risk groups, such as those with diabetes, hypertension and certain ethnic groups since earlier detection enables timely interventions. Screening typically involves assessing estimated glomerular filtration rate (eGFR) or proteinuria. Despite the availability of effective treatments, CKD screening rates remain suboptimal, even in high-income countries and in those with diabetes. Serum creatinine, a key component in eGFR calculation, is influenced by factors such as muscle mass, diet and specific medication use, which can affect its precision. Similarly, albuminuria demonstrates significant intra-individual variability, with up to 50% fluctuation, and is also affected by physical activity and other factors. Additionally, up to 50% of individuals with diabetes and reduced eGFR may have albuminuria levels within the normal range, underscoring the limitations of current screening tools in detecting CKD in this population. The 24-hour urine collection is considered the gold standard for diagnosing microalbuminuria due to its minimal variability, but it is labor-intensive. In clinical practice, when CKD screening is recommended by physicians, the patient visits the laboratory on one day and is scheduled to return on another day for the physician to review the results which may involve multiple visits. Scaling up screening tests poses challenges due to limited resources. Deep learning algorithms (DLA) using noninvasive imaging, such as ultrasound kidney images or retinal images, may complement early CKD detection. Ultrasound-based parameters, such as kidney length, echogenicity, and cortical thickness, are influenced by CKD and offer a non-invasive means to assess renal function. Renal cortical echogenicity, being irreversible compared to serum creatinine fluctuations, serves as a stable marker of kidney health. However, substantial interobserver variability in ultrasound interpretation has historically limited its utility. Advances in deep learning for image segmentation and classification now enable standardized, objective analysis, enhancing diagnostic accuracy. Besides, ultrasound images, studies, including our own, have demonstrated that manually graded retinal features can predict CKD, forming the basis for developing DLAs to detect CKD directly from retinal images. These imaging modalities offer accessible, cost-effective, and non-invasive options for screening, making them valuable tools for early CKD detection and management.",
        "Table 2 summarizes studies on image-based DLAs for CKD detection. Kuo et al. used over 4,500 kidney ultrasound images to predict eGFR and CKD, achieving an 85.6% accuracy, outperforming nephrologists (60.3%-80.1%). However, lacking external validation limits its generalizability. We published two studies using retinal imaging to detect CKD in general and diabetic populations, later named RetiKid and RetiKid-Diab. RetiKid achieved 91% accuracy in internal validation and 73%-83% in external validation across two populations, comparable to a traditional risk factor model including age, sex, ethnicity, diabetes and hypertension (92% internally, 83%-89% externally). RetiKid-Diab, developed for diabetic populations, achieved 83% accuracy internally and 73%-76% externally, performing similarly to risk factor models. Other studies, such as those by Kang et al. and Zhang et al. have also shown promising results for retinal image-based DLAs in CKD detection. An et al. used UK Biobank fundus images to train DLAs for detecting CKD (using creatinine-only vs. creatinine and cystatin-C eGFR) and chronic renal failure (ICD-10 codes). DLAs trained on CKD defined by dual markers outperformed single markers (AUCs: 0.758 vs. 0.668, p<0.05), but performance for chronic renal failure was similar (AUCs: 0.712 vs. 0.690, p=0.1).",
        "The advantages of using retinal images for CKD screening is that it is non-invasive, and retinal cameras which are commonly available in community and primary care settings for diabetic retinopathy (DR) screening can be utilized. Thus, it may prove useful in the following circumstances: First, in facilities with availability of retinal images from DR screening, CKD screening can be used as an 'add-on' to DR screening report using the same images. Second, non-invasive screening methods may be more tolerable for individuals with a fear of needles, potentially increasing participation rates. Fear of needles, which affects approximately 10% of individuals, is a common issue that can lead to the avoidance of medical care. Third, drawing blood may not be practical in all settings, for e.g. rural areas with lack of laboratory facilities. With improvement in imaging technologies and resolution of smart phones, RetiKid can be integrated into smartphones to give rapid, point-of-care diagnoses, which will help reduce demand on human resources involved in CKD screening services and could improve compliance to screening.",
        "Finally, as RetiKid automates the screening process, it enables a larger number of at-risk patients, for e.g. those with family history of CKD to be screened more effectively. It will also allow screening to be done in a few minutes at any healthcare site or community site in the future, therefore increasing the scope of kidney screening to beyond the usual blood testing sites.",
        "Risk stratification in CKD using ML involves two main approaches. First, predictive models utilizing supervised learning trained on electronic health records (EHR) or other patient data sources estimate individual risk of CKD progression and adverse outcomes. Second, unsupervised learning methods are employed to identify and characterize distinct sub-phenotypes of CKD, revealing underlying patterns and heterogeneity in the disease that can inform more personalized treatment strategies.",
        "Two validated ML-based risk scores, KidneyIntelX and Klinrisk stratify patients with preserved kidney function (eGFR \u226560) to identify those at high risk of CKD progression. KidneyIntelX developed by Chan et al. uses KDIGO components, clinical variables, and three blood-based biomarkers to categorize patients into low, intermediate, and high risk, with high-risk patients 2.5 times more likely to be referred to specialty care. It is also the first FDA-authorized test for assessing CKD progression risk in adults with type 2 diabetes. In the CANVAS trial, KidneyIntelX effectively stratified participants with baseline DKD into low- (42%), intermediate- (44%), and high-risk (15%) groups, with cumulative incidence rates of 3%, 11%, and 26%, respectively. Klinrisk, developed by Ferguson et al., uses a random forest model to risk stratify individuals, predicting that the top 30% of those classified as high- and intermediate-risk account for 87% of progression events over 2 years and 77% over 5 years.",
        "A US study used convolutional neural networks (CNN) models trained on kidney biopsy images to classify tasks including CKD severity (multi-class label), baseline serum creatinine and nephrotic-range proteinuria at the time of biopsy (binarized values), and predicting renal survival at 1-, 3-, and 5-years and compared the performance of CNN models to pathologist-estimated fibrosis score (PEFS). The CNN achieved superior accuracy for all outcomes compared to PEFS (Kappa 0.519 vs. 0.051 for CKD staging; accuracy of 91% vs. 84% for serum creatinine, 87% vs. 70% for nephrotic-range proteinuria, and 88%, 88% and 90% vs. 81%, 80% and 79% for predicting 1-, 3-, and 5-year renal survival). With further validation across diverse clinical practices and image datasets, this AI tool has the potential to be deployed at the point of care, enhancing clinical decision-making for nephrologists.",
        "Inaguma et al. used hierarchical clustering to identify eGFR trajectories and a random forest (RF) model to predict CKD progression (eGFR decline \u226530% within 2 years), achieving 79% accuracy for rapid eGFR decline, with hemoglobin, albumin, and CRP as key predictors. Kaufmann et al. used K-Means clustering to identify four patient groups with varying eGFR trajectories before dialysis, finding higher hospitalization and mortality risks in those with rapid eGFR decline. The Chronic Renal Insufficiency Cohort (CRIC) study applied consensus clustering to categorize CKD patients into three clusters based on 72 characteristics, revealing significant associations with cardiovascular disease and mortality, although cluster membership did not improve risk prediction beyond traditional markers like eGFR and albuminuria. Using time-series clustering, Saito et al. stratified CKD patients (baseline eGFR \u226545 mL/min/1.73m\u00b2) into five groups based on 5-year eGFR changes, ranging from 4.9% to 45.1% decline. A prediction model with light gradient boosting achieved 68% accuracy overall and 76% for predicting severe decline (Classes 4 and 5). SHapley Additive exPlanations (SHAP) analysis highlighted baseline eGFR (1.61), hemoglobin (0.12), and BMI (0.11) as key contributors. While clustering did not improve prediction accuracy, these studies demonstrate the utility of unsupervised algorithms for phenotyping and exploring CKD heterogeneity.",
        "Digital twins are virtual replicas or models of individual patients, crafted to mirror their physiological characteristics, health status, and disease progression in real time. Powered by data from various sources such as EHR, lab reports, imaging reports, genetics, wearable devices etc. AI algorithms create sophisticated computational models that simulate a patient's biological processes. Just like a flight simulator helps pilots practice and understand different flight scenarios, digital twin models allow doctors to simulate and analyze how various factors, such as lifestyle changes, medications, or genetic mutations affect disease progression leading to more personalized treatment plans.",
        "Researchers in Singapore developed a digital twin model using generalized metabolic fluxes (GMF) to predict CKD onset within three years across four multi-ethnic cohorts (US and Singapore). The prediction model reached 75-86%, revealing worse metabolic profiles in future CKD patients. Participants were stratified into high-, moderate-, and low-risk groups, with CKD development rates of 53.9-62.9%, 17.3-19.3%, and 5.4-10.7%, respectively. GMF combined with K-means clustering reveal distinct metabolic profiles driving CKD progression, with future CKD patients exhibiting elevated fluxes linked to circulation, blood pressure, glucose metabolism, and kidney function. This approach maps patient health trajectories, enabling risk stratification, sub-grouping, and clustering based on metabolic health.",
        "Apart from CKD applications, few studies have explored the use of ML models for assessing CVD risk in CKD. A recent cross-sectional study in China, using the random forest algorithm, identified age, systolic blood pressure, and sublingual microcirculatory perfusion parameters (total and perfused vessel density, TVD and PVD) as optimal predictors for cardiovascular-kidney-metabolic (CKM) risk in type 2 diabetes mellitus (T2DM) patients. Another study in China developed CVD risk prediction models for patients with CKD using routine clinical diagnostic and treatment data extracted from EMR. By applying Least Absolute Shrinkage and Selection Operator (LASSO) regression, the study identified eight critical predictors of CVD risk, including age, history of hypertension, high-density lipoprotein levels, and urinary protein. Among various ML approaches tested, the extreme gradient boosting model demonstrated superior predictive performance with accuracy of 89%. These findings underscore the potential of ML models in cardiovascular risk stratification among CKD patients, offering opportunities to enhance CKD management strategies. However, external validation is necessary to confirm their broader applicability and usefulness.",
        "Recent advancements in CDSS have enabled personalized management of CKD. Anemia in CKD patients remains a significant risk factor despite advances in dialysis, erythropoietin stimulating agents (ESAs), and injectable iron therapies. Barbieri et al. developed a data-driven ML model the 'Anemia Control Model (ACM)' to generate individualized ESA dose recommendations based on patient history, dose-response information, and demographic data, supporting anemia management in hemodialysis patients. The ACM incorporates an ANN and a dose selection algorithm to optimize ESA dosing. The ANN, trained on 170,000 clinical records and tested on 40,000, generated optimal darbepoetin and iron doses to achieve target Hb and ferritin levels. Deployment of the ACM in 752 patients undergoing hemodialysis therapy in three pilot clinics, reduced ESA use, minimized Hb fluctuations, and improved anemia management. A subsequent prospective study in Spain validated the model's effectiveness, showing reduced cardiovascular events, transfusions, hospitalization, and costs, enhancing patient care. This AI-driven CDSS has the potential to improve prescribing practices that typically react excessively to Hb fluctuations, ultimately enhancing patient care and treatment outcomes.",
        "Li et al. developed TrajVis, a web-based interactive visual CDSS designed to visualize AI-driven CKD patient trajectories. This tool aids clinicians in understanding CKD progression by leveraging the DisEase PrOgression Trajectory (DEPOT) model, a graph-based AI approach that uses latent representation to infer disease trajectories and support personalized patient management. TrajVis features four panels: Patient View (demographics and clinical data), Trajectory View (visualizing CKD trajectories), Clinical Indicator View (longitudinal patterns), and Analysis View (individual progression trajectories). Using synthetic EHR data, the web app helps clinicians summarize data, visualize progression, and identify risk factors. TrajVis complements KFRE by incorporating comorbidities, past patterns, and treatment adherence, providing tailored predictions to support nephrologists in managing CKD progression.",
        "Kalmrowski et al. utilised random forest model to predict the risk of kidney failure in patients with advanced CKD over 6- and 12-month time frames using patient data, such as age, sex, and time-varying trends in laboratory measurements. The model accurately identified unplanned dialysis in 88% of cases at 6 months and 87% at 12 months, with external validation confirming 87% accuracy at both timepoints. This early warning system aids clinical decision-making, enabling timely interventions and smoother transitions to kidney failure care at both timepoints.",
        "NLP has emerged as a powerful tool in CKD management, with various use cases aimed at improving documentation, symptom detection, data extraction, and disease tracking from unstructured clinical notes and reports.",
        "Two NLP-based tools developed to assess CKD documentation in EHRs, achieved 95.4%-99.8% sensitivity and 99.8% specificity. Analysis revealed 22% of moderate CKD cases were undocumented, potentially delaying treatment. NLP was used to detect seven hemodialysis symptoms, showing higher sensitivity (0.85-0.99) than ICD codes (0.09-0.59). In Canada, an NLP system identified dementia (99%), diabetes (83%), and infarction (80%) from dialysis notes. Another Canadian study applied NLP to kidney biopsy reports, creating a structured database linked to clinical data, improving disease classification and patient management.",
        "NLP has been used to extract concepts from unstructured clinical notes to identify predictors of CKD progression, such as high-dose ascorbic acid and fast-food consumption. Latent Dirichlet Allocation, an unsupervised ML technique, uncovered themes related to diabetes, including insulin and glucose, which were linked to a higher risk of progression from CKD stage 3 to stage 4. Models combining longitudinal lab data with NLP-extracted clinical text achieved 85% accuracy in predicting progression to stage 4, outperforming models based on lab results alone (82%) or eGFR (78%).",
        "These capabilities highlight NLP's potential to improve CKD care by detecting undocumented cases, identifying early signs of progression, and supporting personalized treatment and proactive population health management. While NLP has shown promise for improved patient care, its clinical application remains limited due to the need for external validation across different healthcare systems, complicated by unique note templates, settings-related and regional variations. Sharing progress notes for validation is challenging due to the presence of protected health information (PHI) and strict privacy protections, though automated deidentification solutions offer potential to overcome these barriers.",
        "AI tools, particularly LLMs like ChatGPT/GPT-4, are revolutionizing patient care by streamlining various tasks. Physician burnout, affecting 63% of U.S. physicians, is a major issue that impacts healthcare efficiency, leading to more errors, lower patient satisfaction, and higher turnover. A key contributor to burnout is the excessive workload, including medical documentation and communication. AI, especially LLMs, can alleviate this by generating accurate discharge summaries, operative reports, and informed consent documents, sometimes outperforming traditional methods. Despite occasional inaccuracies, ChatGPT's potential to improve documentation quality and empathy in patient communication makes it a promising tool for reducing burnout. Specific use cases and examples of using LLMs, particularly ChatGPT, in patient care are detailed below:",
        "The digital scribe uses automatic speech recognition (ASR) and NLP to automate clinical documentation, including creating notes, adding billing codes, and supporting diagnoses. This reduces physician documentation burden, enhances accuracy, and supports clinical decision-making. A proof-of-concept system developed by Klan et al. demonstrated ASR's feasibility for single-speaker physician-patient encounters. Expanding this, an Intelligent Listening Framework (ILF) was developed for multi-speaker environments, integrating advanced NLP techniques to capture and structure doctor-patient interactions.",
        "In a study including 100 simulated nephrology cases, ChatGPT-4.0 outperformed ChatGPT-3.5 in identifying ICD-10 codes for nephrology conditions, with accuracy rates of 99% compared to 91% with consistent performance across two rounds. While ChatGPT-4.0 showed promise in reducing physician workload, the study highlights the need for further refinement, including multi-code generation and EHR integration.",
        "Efficiently managing EHR inbox messages has become a significant challenge for healthcare providers, contributing to clinician burnout. Pham et al. assessed ChatGPT-4's performance in triaging simulated nephrology patient messages as non-urgent, urgent, or emergent. In two trials with 150 messages, ChatGPT-4 correctly categorized 93% of the messages, with minor overestimation (3-6%) and underestimation (1-4%). The system showed high internal consistency (Kappa score of 0.88), indicating that AI-driven triage could improve efficiency and patient care in outpatient nephrology settings.",
        "LLMs support patient education by providing tailored materials and answering questions in understandable language, helping patients better manage chronic diseases and adhere to therapies. ChatGPT has been shown to generate recommendations for cardiovascular disease prevention, breast cancer screening and prevention and kidney cancer.",
        "ChatGPT offers personalized dietary advice and assists clinicians with diagnosis and treatment recommendations by analyzing patient data against medical guidelines. Using a retrieval-augmented generation (RAG) method, models like ChatGPT can access real-time external sources, aligning with updated guidelines, such as the KDIGO 2023 CKD guidelines, ensuring accurate, current recommendations while reducing hallucination issues.",
        "Medication management in nephrology is complex, and ChatGPT can assist by checking drug interactions, adjusting dosages based on renal function, and monitoring adherence. A study found ChatGPT-4 accurately identified 88% of 25 nephrology medications from self-captured pill images, with misidentifications mainly due to imprint issues. Despite this, it showed improved accuracy after feedback, highlighting its potential for medication identification. ChatGPT has also demonstrated value in clinical decision-making, such as identifying treatment-resistant schizophrenia and suggesting treatment plans aligned with medical standards.",
        "ChatGPT can assist in drafting correspondence, such as patient letters, and improving communication between healthcare professionals and patients about medication-related queries and side effects. Ayers et al. evaluated ChatGPT's performance using a public database from Reddit's r/AskDocs, analyzing 195 exchanges with verified physician responses. ChatGPT's responses were preferred 78.6% of the time, with higher ratings for quality and empathy. These findings suggest AI chatbots could ease clinician workload and reduce burnout. Incorporating prompt engineering (PE) into LLMs significantly enhances output accuracy by optimizing question framing and interpretation.",
        "LLMs also provide fast, accurate translations in multiple languages, aiding clinical decision-making and improving therapy adherence. A recent study on ChatGPT's translation of 54 kidney transplant FAQs from English to Spanish found both GPT-3.5 and GPT-4.0 translations to be linguistically accurate and culturally sensitive, improving access to medical information for non-English-speaking populations.",
        "ChatGPT can streamline administrative tasks by automating appointment scheduling, reminders, discharge summaries, and billing codes. It also helps patients track symptoms and medication adherence with automated reminders. This reduces the administrative burden on healthcare staff, freeing up time for direct patient care and improving healthcare efficiency. A study on ChatGPT's ability to generate a history of present illness showed that iterative PE improved its accuracy from 10.0% to 43.3%, matching the performance of senior medical residents. ChatGPT has also proven successful in generating accurate discharge summaries and operative reports, with AI-created visuals enhancing the quality of these notes.",
        "AI has the potential to optimize CKD management by uncovering complex disease patterns and offering predictive insights, such as early detection, risk identification, and advanced image analysis. Reinforcement learning may further advance AI by providing real-time treatment recommendations.",
        "However, integrating AI models into healthcare presents significant challenges, including technical hurdles related to data quality and access, model accuracy, interpretability, as well as adoption issues such as workflow integration, user training, and regulatory approval (Table 3).",
        "Data quality and access: AI systems depend on reliable and valid training datasets, which are often difficult to procure. Access to high-quality data can be limited due to varying levels of digitization across healthcare institutions and restrictive data-sharing policies. Data sharing across institutions is crucial for developing more generalizable and robust models, but direct data sharing poses privacy concerns and logistical challenges. Federated learning offers an alternative approach, allowing collaborative model development without directly sharing patient data. In this method, local models are trained independently at each institution, and only the gradients or coefficients are sent to a centralized global model. This ensures privacy by design while integrating knowledge from multiple institutions, which is essential for developing AI-enabled decision support systems.",
        "Bias: Algorithmic bias occurs when an algorithm produces skewed outcomes due to biased training data or flawed design, leading to inaccurate predictions for underrepresented groups. For example, models may underperform for minority populations or younger patients if trained on data skewed toward older or majority groups. To address this, ensuring diverse data and regular auditing of algorithm outputs is crucial. Integrating AI into clinical workflows ensures its actionability and effectiveness in real-time practice.",
        "Model accuracy: Modest predictive accuracy and lack of clinical utility are challenges for image-based DL models. Future research should focus on standardizing image acquisition, establishing multicenter data-sharing platforms, and exploring diverse biomarkers. Combining multimodal imaging with clinical data shows promise for improving model performance and clinical relevance.",
        "Specifically in diagnosis, CKD poses significant challenges in the collection of imaging and pathological data, as only a small subset of patients undergo renal biopsy, and the limited tissue obtained is often insufficient for advanced sequencing. ML models leveraging multimodal frameworks can help overcome these limitations by integrating diverse data sources, including unstructured health records, pathological findings, imaging modalities, Omics, laboratory results, and clinical biomarkers to enhance predictive accuracy. Techniques like transfer learning and few-shot learning can optimize performance with small datasets, while generative adversarial networks (GANs) can generate synthetic data to augment training sets without compromising privacy. Additionally, temporal ML models incorporating longitudinal data, such as changes in imaging features and clinical parameters, hold promise for predicting treatment responses and recovery trajectories.",
        "In medical image analysis, foundation models enhance AI by offering a pre-trained base for specialized models, improving tasks like image classification. They support zero-shot learning, where the model is applied to a test set without task-specific training, and few-shot learning, where a small number of labeled examples are used to adapt to a task. Pre-trained on diverse datasets, these models capture broad patterns and knowledge, improving performance and reducing the need for extensive task-specific training. RETFound, a retinal image-based foundation model, was pre-trained on 1.6 million unlabeled fundus photographs using self-supervised learning. It achieved higher performance than comparison models with fewer labeled data, enabling effective diagnosis and prognosis of sight-threatening eye diseases and predicting heart failure, acute myocardial infarction (AMI), and stroke. The trend in image analysis is moving towards foundation models, with open-source models like RETFound allowing for the creation of more effective models with less data.",
        "Interpretability of AI models is crucial for patient care, as understanding a model's reasoning can impact decisions. For image-based deep learning models, techniques like heat maps or saliency maps highlight key influencing areas. In LLMs, attention mechanisms show which parts of the input the model focuses on, while Layer-Wise Relevance Propagation (LRP) traces each input feature's contribution. Model probing analyzes the model's internal workings to reveal decision-making processes.",
        "Hallucinations in LLMs occur when models generate inaccurate or fabricated information, undermining trust in their predictions. To mitigate this, PE can refine inputs for more accurate outputs. Additionally, domain-specific models, like BioMedLM 2.7B, ClinicalBERT, and Med-PaLM2, are fine-tuned on specialized datasets to improve accuracy in medical fields. The RAG framework enhances LLMs by integrating external knowledge bases, increasing accuracy, explainability, and transparency. This integration allows healthcare systems to use proprietary hospital data, ensuring functionality and Health Insurance Portability and Accountability Act (HIPAA), compliance while maintaining patient privacy.",
        "Non-technical challenges: Ethical concerns around data privacy and security demand robust systems for managing data collection, storage, and sharing while establishing clear guidelines for patient autonomy and privacy. Financially, the substantial costs associated with AI implementation require investments in technology, infrastructure, and user training. To mitigate these costs, fostering a collaborative ecosystem among healthcare professionals, researchers, regulators, and industries can optimize resource use. Regulatory approval is essential for medical devices using AI algorithms in clinical decision-making, but navigating these frameworks is often complex and time-consuming. Streamlining the approval process is crucial to overcoming regulatory hurdles for AI-based medical devices. Specifically, there is currently no established regulatory framework for integrating LLM-based devices into clinical use, though this landscape is rapidly evolving. It is crucial for researchers and developers to recognize the importance of building these models with a Quality Management System (QMS) in place, along with a plan for external validation and managing future changes. Legal issues in using AI technologies include cybersecurity threats such as data breach, unauthorized access, or liability concerns due to incorrect recommendations provided by AI tools that may impact patient care. Strong data encryption and clear accountability frameworks are needed to safeguard patient information and clarify liability for AI errors. Collaboration among healthcare providers, researchers, regulators, and industries is essential to develop robust protocols, ensuring compliance with legal standards while minimizing risks and maintaining patient safety. By addressing these key areas, the barriers for successful implementation can be overcome to pave the way for effective AI integration within healthcare systems."
    ],
    "title": "Artificial intelligence in chronic kidney disease management: a scoping review"
}