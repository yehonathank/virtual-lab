{
    "content": [
        "Alzheimer's disease (AD) prevalence is increasing, with no current cure. Natural language processing (NLP) offers the potential for non\u2010invasive diagnostics, social burden assessment, and research advancements in\u00a0AD.",
        "A systematic review using Preferred Reporting Items for Systematic Reviews and Meta\u2010Analyses guidelines explored NLP applications in AD, focusing on dataset types, sources, research foci, methods, and effectiveness. Searches were conducted across six databases (ACM, Embase, IEEE, PubMed, Scopus, and Web of Science) from January 2020 to July\u00a02024.",
        "Of 1740 records, 79 studies were selected. Frequently used datasets included speech and electronic health records (EHR), along with social media and scientific publications. Machine learning and neural networks were primarily applied to speech, EHR, and social media data, while rule\u2010based methods were used to analyze literature\u00a0datasets.",
        "NLP has proven effective in various aspects of AD research, including diagnosis, monitoring, social burden assessment, biomarker analysis, and research. However, there are opportunities for improvement in dataset diversity, model interpretability, multilingual capabilities, and addressing ethical\u00a0concerns.",
        "This review systematically analyzed 79 studies from six major databases, focusing on the advancements and applications of natural language processing (NLP) in Alzheimer's disease (AD) research.",
        "The study highlights the need for models focusing on remote monitoring of AD patients using speech analysis, offering a cost\u2010effective alternative to traditional methods such as brain imaging and aiding clinicians in both prediagnosis and post\u2010diagnosis periods.",
        "The use of pretrained multilingual models is recommended to improve AD detection across different languages by leveraging diverse speech features and utilizing publicly available datasets.",
        "Dementia is a clinical syndrome marked by a gradual, persistent, and progressive decline in cognitive function, which significantly impairs an individual's capacity for independent living. Dementia ranks as the seventh leading cause of death and is a significant contributor to dependency and disability worldwide. ",
        "Alzheimer's disease (AD) is the predominant form of dementia, impacting over 27 million individuals and accounting for 60% to 70% of all dementia cases. The predominant impact of AD on individuals is the creation of atrophy in diverse brain areas, causing the deterioration of brain cells and, in turn, cognitive impairment. AD hinders cognitive functions, resulting in symptoms such as memory decline, decision\u2010making difficulties, impaired communication, reduced focus, planning issues, and changes in perception. AD's far\u2010reaching prevalence has extensive societal and economic impacts, affecting more than just patients and caregivers. ",
        "The rise of artificial intelligence (AI) introduces novel capabilities to assist AD patients in various capacities. One area showing great potential in AD diagnosis is natural language processing (NLP)\u2010powered models, which are attracting considerable attention. The manual diagnosis of AD and other forms of dementia has become increasingly complex, and current diagnostic protocols rely heavily on specific clinical assessments and neuropsychological tests, which are both time\u2010consuming and expensive. As a result, early detection remains a significant obstacle. However, recent studies, including the ADReSS Challenge at the Interspeech 2020 conference and the ADReSSo Challenge at the Interspeech 2021 conference, have proven the potential of the NLP\u2010driven model for AD diagnosis and monitoring using patients' speech. These challenges offered research groups a platform to test their methods on two benchmark datasets of spontaneous speech from AD patients and healthy controls (HC). Researchers primarily competed using NLP and signal processing techniques to differentiate AD from non\u2010AD in classification tasks and to evaluate cognitive impairment through a Mini\u2010Mental State Examination (MMSE) score prediction task.",
        "Several studies have reviewed NLP applications in AD\u2010related fields. Shi et\u00a0al. concentrated on deep learning (DL) approaches for dementia diagnosis based on speech and language data, specifically differentiating HC from dementia cases. Their review exclusively targeted studies that employed DL for dementia diagnosis. De la Fuente Garcia et\u00a0al. also explored AI applications in monitoring AD based on patients' speech and language. They reviewed acoustic and linguistic features that AI\u2010based approaches extract to monitor and diagnose AD stages using speech. A study by Petti et\u00a0al. investigated automatic AD detection using speech data, concentrating on identifying different categories of acoustic and linguistic features present in various patient cohorts, such as AD and mild cognitive impairment (MCI). They asserted that language and speech could be effectively utilized for the automatic detection of dementia. The review study carried out by Patra et\u00a0al. presented a systematic review of state\u2010of\u2010the\u2010art NLP approaches and tools designed to identify and extract social determinants of health such as smoking status, substance use, homelessness, and alcohol use from unstructured clinical text in electronic health records (EHR). They concluded that extracted data could aid in the development of screening tools, risk prediction models, and clinical decision support\u00a0systems.",
        " RQ1 Which types of data are utilized for AD analysis using NLP?",
        " RQ2 What are the most popular datasets in each category?",
        " RQ3 What are the research goals?",
        " RQ4 What are emerging trends in the field?",
        " RQ5 What NLP approaches are employed in AD analysis?",
        " RQ6 How effective are NLP approaches in AD analysis?",
        "While the previous reviews provided valuable insights into dementia, our study differs in range and scope. We not only focus on language and speech data but also include studies utilizing other sources of textual data, such as EHR, comments posted by AD caregivers or their families on social media platforms, and medical publications extracted from scientific databases. However, the focus of our study is based on AD, which is the most predominant form of dementia. This systematic literature review (SLR) distinguishes itself from existing ones by proposing a thorough approach to recognizing the areas in which NLP can serve AD patients to provide an in\u2010depth view of research in the field. This review addressed the following six research questions:  ",
        "The remainder of this paper is structured as follows. Section\u00a02 describes the methodology and search and selection processes used in this SLR. Section\u00a03 presents the results and provides the findings from the data synthesis. Section\u00a04 discusses the findings and potential directions for future work, and Section\u00a05 concludes the\u00a0review.",
        "We chose to implement a systematic approach as it is well suited for broadly evaluating diverse studies across multiple disciplines, particularly those that hold clinical significance. The review followed the PRISMA checklist as its protocol. The process began by identifying the need for the SLR, followed by a formulation of research questions. We then conducted an extensive search and selection of primary studies, assessed the quality of these studies, and extracted relevant data. The article assessment procedure is depicted in Figure\u00a01. Finally, we interpreted the results and reported the findings of the\u00a0SLR.",
        "We searched six scholarly databases \u2013 ACM, PubMed, Scopus, Web Of Science, Embase, and IEEE \u2013 to identify all relevant articles related to AD and NLP. We conducted searches within a defined timeframe to identify studies that met our criteria for inclusion. The first database query was executed from January 2020 to November 2023, and then the search was updated by July 2024. As a result, this SLR concentrates on the latest developments in AD analysis using NLP, with a specific focus on the developments from the past 4 years. This focus reflects the rapid advancements in NLP, aiming to provide a concise and current review of recent innovations, keeping researchers and clinicians updated on the latest developments in this fast\u2010evolving field. To manage the search results effectively, we restricted the choice of keywords to two sets corresponding to AD and NLP. Those linked to AD encompassed \u201cAD,\u201d \u201cAlzheimer's,\u201d \u201cAlzheimer,\u201d \u201cAlzheimer's disease,\u201d \u201cdementia,\u201d and \u201cAlzheimer's Disease and Related Dementia,\u201d and keywords related to NLP included \u201cnatural language processing,\u201d \u201ctext mining,\u201d \u201cdata mining,\u201d \u201cdatamining,\u201d \u201cinformation storage and retrieval,\u201d \u201cinformation retrieval,\u201d \u201cNLP,\u201d \u201cmedical language processing,\u201d \u201cinformation extraction\u201d. When executing queries in a database, the keywords within each group were combined using the OR operator, while the two keyword sets related to AD and NLP were connected using the AND operator to refine the search\u00a0results.",
        " Systematic review: We performed a systematic review across ACM, Embase, IEEE, PubMed, Scopus, and Web of Science databases to assess recent advancements and potential uses of NLP in Alzheimer's disease (AD) analysis. Adhering to Preferred Reporting Items for Systematic Reviews and Meta\u2010Analyses (PRISMA) guidelines, this review is unique in its specific focus and scope.",
        " Interpretation: Analysis of 79 studies revealed four key trends in NLP applications for Alzheimer's research: (1) detection and monitoring of AD using speech datasets, (2) identification of AD risk factors based on EHR, (3) summarizing the current state of knowledge in AD\u2010related publications, and (4) exploring the social burden experienced by AD patients, caregivers, and their families based on social media comments.",
        " Future directions: The study suggests future research should address developing larger speech datasets for AD analysis, enhancing monitoring and remote AD diagnostic models, incorporating geo\u2010 graphically diverse datasets, and integrating privacy\u2010preserving AI tools.",
        "We excluded review papers and established our criteria to encompass a range of studies that fit the scope of this SLR. Our selection encompassed studies utilizing NLP approaches either independently or in conjunction with other methodologies. Papers selected for inclusion cover the period from January 2020 to July 2024. Table\u00a01 outlines detailed inclusion and exclusion\u00a0criteria.",
        "A sole reviewer carried out the initial screening of studies for the review. Initially, automated searches were conducted across the six previously mentioned databases using the two sets of keywords described in Section\u00a02.1 to identify relevant articles. The preliminary search yielded a collection of 3861 articles. Following the removal of duplicate entries, 1740 distinct articles remained. Subsequently, a rigorous screening process was initiated, wherein papers were evaluated based on predefined keywords, titles, and abstracts, identifying 104 pertinent papers. At this stage, a more inclusive approach was adopted when titles and abstracts did not explicitly specify the cognitive impairments addressed, the nature of the datasets processed, or the application of NLP methodologies. After this initial screening phase, a secondary round of screening was undertaken, involving an inclusive review of full\u2010text articles, culminating in the retention of 79 papers. In the final stage, papers were excluded if they lacked full\u2010text access, focused on dementia types other than MCI or AD, or did not fulfill the quality checklist criteria for bias risk assessment as outlined in Table\u00a02. Studies focusing on MCI were included, given that MCI has the potential to progress into AD. Furthermore, a detailed examination of the papers not meeting the inclusion criteria presented in Table\u00a01 was undertaken to ensure a thorough selection process. Zotero and EndNote were essential tools to manage study records throughout this\u00a0process.",
        "Adherence to the PRISMA guidelines minimized selection bias and ensured a comprehensive review. For quality assessment, we used the checklist for quantitative studies from Kitchenham and Charters' guidelines for SLRs. We applied the 12 questions listed in Table\u00a02 to evaluate the design, implementation, analysis, and conclusions of the papers. This led to the exclusion of papers that failed to meet these criteria, reducing internal biases such as measurement and reporting biases and thereby enhancing the objectivity and reliability of our conclusions. Consequently, the identified biases were minor and did not have a major impact on the impartiality or quality of this\u00a0review.",
        "Data were directly gathered from the chosen papers and organized into MS Excel for further analysis. The extracted information comprised the publication year, methodology details, dataset details, performance metrics, objectives, key findings, future prospects, and\u00a0limitations.",
        "Having discussed the identification of reviewed papers, we now address the six underlying research\u00a0questions.",
        "NLP is a highly adaptable field, allowing for various applications in the analysis of AD. This flexibility means that NLP techniques can be employed in multiple, diverse ways to tackle the complexities of AD research. In the section\u00a0being introduced, the objective is to highlight and discuss the primary directions in which NLP has been applied to AD analysis. This will be done by examining the types of data utilized in the studies that have been reviewed. We identified four major trends in how NLP is used for AD analysis. In addition to these four specific trends, we identified an additional category that encompasses approaches that do not fit neatly into the major classes and have been used infrequently. The details and citations of all reviewed papers are provided in Tables\u00a03, 4, 5, each corresponding to a specific data type (Category). The detailed analysis of the 79 reviewed papers revealed that a total of 59 distinct datasets were utilized across these\u00a0studies.",
        " Speech dataset: The primary type of data utilized comprises speech datasets, accounting for 40.68% (24 out of 59) of the total dataset. These speech datasets consist of recordings from patients with cognitive impairments such as AD and MCI, as well as HC. The speech samples are collected through various tasks and settings, including in\u2010clinic interviews and remote self\u2010assessment tools on smart devices. These tasks include the Cookie Theft description, semantic fluency task, story recall, and sentence construction. The Cookie Theft description task is a component of the Boston Diagnostic Aphasia Examination, specifically within the conversational and expository speech domain. This task involves depicting a domestic scene featuring a mother and her two children in a kitchen setting. Participants are instructed by the examiner to describe in detail everything occurring in the image. The semantic fluency task involves asking participants to generate as many words as they can within a specific semantic category (such as animals, fruits, and tools) within a set time period. This task can be understood as individuals navigating through a mental network of related words, where they move from one concept to the next based on the way their brains organize and store words and concepts. Story recall is a cognitive assessment method designed to evaluate verbal episodic memory and is frequently utilized to monitor declines associated with AD. The story recall task is administered differently across various studies. For instance, in the approach applied by Skirrow et\u00a0al., participants are presented with a series of stories consecutively. After each story, they are required to immediately recount the story in as much detail as possible. Sentence construction is another task used in collecting speech samples for AD analysis, as individuals with probable AD often have difficulty with tasks that require generating specific nouns or verbs. Their responses frequently show signs of word\u2010finding errors, dysfluent speech, and numerous lexical substitutions. ",
        " EHR dataset: The second most frequently utilized data type is the EHR, accounting for 35.59% (21 out of 59) of the distinct datasets. EHR serve as a centralized repository of patient\u2010centered records, encompassing records from healthcare providers across the full continuum of a patient's care. The content of an EHR dataset can vary significantly depending on the dataset provider, encompassing a broad range of information. This may include antipsychotic prescriptions, diagnoses, MMSE scores, mortality data, hospitalization records, clinicians' free\u2010text notes, patient demographics, living arrangements, informal support systems, comorbidities, symptom severity, risk factors, prognosis, therapies, medication and equipment management, pain assessments, wound care, and neurocognitive and behavioral status. ",
        " Literature dataset: This data type constitutes 10.17% (six out of 59) of the total datasets. A literature dataset is generated from publications within scientific databases, such as PubMed, and is employed for a variety of purposes, including detecting potential drug\u2010to\u2010drug interactions, summarizing relevant information, and extracting insights from extensive text\u00a0corpora.",
        " Social dataset: Social datasets make up 8.47% (five out of 59) of the total datasets and are sourced from social media platforms. These datasets typically include user reviews of AD\u2010related mobile applications and posts from AD stakeholders on social media. This type of dataset is often utilized to support disease management, gain insights into patients' needs, investigate the experiences of family caregivers, address behavioral and psychiatric challenges, and evaluate healthcare access and\u00a0barriers.",
        " Other dataset: As previously noted, this dataset category does not fit into the other four primary dataset sources and exhibits a diverse range of characteristics. Therefore, it is classified as \u201cOther,\u201d comprising 5.08% (three out of 59) of the total datasets. This category includes various types of data, such as free\u2010text survey responses related to the development of new AD treatments and experimentally verified glycoprotein datasets. Glycoproteins are a prevalent class of proteins linked to a range of diseases, including AD. ",
        "To summarize the answer to RQ1, we identified four primary types of data utilized in AD analysis with NLP: speech datasets, EHR datasets, literature datasets, and social datasets. Additionally, we recognized an additional type of dataset called \u201cOther\u201d that does not align with these primary categories, covering unique or non\u2010standard datasets employed in AD\u00a0research.",
        "In this section, we aim to present the most frequently utilized dataset within each of the five dataset\u00a0types.",
        "Concerning studies focused on speech datasets, a frequently utilized source is the open\u2010access, password\u2010protected DementiaBank database. DementiaBank is a collaborative database encompassing multimedia interactions in English, German, Mandarin, Spanish, and Taiwanese, specifically designed to examine communication in individuals with dementia. In the extensive exploration of 43 papers focused on speech datasets, 27 of them (62%) incorporated datasets from DementiaBank, with distribution as follows: Pitt corpus (10 papers), ADReSS (15 papers), ADReSSo (three papers), and the Wisconsin Longitudinal Study (WLS) (one paper). Notably, one study analyzed both Pitt and ADReSS datasets, while Guo et\u00a0al. incorporated both ADReSS and WLS\u00a0datasets.",
        "The Pitt corpus was compiled over a 5\u2010year period from 1983 to 1988 every year as part of the Alzheimer Research Program at the University of Pittsburgh. The Pitt corpus comprises speech recordings from 104 HC, 208 dementia participants, and 85 individuals with an unknown diagnosis. Eligibility requirements included being over the age of 44, having completed at least 7 years of education, not having a history of neurological disorders or current use of neuroleptic medications, an initial MMSE score of 10 or higher, and the ability to provide informed consent. This dataset covers various tasks, including the Cookie Theft picture description, word fluency, story recall, and sentence construction\u00a0tasks.",
        "The ADReSS dataset, introduced as part of the Alzheimer's Dementia Recognition through Spontaneous Speech Challenge at the INTERSPEECH 2020 conference, provides a standardized dataset for evaluating various methods of automated AD detection based on spontaneous speech. As a subset of the Pitt corpus, the ADReSS dataset is meticulously balanced with respect to age and gender, comprising recordings from 78 participants with AD and 78 HC. The dataset includes both audio recordings and transcriptions of participants' speech, specifically focusing on the Cookie Theft description task from the Boston Diagnostic Aphasia\u00a0Exam.",
        "The ADReSSo dataset, introduced as part of the ADReSSo Challenge 2021, serves as a benchmark for analyzing spontaneous speech in AD research. This dataset is acoustically pre\u2010processed and balanced with respect to age and gender, making it ideal for comparing various approaches to AD recognition in spontaneous speech. The dataset consists of two parts. The first set includes 105 recordings of AD patients engaged in a semantic fluency task, while the second set comprises 237 recordings of both AD patients and HC participants describing the Cookie Theft picture. ",
        "Guo et\u00a0al. combined the ADReSS Challenge 2020 dataset with the public dataset collected through the Wisconsin Longitudinal study. The WLS dataset is a longitudinal study of 10,317 graduates from Wisconsin high schools in 1957, containing cognitive test results and recordings of cognitive tests such as semantic verbal fluency. The Carolina Conversation Collection dataset is another open\u2010access resource examined by Nasreen et\u00a0al. This dataset comprises over 200 interviews with elderly individuals experiencing 12 chronic diseases, as well as over 400 interviews with those facing cognitive impairment, collected in 2011. Access to this dataset requires an application process.",
        "Several other studies tapped into non\u2010English speech datasets, including Japanese datasets, a German dataset, a Greek dataset, a Nepali speech dataset created using the DementiaBank dataset, and a French dataset. Two studies by Liu et\u00a0al. utilized an open\u2010access Chinese dataset from the Predictive Challenge of AD organized by iFlytek in 2019. This dataset encompasses 111 individuals in the HC group and 68 individuals in the AD group. Based on our analysis, most datasets used in the speech\u2010based reviewed articles (36 out of 43) are in English. Some studies utilized multiple datasets in their analysis. For example, one study by Liu et\u00a0al. used both English and Chinese datasets, while Lindsay et\u00a0al. utilized English and French datasets.",
        "Among the 79 studies reviewed, 22 employed EHR datasets. These EHR datasets were gathered from various locations: seven from the UK, 14 from the US, and one from the Netherlands. Notably, the South London and Maudsley NHS Foundation Trust (SLaM) clinical records, a major European provider of dementia and mental health services, were prominently featured, appearing in five of the 21 studies. Since 2006, SLaM has served 1.36 million residents across four South London boroughs (Lambeth, Lewisham, Southwark, and Croydon) with a comprehensive electronic health system. The Clinical Record Interactive Search (CRIS) platform provides research access to over 400,000 anonymized health records from SLaM, supported by a robust governance framework. Additionally, two studies, by Chen et\u00a0al. and Phiri et\u00a0al., utilized EHR datasets from the secondary care mental health services of the Cambridgeshire and Peterborough NHS Foundation Trust (CPFT) and the Southern Health NHS Foundation Trust (SHFT) from the UK. In the US, EHR datasets are sourced from different institutional databases such as the University of Florida health system, the Outcome and Assessment Information Set (OASIS), Michigan Medicine EHR database, Kaiser Permanente Southern California health system, a the clinical data repository of the University of Minnesota. The OASIS comprises standardized data elements developed for the purpose of assessing and comparing patient outcomes within home healthcare environments. EHR data in the Netherlands have been collected from two sources: the Alzheimer Center Amsterdam at the Amsterdam University Medical Centers, spanning the period from March 1993 to December 2020, and the Alzheimer Center Erasmus MC at the Erasmus MC University Medical Center, covering data from January 2004 to April 2019. ",
        "Turning to literature datasets assessed in the six studies, four drew on data from PubMed, utilizing its extensive repository of publications and abstracts. These studies employed NLP pipelines to extract and analyze biomedical information from PubMed. PubMed, established in 1996 and maintained by the National Center for Biotechnology Information (NCBI) at the US National Library of Medicine (NLM), is a publicly accessible database offering over 36 million citations and abstracts of biomedical\u00a0literature.",
        "Among the five studies that analyzed social datasets, three primarily used X (formerly Twitter) as their data source, where researchers developed and annotated datasets by extracting tweets related to dementia or AD. Another study by Alroobaea et\u00a0al. analyzed comments from 10 applications designed for AD patients. Additionally, Tahami et\u00a0al. examined posts from AD stakeholders collected from 112 publicly accessible social media platforms indexed by major search engines such as Google and\u00a0Bing.",
        "The minor dataset category, labeled \u201cOther,\u201d comprises three out of the 79 reviewed papers. This category includes studies utilizing questionnaires and public protein language datasets for glycosylation and glycation site prediction. A comprehensive description of all datasets employed in the reviewed papers is detailed in the dataset column in Tables\u00a03, 4, 5.",
        "To address the second research question succinctly: ADReSS is the most frequently analyzed dataset among studies focusing on speech datasets. In the context of EHR datasets, SLaM, a prominent European EHR provider, is the dataset most commonly utilized. For studies concentrating on social data, X is the most frequently examined source. Regarding literature datasets, PubMed is the primary resource employed. In the \u201cOther\u201d category, the dataset sources exhibit considerable\u00a0variability.",
        "In this section, we briefly discuss the objectives of the papers reviewed. For detailed research goals and corresponding citations for all reviewed papers, please refer to the goal column in Tables\u00a03, 4, 5.",
        "The primary goal in the reviewed papers, particularly those utilizing speech datasets (40 out of 79 studies), was AD detection through classification tasks. Studies in Table\u00a03 mainly extracted features from speech data to distinguish between AD and HC and to predict cognitive scores, such as the MMSE score. Another prevalent research aim involved identifying the optimal data modality for automatic AD detection \u2013 whether text, audio, or a combination of both \u2013 and the most effective methods for integrating these modalities. The findings of three reviewed papers indicate that combining linguistic and acoustic features enhances performance compared to unimodal approaches in AD detection. However, these studies report mixed conclusions regarding which modality \u2013 linguistic or acoustic \u2013 is more effective. For instance, Pappagari found that linguistic models typically outperform acoustic ones in detecting AD and estimating MMSE scores. However, under certain conditions, acoustic models can outperform linguistic models, particularly when errors are present in automatic speech recognition transcriptions. ",
        "In studies analyzing EHR datasets (referenced in Table\u00a04), the primary focus has been on employing rule\u2010based NLP pipelines to extract risk factors associated with AD. These factors include motor issues, cognitive test results, biomarkers of AD and AD and related dementias\u00a0(ADRD), uncooperative behavior, delusions or hallucinations, and neuropsychiatric symptoms. Furthermore, studies in this category explored the association between these factors and adverse outcomes in AD or dementia patients, with adverse outcomes being variably defined across studies ranging from death and hospitalization to weight\u00a0loss.",
        "The primary focus of studies assessing literature datasets (referenced in Table\u00a05) has been the development and optimization of NLP pipelines aimed at summarizing information and generating insights from large text\u2010based corpora derived from AD\u2010related biomedical publications. These efforts are directed toward various objectives, such as identifying potential drug\u2010to\u2010drug interactions, uncovering preventive strategies for AD, and extracting AD\u2010related gene\u2010specific information. The underlying motivation in this area is the critical need for AD researchers to review previous work and remain up to date with the rapidly expanding body of AD literature, a task that is both essential and increasingly challenging. ",
        "Research on social datasets (referenced in Table\u00a05) primarily focuses on understanding the needs of patients, providing disease management support outside of hospitals, and exploring the experiences and mental health needs of family caregivers of individuals with\u00a0ADRD.",
        "The studies categorized under the \u201cOther\u201d dataset (referenced in Table\u00a05) had a wide range of focuses, including the prediction of specific proteins associated with AD using protein language models, the evaluation of patient awareness regarding their brain health in the predementia period, and various aspects of patient\u00a0management.",
        "In summary, the primary goals in the context of AD analysis span several key areas: automatic AD detection using speech data, identification of AD risk factors through EHR, summarization of AD\u2010related literature, and examination of the social burden on AD patients and caregivers as expressed on social media\u00a0platforms.",
        "An emerging trend in AD detection using speech datasets is the shift toward more complex multiclass classification tasks. Only two of the 43 studies listed in Table\u00a03 addressed the more complex task of multiclass classification, differentiating between AD, MCI, and HC. However, the remaining studies concentrated on binary classifications, such as AD versus HC or AD+MCI versus HC. The multiple\u2010classification approach holds greater practical significance, as MCI represents a mild stage of cognitive impairment that may or may not progress to AD, making it challenging for models to differentiate between AD, MCI, and HC. Importantly, if a model can accurately detect MCI, it offers a critical opportunity for clinicians to take preventive measures to delay the onset of\u00a0AD.",
        "Five studies focused on developing automatic diagnostic tools using longitudinal speech datasets. Analyzing longitudinal speech data is another developing direction, as it may uncover temporal patterns in AD speech pathology, offering insights that single\u2010time\u2010point analyses cannot provide. The type of features used for AD detection is another crucial aspect. Some studies relied solely on embeddings extracted from pretrained large language models, which operate as black boxes. However, a rising tendency involves comparing and combining various feature types, such as linguistic, acoustic, and psycholinguistic features, alongside embeddings from pretrained models, as demonstrated in the studies by refs..",
        "Data augmentation techniques are also attracting attention in the AD detection domain, particularly for speech datasets, which are often small and imbalanced, potentially compromising model reliability. Two studies explored data augmentation methods, with Runde et\u00a0al. employing standard numerical techniques, over\u2010sampling, after converting text to numerical representations, while Woszczyk et\u00a0al. have utilized audio\u2010based or text\u2010based augmentation methods, such as paraphrasing and lexical substitution. Furthermore, a recent trend involves directly inputting speech audio files into models, bypassing manual transcription, as investigated by Runde et\u00a0al.. They noted that for an automatic AD detection model to be practical, it must be capable of processing real\u2010time speech and making continuous inferences. This necessitates research into the usability of automatic audio\u2010to\u2010text transcription tools and audio enhancement\u00a0techniques.",
        "An evolving direction in EHR\u2010based research involves leveraging these datasets to identify social determinants of health, such as housing, transportation, food, medication access, and financial difficulties, in order to address the social needs of AD patients. However, a limitation in the current body of research is the predominant reliance on datasets collected from specific locations, which may limit the generalizability of findings. Expanding studies to include datasets from diverse geographical regions could provide a more comprehensive understanding of AD\u2010related risk factors and\u00a0outcomes.",
        "According to Shao et\u00a0al., a noteworthy advancement is the development of a transformer\u2010based model architecture capable of jointly learning from both longitudinal and non\u2010longitudinal inputs, which has demonstrated high performance in predicting AD outcomes. This study underscores the significant potential of EHR data not only for identifying AD risk factors but also for improving diagnostic accuracy. Mahmoudi et\u00a0al. showed that EHR studies also have the potential to inform better care planning within health systems by identifying factors such as caregiver availability for dementia patients. Given the lack of effective therapies for AD, prevention through lifestyle changes and interventions has become increasingly important. Analyzing EHR data to understand the impact of lifestyle on AD, as examined by Shen et\u00a0al., represents a valuable approach for advancing our understanding of how lifestyle modifications can influence the progression and prevention of\u00a0AD.",
        "A development in the AD literature summarization field is the work by Rossanez et\u00a0al., which facilitates a deeper understanding of AD and potential treatments by linking entities and relationships represented in knowledge graphs derived from biomedical publications to concepts from existing biomedical ontologies available on the web. However, this approach has certain limitations, such as the lack of direct accuracy assessment and the absence of qualitative analyses involving AD experts, which could further validate the\u00a0findings.",
        "In the domain of social datasets, a growing focus is on demonstrating how social media, such as X, can be harnessed to gain insights into the experiences and needs of dementia family caregivers. Klein et\u00a0al. identified a notable gap in leveraging social media for interventions. In response, they developed an annotated dataset and benchmark classification models to automatically identify X users who are family caregivers of AD patients, showcasing the platform's potential to facilitate large\u2010scale interventions. However, this study assumes that all identified users are actual caregivers, which may not always be the case, highlighting a limitation in the definition used for family caregivers on X. Building on this, Sunmoo provided an in\u2010depth analysis of sentiments and topics expressed in AD and dementia\u2010related tweets during the COVID\u201019 pandemic. This study provided critical insights into the mental health needs of family caregivers, suggesting the potential for social media analysis to extend beyond the pandemic period. Such research lays the groundwork for ongoing studies that could provide a more comprehensive understanding of the challenges and experiences faced by AD patients and their caregivers, illustrating the valuable role of social media data in addressing the broader impacts of\u00a0AD.",
        "Exploration of studies utilizing datasets in the \u201cOther\u201d category revealed a distinct trend, as exemplified by the work of Alkuhlani et\u00a0al., which integrates transformer\u2010based language models into the proteomics field. Specifically, these researchers developed protein language models for the representation of protein sequences. This innovative approach adapts NLP principles to analyze protein sequences, paving new paths for biomarker discovery in AD research. This study demonstrates the potential of repurposing computational linguistic models to significantly advance biomedical\u00a0research.",
        "In the reviewed articles, researchers utilized diverse NLP techniques tailored to the datasets and research questions at hand. In what follows, we provide a concise overview of these methodologies, offering a clear understanding of the approaches employed. Detailed information on the methodologies applied in each study is provided in the NLP technique column in Tables\u00a03, 4, 5.",
        "Various hand\u2010coded linguistic features have been employed to analyze speech in patients with AD. Chandler et\u00a0al. evaluated poverty of speech by utilizing the type\u2010token ratio (), part\u2010of\u2010speech (PoS) tag counts and Brun\u00e9t's index () and poverty of content by measuring through the content density feature (). Furthermore, they evaluated verbigeration and language fluency by analyzing phrase\u2010 and word\u2010level repetitions, including counts of filler words like \u201cum\u201d and \u201cah.\u201d Syntactic complexity was examined using sentence parse trees and speech graphs. Additionally, semantic features were assessed by measuring coherence through cosine distances between adjacent text windows using\u00a0embeddings.",
        "Paralinguistic features, which refer to aspects of communication not related to the actual spoken words but rather to non\u2010speech sounds and socially significant gradations that influence the meaning of utterances, were also examined for AD detection based on patients' speech. These features are not confined to a rigidly defined set of units and include elements such as pitch contours, prominence, tempo, and rhythm. For example, Tavabi et\u00a0al. extracted paralinguistic features, including speech time variables such as total speaking time, the mean and standard deviation of word and pause lengths (in seconds), fraction of time spent pausing, total section\u00a0time, and the fraction of that section\u00a0in which the participant was\u00a0speaking.",
        "Psycholinguistic features have also been explored for diagnosing AD, as shifts in emotional expression among ADRD patients can occur alongside cognitive decline. These changes may affect the psycholinguistic elements of their speech, potentially impairing their ability to communicate effectively and convey their needs. Psycholinguistic indicators in speech can be evaluated through both non\u2010verbal vocalizations (such as non\u2010word utterances) and semantic\u00a0language.",
        "The reviewed articles also investigated cross\u2010modal linguistic and task\u2010specific features. Cross\u2010modal linguistic features involve examining the interactions between language and acoustic elements, such as correlating acoustic features with linguistic features and analyzing time\u2010aligned language and acoustic features. Task\u2010specific features, for example, include counting the unique animals mentioned in the animal fluency\u00a0task.",
        "While sparse text representation is fundamentally a type of linguistic feature, we categorize it under sparse text representation due to the nature of the features generated, which result in sparse matrices (often containing zero elements) owing to the underlying algorithms. In the reviewed studies, two primary sparse text representation techniques were frequently used for feature extraction, particularly with speech datasets, to convert text into numerical formats. The first one is the bag of words (BoW) technique, which represents a document as a vector of word frequencies, disregarding grammar and word order. This approach is commonly implemented using the CountVectorizer class in scikit\u2010learn. The second one is the term frequency\u2010inverse document frequency (TF\u2010IDF) approach, which extends the BoW model by incorporating a weighting mechanism that accentuates more informative words. This method evaluates the significance of a word by considering its commonality or rarity across the entire corpus, assigning greater weight to rarer words. ",
        "Dense text representation is a type of linguistic feature usually generated through neural networks (NNs), allowing for meaningful interpretation of the resulting features. Dense representation involves text encoding where most elements in the resulting vectors are non\u2010zero. These vectors typically have lower dimensionality compared to the full vocabulary size and are capable of capturing rich semantic information about words, phrases, or entire documents. The reviewed articles frequently employed dense representation methods such as fastText, Word2Vec, and\u00a0GloVe.",
        "GloVe learns a single fixed embedding for each word in the vocabulary. GloVe generates dense word embeddings by factorizing a word co\u2010occurrence matrix, thereby capturing global statistical relationships between words and encoding semantic meaning into vectors. In the study by Jain et\u00a0al. both domain\u2010specific and general\u2010purpose versions of GloVe word embeddings were generated. The domain\u2010specific embeddings were trained on a specialized corpus relevant to the area of interest, while the generic embeddings were trained on large, general\u2010purpose corpora. These embeddings were then used for AD versus HC classification on the Pitt corpus. The results indicated that domain\u2010specific embeddings outperformed generic word\u00a0embeddings.",
        "Word2Vec is an embedding technique that generates dense word embeddings by training on large text corpora. It utilizes two main algorithms: Skip\u2010Gram, which predicts context words from a target word, and Continuous BoW, which predicts a target word from its surrounding context. This model learns word vectors such that words appearing in similar contexts have similar embeddings, effectively capturing semantic relationships within the vector space. In the study by Saranp\u00e4\u00e4 et\u00a0al., Word2Vec was applied to extract feature\u2010rich semantic vectors from participants' speech. These vectors were then visualized by reducing the 300\u2010dimensional space to a two\u2010dimensional map using a data\u2010driven dimensionality reduction technique. This visualization helped identify and label semantic subcategories, providing insights into how patients with prodromal and early AD navigate the semantic space during fluency tasks compared to control\u00a0participants.",
        "fastText extends Word2Vec by addressing challenges related to unknown words and sparsity in morphologically rich languages. fastText represents each word as a combination of the word itself and its constituent n\u2010grams. A skip\u2010gram model is then used to learn embeddings for each n\u2010gram, with the word's final representation being the sum of these embeddings. The study by Jain et\u00a0al. demonstrated that domain\u2010specific fastText embeddings yielded the best results for dementia versus HC classification using the Pitt\u00a0corpus.",
        "Contextualized embedding models, which are a type of dense text representation, were frequently used to generate text features. In these models, the vector representation of a single word varies depending on its context. There was a particular focus on different versions of Bidirectional Encoder Representations from Transformers (BERT), such as DistilBERT, DistilRoBERTa, RoBERTa, Bio\u2010clinical BERT, ALBERT, PubMed BERT, BioBERT, ProtBERT\u2010BFD, ProtBERT, and ProtALBERT. Each of these models builds upon BERT and is tailored for specific tasks, domains, or improvements in efficiency through different training data, numbers of layers, attention heads, or hidden sizes. Twenty\u2010two studies in the review examined BERT\u2010derived embeddings either individually or in conjunction with other acoustic or linguistic features for AD detection through classification tasks (for a detailed description, see Tables\u00a03, 4, 5). For instance, Shen et\u00a0al. used BERT models to classify lifestyle status in an EHR dataset of AD patients, while Klein applied BERT to create a pipeline for identifying dementia\u2010related families and caregivers on X. BERT is a transformer\u2010based model that pretrains deep bidirectional representations by considering both left and right contexts across all layers, using large volumes of unlabeled text. ",
        "ESM\u20101B, TAPE, and ProtXLNet are pretrained transformer\u2010based protein language models used to encode peptide sequences in ref.. ESM\u20101B, developed by Facebook AI Research, is based on the BERT language model and trained on the UniRef50 dataset. TAPE, another BERT\u2010based model, was trained on the Pfam database, which includes approximately 31 million protein sequences. ProtXLNet is built on the XLNet language model and trained on the UniRef100 database, containing around 216 million protein sequences. The embeddings obtained from these models were input into a conventional NN model to predict glycosylation and glycation sites, as detailed in ref.. These predictions are vital because modifications at glycosylation and glycation sites are linked to various diseases, including\u00a0AD.",
        "GPT\u20103, OpenAI's Generative Pre\u2010trained Transformer model, generated embeddings employed in two reviewed articles for AD detection. The embeddings of AD and HC participants were fed into machine learning (ML) classifiers for AD versus HC classification. Agbavor demonstrated that the text embeddings generated by the GPT\u20103 model significantly outperformed conventional feature\u2010based\u00a0approaches.",
        "In the reviewed articles, a wide range of acoustic features were utilized for AD\u00a0detection.",
        "Yeung et\u00a0al. extracted several acoustic features, including properties of the sound wave, speech rate, and the number of pauses, using automatic speech analysis tools. The study by Tavabi et\u00a0al. computed a comprehensive set of acoustic features, including Mel\u2010Frequency Cepstral Coefficients (MFCCs), fundamental frequency (F0), voicing probability, local jitter, difference of differences jitter, local shimmer, harmonics\u2010to\u2010noise ratio (HNR), power spectrum (audspec), relative spectral transform (RASTA), zero crossing rate, and root mean square (RMS) energy. These features were extracted using the Massachusetts Institute of Technology's featurization algorithm and the openSMILE toolkit. ",
        "Pappagari et\u00a0al. employed x\u2010vectors to characterize the speech signals of AD patients for AD versus HC classification. They noted that x\u2010vector embeddings capture various speech characteristics including emotion, speaking rate, gender, and various articulatory, phonatory, and prosodic characteristics, which can be leveraged to identify neurological disorders such as Parkinson's disease. X\u2010vectors are acoustic features primarily used for speaker recognition, generated by a deep NN (DNN) trained to distinguish between speakers. They convert variable\u2010length speech utterances into fixed\u2010dimensional embeddings, making them particularly useful for tasks like speaker verification and, in this context, detecting neurodegenerative\u00a0diseases.",
        "A variety of NLP digital tools were employed in the reviewed articles to organize and analyze large volumes of unstructured text, with each tool typically tailored for specific text annotation\u00a0purposes.",
        "Emotional text annotation: Tools such as Affine, Syuzhet, and Bing were utilized for sentiment analysis in ref. to assign emotional valence scores to tweets regarding AD. Affine and Syuzhet are dictionary\u2010based algorithms, while Bing operates on a ML\u00a0algorithm.",
        "Medical text annotation: In ref., RLS Reveal, a taxonomy\u2010based and semantic text\u2010mining NLP algorithm, was applied to extract medical, clinical, and functional terms from unstructured clinical data. Med\u20107, a transferable clinical NLP model for EHR, was employed in ref. to identify medications within patient notes. NimbleMiner, an open\u2010source nursing\u2010sensitive NLP system based on word embeddings, is utilized to annotate neuropsychiatric symptoms in EHR datasets, as demonstrated in refs.. The General Architecture for Text Engineering (GATE) toolkit was the most frequently utilized NLP toolkit for extracting relevant information from free\u2010text clinical documentation, as seen in studies such as in refs.. This toolkit can address a variety of text processing challenges. MedTagger, an open\u2010source NLP pipeline, was applied in ref. to identify individuals with covert brain infarction and white matter disease reported in neuroimaging reports. Additionally, the Adverse Drug Event annotation Pipeline (ADEPt), a semantically enriched pipeline for extracting adverse drug events from free\u2010text EHR, was employed in ref. to detect specific motor signs from clinical free\u00a0text.",
        "Custom NLP pipelines: The CRIS NLP SERVICE was leveraged in ref. to extract symptoms, treatments, and patient outcomes from EHR, enhancing mental health research by utilizing NLP techniques to mine unstructured clinical records. In a separate study, Chen et\u00a0al. developed a custom rule\u2010based NLP pipeline using the BRAT annotation tool to extract the most frequent cognitive measurements from clinical notes. A study by Zolnoori et\u00a0al. applied two NLP methods to develop pipelines for identifying potential risk factors: a semi\u2010supervised Word2Vec method to extract specific predefined home health ADRD risk factors and unsupervised topic modeling to identify emerging topics from clinical notes. Finally, Wu et\u00a0al. developed a custom rule\u2010based NLP algorithm to identify seven domains of social determinants of health, where the rule\u2010based algorithm outperformed DL and regularized logistic regression (LR)\u00a0methods.",
        "A wide range of ML models are applied for regression and classification tasks in the reviewed papers. Examples of classification tasks include detecting AD or distinguishing between AD and HC based on speech or lifestyle data derived from EHR. Studies commonly employed ML classifiers, including support vector machine (SVM), random forest (RF), K\u2010nearest neighbor (KNN), LR, convolutional neural network (CNN), and recurrent neural network (RNN). Detailed descriptions of ML models can be found in the NLP technique column of Tables\u00a03, 4, 5.",
        "In terms of regression tasks, such as predicting cognitive scores based on speech datasets or analyzing AD risk factors from EHR datasets, linear regression and Cox regression were the most frequently utilized methods. Aryal et\u00a0al. utilized 10 distinct linear regression models, leveraging a combination of handcrafted and learned acoustic\u2010linguistic features to assess and score mental status. Al\u2010Harrasi employed the Cox regression model to explore the associations between survival, hospitalization, and a range of explanatory variables. The Cox regression model, often referred to as the proportional hazards model, is a statistical tool used to investigate the relationships between a time\u2010to\u2010event outcome and a set of\u00a0covariates.",
        "In the field of AD detection using speech data, studies typically evaluate performance metrics such as F1\u2010score, recall, accuracy, precision, and area under the curve (AUC). These metrics are summarized in the results column of Table\u00a03, where the most frequently reported metric is accuracy, noted in 32 out of 43 studies. The accuracy scores ranged from 0.65 to 0.99, with 27 studies reporting scores above 0.80.",
        "The most effective results often employ transformer\u2010based methods for contextualized embedding production, either alone or in conjunction with classical machine\u2010learning approaches. Notably, Runde et\u00a0al. reported an accuracy and an F1\u2010score of 0.99 for differentiating AD from HC using a combination of GPT embeddings and a KNN classifier. However, non\u2010public details of GPT models restrict their research utility. Transformer models, particularly various versions of BERT, are extensively studied due to their capability to capture rich semantic information and effectively encode context\u2010dependent meanings. However, a major limitation of transformer models is their \u201cblack box\u201d nature, which poses challenges for interpretation and its high demand for computational power and extensive training\u00a0data.",
        "Among ML\u00a0classifiers, SVM showed the best results in eight studies, followed by LR in five, with RF\u2010, KNN\u2010, and DL\u2010based classifiers such as CNN, RNN, and BLSTM also being employed. In terms of static word embeddings, domain\u2010specific adaptations of Word2Vec and fastText demonstrated superior performance, with the accuracy reaching 0.96 in ref. and 0.91 in ref., respectively. However, these static embedding models are limited compared to contextual models such as BERT and GPT, as they cannot adjust representations dynamically based on the text's context, potentially limiting their effectiveness in variable scenarios. TF\u2010IDF, a method for sparse text representation, proved effective, as evidenced by Linu et\u00a0al. who achieved an accuracy and F1\u2010score of 0.98 using TF\u2010IDF features combined with a KNN classifier. This approach is advantageous in terms of computational resources and runtime, and it facilitates interpretation since it relies solely on the frequency of words in the text, making it particularly suitable for clinical applications. In contrast, TF\u2010IDF disregards syntax and word order, leading to the potential loss of context and meaning. Its focus on rare words might overemphasize terms that are unique yet contextually irrelevant, potentially skewing the analytical\u00a0outcomes.",
        "Traditional linguistic features are frequently used alongside classical ML classifiers in AD detection. These features offer a clear, quantitative analysis of speech characteristics such as lexical diversity and syntax and are advantageous for their explainability. Conversely, they might fall short of capturing nuanced changes in semantics and pragmatics, in contrast to dense text representation models. Traditional linguistic features demonstrate moderate to low effectiveness in accurately detecting AD, as evidenced by the results shown in Table\u00a03 and highlighted by ref.. This shortcoming could be attributed to the methods used for feature selection, the relevance of the selected features, or the limited size of\u00a0datasets.",
        "Tavabi et\u00a0al. demonstrated that paralinguistic features were the primary contributors to distinguishing between HC and dementia cases. A disadvantage of analyzing paralinguistic features is their susceptibility to external influences, such as stress and excitement, which might not be directly related to AD. Furthermore, analyzing psycholinguistic cues can enhance the accuracy of screening methods, according to Zolnoori et\u00a0al. However, psycholinguistic analysis can be complex and may depend heavily on the context of the conversation. In accordance with results reported in several studies, the analysis of acoustic features such as x\u2010vectors and MFCC features provides comprehensive information on speech dynamics and quality and has proven beneficial. In contrast, acoustic features demand high\u2010quality audio recordings and can be susceptible to background noise and recording inconsistencies, which may complicate data collection and analysis in less controlled\u00a0environments.",
        "In studies utilizing EHR, 11 employed standard evaluation metrics such as F1\u2010score, accuracy, and AUC, as referenced in the results column of Table\u00a04. Six of them reported F1\u2010scores ranging from 0.63 to 0.96, highlighting their models' capabilities in extracting relevant information from unstructured health data. The remaining studies, which did not explicitly present metrics, relied on NLP digital tools for data extraction, followed by various statistical analyses such as significance testing and Cox regression, indicating a descriptive rather than predictive approach common in EHR data analysis. A key advantage of Cox regression is that it does not require specific distributional assumptions and can effectively incorporate both baseline and time\u2010varying clinical factors, making it ideal for analyzing complex data. ",
        "Regarding analyses of social datasets, Alroobaea et\u00a0al. achieved an accuracy and F1\u2010score of 0.994 using TF\u2010IDF features and a SVM classifier for classifying user reviews into positive and negative categories. Furthermore, a study by Klein et\u00a0al. demonstrated high performance with BERTweet\u2010Large, attaining an F1\u2010score of 0.962 for identifying tweets related to family members with dementia. The remaining three studies in this category did not explicitly report results. For literature datasets, the only reported study is the one by Hu et\u00a0al. which utilized a prompt\u2010based approach with PubMedBERT to extract relevant information from RCT abstracts, achieving an F1\u2010score of 0.962.",
        "In the \u201cOther\u201d category, Fang et\u00a0al. achieved an accuracy of 0.924 and an F1\u2010score of 0.922 in negation scope detection using their proposed model, Criteria2Query 2.0. This model integrates medical entity recognition and concept mapping from free\u2010text eligibility criteria, employing a transfer learning approach with PubMedBERT. Additionally, Alkuhlani et\u00a0al. utilized CNNs and embeddings generated from six protein language models, including ProtBert\u2010BFD, ProtBert, ProtAlbert, ProtXlnet, ESM\u20101b, and TAPE for protein site prediction. The model leveraging ProtBert\u2010BFD embeddings demonstrated the highest performance, achieving an accuracy of 0.64 and F1\u2010score of 0.65. The reviewed papers collectively demonstrate that the transfer\u2010learning approaches using BERT models are effective not only in AD detection using speech but also in analyzing EHR and in social\u2010driven and literature datasets related to\u00a0AD.",
        "To contribute to the progress of the field, enhance comparability across studies, and improve research reproducibility, we make the following recommendations for future studies:",
        " Improving remote monitoring: Only three studies have focused on developing remote, automated AD detection tools using speech. According to ref., substantial work remains to be done to make these models clinically viable, particularly regarding privacy and security of speech and medical data. We believe advancing models for AD patient monitoring through speech analysis could enhance both pre\u2010 and post\u2010diagnosis stages. Remote monitoring also offers a cost\u2010effective alternative to brain imaging, accessible via smartphones, but demands careful attention to ethical and privacy\u00a0standards.",
        " Addressing dataset limitations: Studies by refs. highlight the limitations of small datasets and the outdated collection period of the ADReSS dataset from the mid\u20101980s, which may not align with modern diagnostic standards, potentially reducing the effectiveness of contemporary ML models. A critical factor for developing reliable models is access to large, balanced datasets. Enhancing dataset utility through augmentation, merging multiple sources, and standardizing collection protocols, particularly for speech data, could foster robust model development and facilitate more accurate performance comparisons across\u00a0studies.",
        " Utilizing pretrained multilingual models: Our review of NLP techniques, as listed in the NLP technique column in Table\u00a03, reveals that no reviewed papers employed pretrained multilingual models for AD detection using speech. We recommend utilizing models such as M\u2010BERT, which is trained across over 100 languages, to overcome the scarcity of extensive training datasets in multiple languages. Such models could facilitate the identification of speech features that are generalizable across languages and cross\u2010language AD\u00a0detection.",
        " Expanding classification focus: Only two studies conducted a multiple AD versus MCI versus HC classification task described in Section\u00a03.4. Future research should explore multicategory classification, given its complexity and relevance over binary tasks and its potential benefits for diagnosis and preventive measures in early\u2010stage\u00a0AD.",
        " Improving model interpretability and error analysis: Chandler et\u00a0al. attempted to address the interpretability issue of automatic AD detection by developing dashboards to interpret the results of multiclass cognitive decline prediction models. Additionally, Martinc et\u00a0al. emphasized the importance of detailed error analysis to comprehend the model's behavior. Future research should conduct a thorough analysis of a speech\u2010based assessment tool to facilitate informed decision\u2010making and clinical integration of automated AD detection tools. Focusing on these aspects may illuminate previously hidden facets of the disease, thereby offering valuable insights and enhancing models' overall reliability and\u00a0effectiveness.",
        " Exploring alternative architectures: Despite considerable progress in large language models, it is important to note that various versions of the BERT model, an encoder\u2010only architecture, dominate among studies employing transformer architectures. Specifically, as shown in Table\u00a03, 16 out of 43 studies primarily used different versions of the BERT model for AD detection through speech analysis. Future research could explore alternative approaches by evaluating the performance of advanced models such as the encoder\u2010decoder or the decoder\u2010only model, for example, Gemini, which can handle different modalities, including audio, that allows us to use audio as well as text for AD detection and is available through the Application Programming\u00a0Interface.",
        " Addressing language diversity in speech datasets: The primary language for speech sample datasets predominantly relies on English datasets, as discussed in Section\u00a03.2. This highlights a significant gap in non\u2010English datasets for AD diagnostic and monitoring tools. The development of models that work across various languages is essential. Notably, only two studies among the reviewed articles utilized datasets from more than one language, indicating a constraint on the practical applications of such a\u00a0model.",
        " Standardizing metrics: According to the result column in Tables\u00a03, 4, 5, studies have taken varying approaches to reporting their work. We advocate for using a standardized set of evaluation metrics in classification tasks, rather than relying on a single metric such as AUC or accuracy. Reporting a comprehensive set of metrics, including accuracy, F1\u2010score, precision, recall, and AUC, enables more meaningful comparisons across studies and ensures balanced performance\u00a0evaluation.",
        " Training rule\u2010based algorithms on larger datasets: As stated by Wu et\u00a0al. a significant challenge is training rule\u2010based algorithms on larger datasets of social worker notes, which contain detailed insights on crucial issues such as housing and medication insecurities. Expanding datasets is crucial to enhancing the algorithm's ability to accurately identify social determinants associated with AD risk\u00a0factors.",
        " Integrating privacy\u2010preserving generative AI tools: Another unresolved issue is the potential for improving rule\u2010based algorithms by integrating privacy\u2010preserving generative AI tools, as discussed in ref.. Such tools could significantly enhance the handling and analysis of sensitive data, ensuring confidentiality while improving the overall effectiveness of the algorithms in identifying and analyzing critical social determinants within EHR\u00a0data.",
        " Enhancing model generalizability: Given the challenges outlined in ref. related to accurately identifying AD or ADRD and monitoring their severity through EHR, there is an evident need for models that can both detect dementia and track disease progression using cognitive test results and biomarkers derived from clinical narratives. EHR datasets, which are more readily accessible and available in larger quantities compared to speech datasets, provide a crucial resource for such developments. Additionally, the potential of EHR data in biomarker analysis for dementia and AD is underscored by findings from Chen et\u00a0al. which suggest that lithium treatment may reduce dementia risk. However, the study's focus on a specific mental health patient cohort curtails its broader applicability. Expanding research to include larger and more varied populations would help further elucidate the relationship between lithium levels and dementia\u00a0outcomes.",
        " Utilizing computational NLP pipelines: Four out of six studies analyzing the literature datasets focused on a single source of publications, PubMed. While this source is valuable, there is considerable scope for broadening the range of literature sources analyzed to provide a more comprehensive view of the field. According to Vitali et\u00a0al. there is significant potential in utilizing a computational NLP pipeline to analyze existing literature systematically and rank specific therapeutics for AD prevention. This approach could help address open research questions, such as how demographic data can be effectively integrated into computational models to improve the stratification and efficacy of therapeutic interventions in disease\u00a0prevention.",
        " Enhancing social analysis of AD using NLP: The study by Alroobaea et\u00a0al. underscores the need for more nuanced research in the social analysis of AD using NLP. Beyond binary classification of feedback as positive or negative, future research should explore specific AD applications, such as gaming or caregiving assistants, to pinpoint their strengths and weaknesses. This could include extracting significant patterns or keywords from user reviews to refine these applications. Recognizing that feedback is not always clearly positive or negative \u2013 often being neutral or inquisitive \u2013 can provide a more accurate reflection of user sentiment. Further, Klein et\u00a0al. demonstrated a method for identifying dementia stakeholders on X, which presents an opportunity to extend this approach to other platforms, such as Reddit, to boost the robustness and applicability of the\u00a0models.",
        " Advancing research on dementia subtypes and caregiver insights: Sunmoo et\u00a0al. investigated the sentiment and topics discussed by ADRD caregivers on X before and during the COVID\u201019 pandemic to offer insights into patients' mental well\u2010being during the pandemic. This study could be furthered into a post\u2010pandemic era to obtain updated insights into patients' well\u2010being. One more illustrative approach could be to focus on dominant dementia subtypes such as AD and vascular AD to get a better understanding of challenges specific to each\u00a0subtype.",
        "In this study, we followed the PRISMA protocol to conduct a comprehensive review of publications utilizing NLP methodologies for AD analysis, covering the period from January 2020 to July 2024. We systematically synthesized and examined the findings from 79 selected studies, identifying four primary trends in AD analysis: (1) detection and monitoring of AD using speech datasets, (2) identification of AD risk factors based on EHR, (3) summarizing the current state of knowledge in AD\u2010related publications, and (4) exploring the social burden experienced by AD patients, caregivers, and their\u00a0families.",
        "The studies leveraging speech and EHR datasets frequently employed NN, ML classifiers, and various linguistic features, while rule\u2010based NLP approaches were primarily used for extracting relevant information from EHR data. Analyses of social datasets predominantly utilized sentiment analysis and topic modeling, whereas studies focusing on literature datasets developed custom NLP pipelines for generating knowledge graphs and conducting network analysis.",
        "Overall, NLP techniques have demonstrated effectiveness in detecting AD, as indicated by reported performance metrics. However, significant gaps remain, as outlined in Section\u00a04, including dataset limitations, model interpretability, and privacy concerns. To address these issues, we propose several future research directions: developing larger speech datasets for AD, enhancing monitoring and remote AD detection models, incorporating geographically diverse datasets, and integrating privacy\u2010preserving AI\u00a0tools."
    ],
    "title": "Natural language processing in Alzheimer's disease research: Systematic review of methods, data, and efficacy"
}