[
    {
        "agent": "User",
        "message": "This is the beginning of an individual meeting with Clinical Informatics Specialist to discuss your research project.\n\nHere is the agenda for the meeting:\n\nYou are working on a research project to use software techniques to develop a tool for large language model (LLM) interpretability in the context of creating electronic phenotype definitions, ideally, also incorporating a visual perspective to foster trust between the clinician and the model. To develop a tool for LLM interpretability in electronic phenotype definitions, we will adopt a machine learning approach, leveraging existing open-source interpretability libraries. Our focus will be on integrating SNOMED CT to enhance reasoning and reduce hallucinations, while incorporating visual elements to build clinician trust.\n                You are responsible for understanding the topic Use of terminology servers for phenotype grounding in the context of designing an LLM-based interpretability pipeline for electronic phenotype definition.\n                You need to fine-tune yourself on the relevant literature on Use of terminology servers for phenotype grounding to improve your ability to contribute effectively to building a transparent, clinically grounded, and visually intuitive interpretability tool.\n                Please write out a series of five distinct search queries that you want to run to find relevant scientific papers on Use of terminology servers for phenotype grounding. Include both general queries about Use of terminology servers for phenotype grounding and queries that specifically relate Use of terminology servers for phenotype grounding to LLM interpretability, phenotype definition, clinical applications, and clinician trust.\n                Please provide the queries in Python syntax as a list of double-quoted strings.\n\nHere are the agenda questions that must be answered:\n\n1. What are the PMCIDs and titles of the papers you wish to fine-tune yourself on (as a Python dictionary mapping PMCID as a double-quoted string to title as double-quoted string)?\n\nClinical Informatics Specialist, please provide your response to the agenda."
    },
    {
        "agent": "Clinical Informatics Specialist",
        "message": "To address the agenda, I will first create a series of search queries to find relevant scientific papers on the use of terminology servers for phenotype grounding. These queries will cover both general aspects and specific connections to LLM interpretability, phenotype definition, clinical applications, and clinician trust.\n\nHere are the search queries in Python syntax:\n\n```python\nsearch_queries = [\n    \"Use of terminology servers for phenotype grounding\",\n    \"Terminology servers and LLM interpretability in phenotype definition\",\n    \"Phenotype grounding using SNOMED CT in clinical applications\",\n    \"Building clinician trust with visual interpretability tools in phenotype definitions\",\n    \"Integrating terminology servers for reducing hallucinations in LLMs\"\n]\n```\n\nNext, I will use these queries to search for relevant scientific papers. This will help us identify the PMCIDs and titles of the papers that are most pertinent to our research project. Let's proceed with the search."
    },
    {
        "agent": "Clinical Informatics Specialist",
        "message": "Based on the search queries, here are the PMCIDs and titles of the papers that are relevant to the use of terminology servers for phenotype grounding and related topics:\n\n```python\npapers = {\n    \"7751121\": \"Ontological representation, classification and data-driven computing of phenotypes\",\n    \"3303732\": \"Towards linked open gene mutations data\",\n    \"10236701\": \"An analysis of entity normalization evaluation biases in specialized domains\",\n    \"7485218\": \"Named Entity Recognition and Relation Detection for Biomedical Information Extraction\",\n    \"10013972\": \"First Organoid Intelligence (OI) workshop to form an OI community\",\n    \"11495871\": \"Digital approaches in post-COVID healthcare: a systematic review of technological innovations in disease management\",\n    \"3579732\": \"Semantically enabling a genome-wide association study database\",\n    \"3957334\": \"Semantically enabling pharmacogenomic data for the realization of personalized medicine\",\n    \"3338382\": \"The Bone Dysplasia Ontology: integrating genotype and phenotype information in the skeletal dysplasia domain\",\n    \"10460697\": \"Development of a Systems Medicine Approach to Spinal Cord Injury\",\n    \"2837642\": \"Biomedical informatics and translational medicine\",\n    \"11299037\": \"Trust me if you can: a survey on reliability and interpretability of machine learning approaches for drug sensitivity prediction in cancer\",\n    \"11405275\": \"Evaluation and mitigation of the limitations of large language models in clinical decision-making\",\n    \"11494256\": \"Use of SNOMED CT in Large Language Models: Scoping Review\",\n    \"11275570\": \"Evaluating Large Language Model (LLM) Performance on Established Breast Classification Systems\",\n    \"11960180\": \"Utilizing large language models for gastroenterology research: a conceptual framework\",\n    \"11325100\": \"A Reliable and Accessible Caregiving Language Model (CaLM) to Support Tools for Caregivers: Development and Evaluation Study\"\n}\n```\n\nThese papers cover various aspects of terminology servers, phenotype grounding, and their integration with large language models, providing a comprehensive foundation for your research project."
    },
    {
        "agent": "User",
        "message": "Tool Output:\n\nHere are the top 5 articles on PubMed Central for the query \"Use of terminology servers for phenotype grounding\":\n\n[begin paper 1]\n\nPMCID = 7751121\n\nTitle = Ontological representation, classification and data-driven computing of phenotypes\n\nThe successful determination and analysis of phenotypes plays a key role in the diagnostic process, the evaluation of risk factors and the recruitment of participants for clinical and epidemiological studies. The development of computable phenotype algorithms to solve these tasks is a challenging problem, caused by various reasons. Firstly, the term \u2018phenotype\u2019 has no generally agreed definition and its meaning depends on context. Secondly, the phenotypes are most commonly specified as non-computable descriptive documents. Recent attempts have shown that ontologies are a suitable way to handle phenotypes and that they can support clinical research and decision making.\n\nThe SMITH Consortium is dedicated to rapidly establish an integrative medical informatics framework to provide physicians with the best available data and knowledge and enable innovative use of healthcare data for research and treatment optimisation. In the context of a methodological use case \u2018phenotype pipeline\u2019 (PheP), a technology to automatically generate phenotype classifications and annotations based on electronic health records (EHR) is developed. A large series of phenotype algorithms will be implemented. This implies that for each algorithm a classification scheme and its input variables have to be defined. Furthermore, a phenotype engine is required to evaluate and execute developed algorithms.\n\nIn this article, we present a Core Ontology of Phenotypes (COP) and the software Phenotype Manager (PhenoMan), which implements a novel ontology-based method to model, classify and compute phenotypes from already available data. Our solution includes an enhanced iterative reasoning process combining classification tasks with mathematical calculations at runtime. The ontology as well as the reasoning method were successfully evaluated with selected phenotypes including SOFA score, socio-economic status, body surface area and WHO BMI classification based on available medical data.\n\nWe developed a novel ontology-based method to model phenotypes of living beings with the aim of automated phenotype reasoning based on available data. This new approach can be used in clinical context, e.g., for supporting the diagnostic process, evaluating risk factors, and recruiting appropriate participants for clinical and epidemiological studies.\n\n[end paper 1]\n\n[begin paper 2]\n\nPMCID = 3303732\n\nTitle = Towards linked open gene mutations data\n\nWith the advent of high-throughput technologies, a great wealth of variation data is being produced. Such information may constitute the basis for correlation analyses between genotypes and phenotypes and, in the future, for personalized medicine. Several databases on gene variation exist, but this kind of information is still scarce in the Semantic Web framework.\n\nIn this paper, we discuss issues related to the integration of mutation data in the Linked Open Data infrastructure, part of the Semantic Web framework. We present the development of a mapping from the IARC TP53 Mutation database to RDF and the implementation of servers publishing this data.\n\nA version of the IARC TP53 Mutation database implemented in a relational database was used as first test set. Automatic mappings to RDF were first created by using D2RQ and later manually refined by introducing concepts and properties from domain vocabularies and ontologies, as well as links to Linked Open Data implementations of various systems of biomedical interest.\n\nSince D2RQ query performances are lower than those that can be achieved by using an RDF archive, generated data was also loaded into a dedicated system based on tools from the Jena software suite.\n\nWe have implemented a D2RQ Server for TP53 mutation data, providing data on a subset of the IARC database, including gene variations, somatic mutations, and bibliographic references. The server allows to browse the RDF graph by using links both between classes and to external systems. An alternative interface offers improved performances for SPARQL queries. The resulting data can be explored by using any Semantic Web browser or application.\n\nThis has been the first case of a mutation database exposed as Linked Data. A revised version of our prototype, including further concepts and IARC TP53 Mutation database data sets, is under development.\n\nThe publication of variation information as Linked Data opens new perspectives: the exploitation of SPARQL searches on mutation data and other biological databases may support data retrieval which is presently not possible. Moreover, reasoning on integrated variation data may support discoveries towards personalized medicine.\n\n[end paper 2]\n\n[begin paper 3]\n\nPMCID = 10236701\n\nTitle = An analysis of entity normalization evaluation biases in specialized domains\n\nEntity normalization is an important information extraction task which has recently gained attention, particularly in the clinical/biomedical and life science domains. On several datasets, state-of-the-art methods perform rather well on popular benchmarks. Yet, we argue that the task is far from resolved.\n\nWe have selected two gold standard corpora and two state-of-the-art methods to highlight some evaluation biases. We present non-exhaustive initial findings on the existence of evaluation problems of the entity normalization task. \n\nOur analysis suggests better evaluation practices to support the methodological research in this field.\n\n[end paper 3]\n\n[begin paper 4]\n\nPMCID = 7485218\n\nTitle = Named Entity Recognition and Relation Detection for Biomedical Information Extraction\n\nThe number of scientific publications in the literature is steadily growing, containing our knowledge in the biomedical, health, and clinical sciences. Since there is currently no automatic archiving of the obtained results, much of this information remains buried in textual details not readily available for further usage or analysis. For this reason, natural language processing (NLP) and text mining methods are used for information extraction from such publications. In this paper, we review practices for Named Entity Recognition (NER) and Relation Detection (RD), allowing, e.g., to identify interactions between proteins and drugs or genes and diseases. This information can be integrated into networks to summarize large-scale details on a particular biomedical or clinical problem, which is then amenable for easy data management and further analysis. Furthermore, we survey novel deep learning methods that have recently been introduced for such tasks.\n\n[end paper 4]\n\n[begin paper 5]\n\nPMCID = 10013972\n\nTitle = First Organoid Intelligence (OI) workshop to form an OI community\n\nThe brain is arguably the most powerful computation system known. It is extremely efficient in processing large amounts of information and can discern signals from noise, adapt, and filter faulty information all while running on only 20 watts of power. The human brain's processing efficiency, progressive learning, and plasticity are unmatched by any computer system. Recent advances in stem cell technology have elevated the field of cell culture to higher levels of complexity, such as the development of three-dimensional (3D) brain organoids that recapitulate human brain functionality better than traditional monolayer cell systems. Organoid Intelligence (OI) aims to harness the innate biological capabilities of brain organoids for biocomputing and synthetic intelligence by interfacing them with computer technology. With the latest strides in stem cell technology, bioengineering, and machine learning, we can explore the ability of brain organoids to compute, and store given information (input), execute a task (output), and study how this affects the structural and functional connections in the organoids themselves. Furthermore, understanding how learning generates and changes patterns of connectivity in organoids can shed light on the early stages of cognition in the human brain. Investigating and understanding these concepts is an enormous, multidisciplinary endeavor that necessitates the engagement of both the scientific community and the public. Thus, on Feb 22\u201324 of 2022, the Johns Hopkins University held the first Organoid Intelligence Workshop to form an OI Community and to lay out the groundwork for the establishment of OI as a new scientific discipline. The potential of OI to revolutionize computing, neurological research, and drug development was discussed, along with a vision and roadmap for its development over the coming decade.\n\n[end paper 5]\n\n\n\nHere are the top 1 articles on PubMed Central for the query \"Terminology servers and LLM interpretability in phenotype definition\":\n\n[begin paper 1]\n\nPMCID = 11495871\n\nTitle = Digital approaches in post-COVID healthcare: a systematic review of technological innovations in disease management\n\nPost-COVID conditions (PCC) emerged during the pandemic, prompting a rise in the use of Digital Health Technologies (DHTs) to manage lockdowns and hospital overcrowding. Real-time tracking and information analyses were crucial to strengthening the global research response. This study aims to map the use of modern digital approaches in estimating the prevalence, predicting, diagnosing, treating, monitoring, and prognosis of PCC. This review was conducted by searching PubMed and Scopus databases for keywords and synonyms related to DHTs, Smart Healthcare Systems, and PCC based on the World Health Organization definition. Articles published from 1 January 2020 to 21 May 2024 were screened for eligibility based on predefined inclusion criteria, and the PRISMA framework was used to report the findings from the retained studies. Our search identified 377 studies, but we retained 23 studies that used DHTs, artificial intelligence (AI), and infodemiology to diagnose, estimate prevalence, predict, treat, and monitor PCC. Notably, a few interventions used infodemics to identify the clinical presentations of the disease, while most utilized Electronic Health Records and AI tools to estimate diagnosis and prevalence. However, we found that AI tools were scarcely used for monitoring symptoms, and studies involving SHS were non-existent in low- and middle-income countries (LMICs). These findings show several DHTs used in healthcare, but there is an urgent need for further research in SHS for complex health conditions, particularly in LMICs. Enhancing DHTs and integrating AI and infodemiology provide promising avenues for managing epidemics and related complications, such as PCC.\n\n[end paper 1]\n\n\n\nHere are the top 5 articles on PubMed Central for the query \"Phenotype grounding using SNOMED CT in clinical applications\":\n\n[begin paper 1]\n\nPMCID = 3579732\n\nTitle = Semantically enabling a genome-wide association study database\n\nThe amount of data generated from genome-wide association studies (GWAS) has grown rapidly, but considerations for GWAS phenotype data reuse and interchange have not kept pace. This impacts on the work of GWAS Central \u2013 a free and open access resource for the advanced querying and comparison of summary-level genetic association data. The benefits of employing ontologies for standardising and structuring data are widely accepted. The complex spectrum of observed human phenotypes (and traits), and the requirement for cross-species phenotype comparisons, calls for reflection on the most appropriate solution for the organisation of human phenotype data. The Semantic Web provides standards for the possibility of further integration of GWAS data and the ability to contribute to the web of Linked Data.\n\nA pragmatic consideration when applying phenotype ontologies to GWAS data is the ability to retrieve all data, at the most granular level possible, from querying a single ontology graph. We found the Medical Subject Headings (MeSH) terminology suitable for describing all traits (diseases and medical signs and symptoms) at various levels of granularity and the Human Phenotype Ontology (HPO) most suitable for describing phenotypic abnormalities (medical signs and symptoms) at the most granular level. Diseases within MeSH are mapped to HPO to infer the phenotypic abnormalities associated with diseases. Building on the rich semantic phenotype annotation layer, we are able to make cross-species phenotype comparisons and publish a core subset of GWAS data as RDF nanopublications.\n\nWe present a methodology for applying phenotype annotations to a comprehensive genome-wide association dataset and for ensuring compatibility with the Semantic Web. The annotations are used to assist with cross-species genotype and phenotype comparisons. However, further processing and deconstructions of terms may be required to facilitate automatic phenotype comparisons. The provision of GWAS nanopublications enables a new dimension for exploring GWAS data, by way of intrinsic links to related data resources within the Linked Data web. The value of such annotation and integration will grow as more biomedical resources adopt the standards of the Semantic Web.\n\n[end paper 1]\n\n[begin paper 2]\n\nPMCID = 3957334\n\nTitle = Semantically enabling pharmacogenomic data for the realization of personalized medicine\n\nUnderstanding how each individual\u2019s genetics and physiology influences pharmaceutical response is crucial to the realization of personalized medicine and the discovery and validation of pharmacogenomic biomarkers is key to its success. However, integration of genotype and phenotype knowledge in medical information systems remains a critical challenge. The inability to easily and accurately integrate the results of biomolecular studies with patients\u2019 medical records and clinical reports prevents us from realizing the full potential of pharmacogenomic knowledge for both drug development and clinical practice. Herein, we describe approaches using Semantic Web technologies, in which pharmacogenomic knowledge relevant to drug development and medical decision support is represented in such a way that it can be efficiently accessed both by software and human experts. We suggest that this approach increases the utility of data, and that such computational technologies will become an essential part of personalized medicine, alongside diagnostics and pharmaceutical products.\n\n[end paper 2]\n\n[begin paper 3]\n\nPMCID = 3338382\n\nTitle = The Bone Dysplasia Ontology: integrating genotype and phenotype information in the skeletal dysplasia domain\n\nSkeletal dysplasias are a rare and heterogeneous group of genetic disorders affecting skeletal development. Patients with skeletal dysplasias suffer from many complex medical issues including degenerative joint disease and neurological complications. Because the data and expertise associated with this field is both sparse and disparate, significant benefits will potentially accrue from the availability of an ontology that provides a shared conceptualisation of the domain knowledge and enables data integration, cross-referencing and advanced reasoning across the relevant but distributed data sources.\n\nWe introduce the design considerations and implementation details of the Bone Dysplasia Ontology. We also describe the different components of the ontology, including a comprehensive and formal representation of the skeletal dysplasia domain as well as the related genotypes and phenotypes. We then briefly describe SKELETOME, a community-driven knowledge curation platform that is underpinned by the Bone Dysplasia Ontology. SKELETOME enables domain experts to use, refine and extend and apply the ontology without any prior ontology engineering experience--to advance the body of knowledge in the skeletal dysplasia field.\n\nThe Bone Dysplasia Ontology represents the most comprehensive structured knowledge source for the skeletal dysplasias domain. It provides the means for integrating and annotating clinical and research data, not only at the generic domain knowledge level, but also at the level of individual patient case studies. It enables links between individual cases and publicly available genotype and phenotype resources based on a community-driven curation process that ensures a shared conceptualisation of the domain knowledge and its continuous incremental evolution.\n\n[end paper 3]\n\n[begin paper 4]\n\nPMCID = 10460697\n\nTitle = Development of a Systems Medicine Approach to Spinal Cord Injury\n\nTraumatic spinal cord injury (SCI) causes a sudden onset multi-system disease, permanently altering homeostasis with multiple complications. Consequences include aberrant neuronal circuits, multiple organ system dysfunctions, and chronic phenotypes such as neuropathic pain and metabolic syndrome. Reductionist approaches are used to classify SCI patients based on residual neurological function. Still, recovery varies due to interacting variables, including individual biology, comorbidities, complications, therapeutic side effects, and socioeconomic influences for which data integration methods are lacking. Infections, pressure sores, and heterotopic ossification are known recovery modifiers. However, the molecular pathobiology of the disease-modifying factors altering the neurological recovery-chronic syndrome trajectory is mainly unknown, with significant data gaps between intensive early treatment and chronic phases. Changes in organ function such as gut dysbiosis, adrenal dysregulation, fatty liver, muscle loss, and autonomic dysregulation disrupt homeostasis, generating progression-driving allostatic load. Interactions between interdependent systems produce emergent effects, such as resilience, that preclude single mechanism interpretations. Due to many interacting variables in individuals, substantiating the effects of treatments to improve neurological outcomes is difficult. Acute injury outcome predictors, including blood and cerebrospinal fluid biomarkers, neuroimaging signal changes, and autonomic system abnormalities, often do not predict chronic SCI syndrome phenotypes. In systems medicine, network analysis of bioinformatics data is used to derive molecular control modules. To better understand the evolution from acute SCI to chronic SCI multi-system states, we propose a topological phenotype framework integrating bioinformatics, physiological data, and allostatic load tested against accepted established recovery metrics. This form of correlational phenotyping may reveal critical nodal points for intervention to improve recovery trajectories. This study examines the limitations of current classifications of SCI and how these can evolve through systems medicine.\n\n[end paper 4]\n\n[begin paper 5]\n\nPMCID = 2837642\n\nTitle = Biomedical informatics and translational medicine\n\nBiomedical informatics involves a core set of methodologies that can provide a foundation for crossing the \"translational barriers\" associated with translational medicine. To this end, the fundamental aspects of biomedical informatics (e.g., bioinformatics, imaging informatics, clinical informatics, and public health informatics) may be essential in helping improve the ability to bring basic research findings to the bedside, evaluate the efficacy of interventions across communities, and enable the assessment of the eventual impact of translational medicine innovations on health policies. Here, a brief description is provided for a selection of key biomedical informatics topics (Decision Support, Natural Language Processing, Standards, Information Retrieval, and Electronic Health Records) and their relevance to translational medicine. Based on contributions and advancements in each of these topic areas, the article proposes that biomedical informatics practitioners (\"biomedical informaticians\") can be essential members of translational medicine teams.\n\n[end paper 5]\n\n\n\nHere are the top 3 articles on PubMed Central for the query \"Building clinician trust with visual interpretability tools in phenotype definitions\":\n\n[begin paper 1]\n\nPMCID = 11299037\n\nTitle = Trust me if you can: a survey on reliability and interpretability of machine learning approaches for drug sensitivity prediction in cancer\n\nWith the ever-increasing number of artificial intelligence (AI) systems, mitigating risks associated with their use has become one of the most urgent scientific and societal issues. To this end, the European Union passed the EU AI Act, proposing solution strategies that can be summarized under the umbrella term trustworthiness. In anti-cancer drug sensitivity prediction, machine learning (ML) methods are developed for application in medical decision support systems, which require an extraordinary level of trustworthiness. This review offers an overview of the ML landscape of methods for anti-cancer drug sensitivity prediction, including a brief introduction to the four major ML realms (supervised, unsupervised, semi-supervised, and reinforcement learning). In particular, we address the question to what extent trustworthiness-related properties, more specifically, interpretability and reliability, have been incorporated into anti-cancer drug sensitivity prediction methods over the previous decade. In total, we analyzed 36 papers with approaches for anti-cancer drug sensitivity prediction. Our results indicate that the need for reliability has hardly been addressed so far. Interpretability, on the other hand, has often been considered for model development. However, the concept is rather used intuitively, lacking clear definitions. Thus, we propose an easily extensible taxonomy for interpretability, unifying all prevalent connotations explicitly or implicitly used within the field.\n\n[end paper 1]\n\n[begin paper 2]\n\nPMCID = 7705438\n\nTitle = Abstracts from the 53rd European Society of Human Genetics (ESHG) Conference: Interactive e-Posters\n\n\n\n[end paper 2]\n\n[begin paper 3]\n\nPMCID = 9429973\n\nTitle = Abstract Book for the 27th Congress of the European Hematology Association\n\n\n\n[end paper 3]\n\n\n\nHere are the top 5 articles on PubMed Central for the query \"Integrating terminology servers for reducing hallucinations in LLMs\":\n\n[begin paper 1]\n\nPMCID = 11405275\n\nTitle = Evaluation and mitigation of the limitations of large language models in clinical decision-making\n\nClinical decision-making is one of the most impactful parts of a physician\u2019s responsibilities and stands to benefit greatly from artificial intelligence solutions and large language models (LLMs) in particular. However, while LLMs have achieved excellent performance on medical licensing exams, these tests fail to assess many skills necessary for deployment in a realistic clinical decision-making environment, including gathering information, adhering to guidelines, and integrating into clinical workflows. Here we have created a curated dataset based on the Medical Information Mart for Intensive Care database spanning 2,400 real patient cases and four common abdominal pathologies as well as a framework to simulate a realistic clinical setting. We show that current state-of-the-art LLMs do not accurately diagnose patients across all pathologies (performing significantly worse than physicians), follow neither diagnostic nor treatment guidelines, and cannot interpret laboratory results, thus posing a serious risk to the health of patients. Furthermore, we move beyond diagnostic accuracy and demonstrate that they cannot be easily integrated into existing workflows because they often fail to follow instructions and are sensitive to both the quantity and order of information. Overall, our analysis reveals that LLMs are currently not ready for autonomous clinical decision-making while providing a dataset and framework to guide future studies.\n\nUsing a curated dataset of 2,400 cases and a framework to simulate a realistic clinical setting, current large language models are shown to incur substantial pitfalls when used for autonomous clinical decision-making.\n\n[end paper 1]\n\n[begin paper 2]\n\nPMCID = 11494256\n\nTitle = Use of SNOMED CT in Large Language Models: Scoping Review\n\nLarge language models (LLMs) have substantially advanced natural language processing (NLP) capabilities but often struggle with knowledge-driven tasks in specialized domains such as biomedicine. Integrating biomedical knowledge sources such as SNOMED CT into LLMs may enhance their performance on biomedical tasks. However, the methodologies and effectiveness of incorporating SNOMED CT into LLMs have not been systematically reviewed.\n\nThis scoping review aims to examine how SNOMED CT is integrated into LLMs, focusing on (1) the types and components of LLMs being integrated with SNOMED CT, (2) which contents of SNOMED CT are being integrated, and (3) whether this integration improves LLM performance on NLP tasks.\n\nFollowing the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews) guidelines, we searched ACM Digital Library, ACL Anthology, IEEE Xplore, PubMed, and Embase for relevant studies published from 2018 to 2023. Studies were included if they incorporated SNOMED CT into LLM pipelines for natural language understanding or generation tasks. Data on LLM types, SNOMED CT integration methods, end tasks, and performance metrics were extracted and synthesized.\n\nThe review included 37 studies. Bidirectional Encoder Representations from Transformers and its biomedical variants were the most commonly used LLMs. Three main approaches for integrating SNOMED CT were identified: (1) incorporating SNOMED CT into LLM inputs (28/37, 76%), primarily using concept descriptions to expand training corpora; (2) integrating SNOMED CT into additional fusion modules (5/37, 14%); and (3) using SNOMED CT as an external knowledge retriever during inference (5/37, 14%). The most frequent end task was medical concept normalization (15/37, 41%), followed by entity extraction or typing and classification. While most studies (17/19, 89%) reported performance improvements after SNOMED CT integration, only a small fraction (19/37, 51%) provided direct comparisons. The reported gains varied widely across different metrics and tasks, ranging from 0.87% to 131.66%. However, some studies showed either no improvement or a decline in certain performance metrics.\n\nThis review demonstrates diverse approaches for integrating SNOMED CT into LLMs, with a focus on using concept descriptions to enhance biomedical language understanding and generation. While the results suggest potential benefits of SNOMED CT integration, the lack of standardized evaluation methods and comprehensive performance reporting hinders definitive conclusions about its effectiveness. Future research should prioritize consistent reporting of performance comparisons and explore more sophisticated methods for incorporating SNOMED CT\u2019s relational structure into LLMs. In addition, the biomedical NLP community should develop standardized evaluation frameworks to better assess the impact of ontology integration on LLM performance.\n\n[end paper 2]\n\n[begin paper 3]\n\nPMCID = 11275570\n\nTitle = Evaluating Large Language Model (LLM) Performance on Established Breast Classification Systems\n\nMedical researchers are increasingly utilizing advanced LLMs like ChatGPT-4 and Gemini to enhance diagnostic processes in the medical field. This research focuses on their ability to comprehend and apply complex medical classification systems for breast conditions, which can significantly aid plastic surgeons in making informed decisions for diagnosis and treatment, ultimately leading to improved patient outcomes. Fifty clinical scenarios were created to evaluate the classification accuracy of each LLM across five established breast-related classification systems. Scores from 0 to 2 were assigned to LLM responses to denote incorrect, partially correct, or completely correct classifications. Descriptive statistics were employed to compare the performances of ChatGPT-4 and Gemini. Gemini exhibited superior overall performance, achieving 98% accuracy compared to ChatGPT-4\u2019s 71%. While both models performed well in the Baker classification for capsular contracture and UTSW classification for gynecomastia, Gemini consistently outperformed ChatGPT-4 in other systems, such as the Fischer Grade Classification for gender-affirming mastectomy, Kajava Classification for ectopic breast tissue, and Regnault Classification for breast ptosis. With further development, integrating LLMs into plastic surgery practice will likely enhance diagnostic support and decision making.\n\n[end paper 3]\n\n[begin paper 4]\n\nPMCID = 11960180\n\nTitle = Utilizing large language models for gastroenterology research: a conceptual framework\n\nLarge language models (LLMs) transform healthcare by assisting clinicians with decision-making, research, and patient management. In gastroenterology, LLMs have shown potential in clinical decision support, data extraction, and patient education. However, challenges such as bias, hallucinations, integration with clinical workflows, and regulatory compliance must be addressed for safe and effective implementation. This manuscript presents a structured framework for integrating LLMs into gastroenterology, using Hepatitis C treatment as a real-world application. The framework outlines key steps to ensure accuracy, safety, and clinical relevance while mitigating risks associated with artificial intelligence (AI)-driven healthcare tools. The framework includes defining clinical goals, assembling a multidisciplinary team, data collection and preparation, model selection, fine-tuning, calibration, hallucination mitigation, user interface development, integration with electronic health records, real-world validation, and continuous improvement. Retrieval-augmented generation and fine-tuning approaches are evaluated for optimizing model adaptability. Bias detection, reinforcement learning from human feedback, and structured prompt engineering are incorporated to enhance reliability. Ethical and regulatory considerations, including the Health Insurance Portability and Accountability Act, General Data Protection Regulation, and AI-specific guidelines (DECIDE-AI, SPIRIT-AI, CONSORT-AI), are addressed to ensure responsible AI deployment. LLMs have the potential to enhance decision-making, research efficiency, and patient care in gastroenterology, but responsible deployment requires bias mitigation, transparency, and ongoing validation. Future research should focus on multi-institutional validation and AI-assisted clinical trials to establish LLMs as reliable tools in gastroenterology.\n\n How large language models could transform gastroenterology: a framework for future research and care \n\nArtificial intelligence (AI) is transforming healthcare by helping doctors make better decisions, analyze research faster, and improve patient care. Large language models (LLMs) are a type of AI that process and generate human-like text, making them useful in gastroenterology. This paper presents a structured framework for safely using LLMs in clinical practice, using Hepatitis C treatment as an example. The framework begins by setting clear goals, such as improving Hepatitis C treatment recommendations or making patient education easier to understand. A team of doctors, AI specialists, and data experts is assembled to ensure the model is medically accurate and practical. Next, relevant medical data from electronic health records (EHRs), clinical guidelines, and research studies is gathered and prepared to improve AI, ensuring it provides useful and fair recommendations. The right AI model is then chosen and improved to specialize in gastroenterology. To make sure the model is reliable and makes correct suggestions, its performance is checked and adjusted before use. A user-friendly interface is created so doctors can access AI-generated recommendations directly in EHRs and decision-support tools, making it easy to integrate into daily practice. Before full use, the AI is tested in real-world settings, where gastroenterologists review its recommendations for safety and accuracy. Once in use, ongoing updates based on doctor feedback help improve its performance. Ethical and legal safeguards, such as protecting patient privacy and ensuring fairness, guide its responsible use. Findings are then shared with the medical community, allowing for further testing and broader adoption. By following this framework, LLMs can help doctors make better decisions, personalize treatments, and improve efficiency, ultimately leading to better patient outcomes in gastroenterology.\n\n[end paper 4]\n\n[begin paper 5]\n\nPMCID = 11325100\n\nTitle = A Reliable and Accessible Caregiving Language Model (CaLM) to Support Tools for Caregivers: Development and Evaluation Study\n\nIn the United States, 1 in 5 adults currently serves as a family caregiver for an individual with a serious illness or disability. Unlike professional caregivers, family caregivers often assume this role without formal preparation or training. Thus, there is an urgent need to enhance the capacity of family caregivers to provide quality care. Leveraging technology as an educational tool or an adjunct to care is a promising approach that has the potential to enhance the learning and caregiving capabilities of family caregivers. Large language models (LLMs) can potentially be used as a foundation technology for supporting caregivers. An LLM can be categorized as a foundation model (FM), which is a large-scale model trained on a broad data set that can be adapted to a range of different domain tasks. Despite their potential, FMs have the critical weakness of \u201challucination,\u201d where the models generate information that can be misleading or inaccurate. Information reliability is essential when language models are deployed as front-line help tools for caregivers.\n\nThis study aimed to (1) develop a reliable caregiving language model (CaLM) by using FMs and a caregiving knowledge base, (2) develop an accessible CaLM using a small FM that requires fewer computing resources, and (3) evaluate the model\u2019s performance compared with a large FM.\n\nWe developed a CaLM using the retrieval augmented generation (RAG) framework combined with FM fine-tuning for improving the quality of FM answers by grounding the model on a caregiving knowledge base. The key components of the CaLM are the caregiving knowledge base, a fine-tuned FM, and a retriever module. We used 2 small FMs as candidates for the foundation of the CaLM (LLaMA [large language model Meta AI] 2 and Falcon with 7 billion parameters) and adopted a large FM (GPT-3.5 with an estimated 175 billion parameters) as a benchmark. We developed the caregiving knowledge base by gathering various types of documents from the internet. We focused on caregivers of individuals with Alzheimer disease and related dementias. We evaluated the models\u2019 performances using the benchmark metrics commonly used in evaluating language models and their reliability for providing accurate references with their answers.\n\nThe RAG framework improved the performance of all FMs used in this study across all measures. As expected, the large FM performed better than the small FMs across all metrics. Interestingly, the small fine-tuned FMs with RAG performed significantly better than GPT 3.5 across all metrics. The fine-tuned LLaMA 2 with a small FM performed better than GPT 3.5 (even with RAG) in returning references with the answers.\n\nThe study shows that a reliable and accessible CaLM can be developed using small FMs with a knowledge base specific to the caregiving domain.\n\n[end paper 5]\n\n"
    }
]